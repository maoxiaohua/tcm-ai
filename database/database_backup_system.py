#!/usr/bin/env python3
# database_backup_system.py - PostgreSQLè‡ªåŠ¨å¤‡ä»½ç³»ç»Ÿ
"""
åŠŸèƒ½ï¼š
1. è‡ªåŠ¨å¤‡ä»½PostgreSQLæ•°æ®åº“
2. æ”¯æŒå¢é‡å’Œå…¨é‡å¤‡ä»½
3. å¤‡ä»½æ–‡ä»¶å‹ç¼©å’Œæ¸…ç†
4. å¤‡ä»½å®Œæ•´æ€§éªŒè¯
5. é‚®ä»¶é€šçŸ¥ï¼ˆå¯é€‰ï¼‰
6. å¤‡ä»½æ¢å¤åŠŸèƒ½
"""

import os
import subprocess
import gzip
import shutil
import logging
import json
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple
import hashlib

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class PostgreSQLBackupSystem:
    """PostgreSQLè‡ªåŠ¨å¤‡ä»½ç³»ç»Ÿ"""
    
    def __init__(self, 
                 db_config: Dict = None,
                 backup_dir: str = "/opt/tcm/backups",
                 max_backups: int = 7,
                 compress: bool = False):
        
        self.db_config = db_config or {
            'host': 'localhost',
            'port': 5432,
            'database': 'tcm_db',
            'username': 'tcm_user',
            'password': 'tcm_secure_2024'
        }
        
        self.backup_dir = backup_dir
        self.max_backups = max_backups
        self.compress = compress
        
        # ç¡®ä¿å¤‡ä»½ç›®å½•å­˜åœ¨
        os.makedirs(backup_dir, exist_ok=True)
        
        # å¤‡ä»½é…ç½®
        self.backup_types = {
            'full': 'complete database dump',
            'data_only': 'data without schema', 
            'schema_only': 'schema without data'
        }
        
        logger.info(f"Backup system initialized: {backup_dir}")
    
    def create_backup_filename(self, backup_type: str = 'full') -> str:
        """ç”Ÿæˆå¤‡ä»½æ–‡ä»¶å"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f"tcm_db_{backup_type}_{timestamp}.sql"
        
        if self.compress:
            filename += '.gz'
            
        return os.path.join(self.backup_dir, filename)
    
    def execute_pg_dump(self, output_file: str, backup_type: str = 'full') -> Tuple[bool, str]:
        """æ‰§è¡Œpg_dumpå¤‡ä»½"""
        try:
            # æ„å»ºpg_dumpå‘½ä»¤
            cmd = [
                'pg_dump',
                f"--host={self.db_config['host']}",
                f"--port={self.db_config['port']}",
                f"--username={self.db_config['username']}",
                f"--dbname={self.db_config['database']}",
                '--verbose',
                '--clean',  # åŒ…å«æ¸…ç†å‘½ä»¤
                '--create', # åŒ…å«åˆ›å»ºæ•°æ®åº“å‘½ä»¤
            ]
            
            # æ ¹æ®å¤‡ä»½ç±»å‹æ·»åŠ å‚æ•°
            if backup_type == 'data_only':
                cmd.append('--data-only')
            elif backup_type == 'schema_only':
                cmd.append('--schema-only')
            
            # è®¾ç½®ç¯å¢ƒå˜é‡ï¼ˆå¯†ç ï¼‰
            env = os.environ.copy()
            env['PGPASSWORD'] = self.db_config['password']
            
            logger.info(f"Starting {backup_type} backup to {output_file}")
            
            if self.compress:
                # ç›´æ¥å‹ç¼©è¾“å‡º
                with gzip.open(output_file, 'wt', encoding='utf-8') as gz_file:
                    result = subprocess.run(
                        cmd, 
                        stdout=gz_file, 
                        stderr=subprocess.PIPE,
                        env=env,
                        text=True,
                        timeout=3600  # 1å°æ—¶è¶…æ—¶
                    )
            else:
                # æ™®é€šæ–‡ä»¶è¾“å‡º
                with open(output_file, 'w', encoding='utf-8') as sql_file:
                    result = subprocess.run(
                        cmd,
                        stdout=sql_file,
                        stderr=subprocess.PIPE, 
                        env=env,
                        text=True,
                        timeout=3600
                    )
            
            if result.returncode == 0:
                logger.info(f"Backup completed successfully: {output_file}")
                return True, "Backup completed successfully"
            else:
                error_msg = result.stderr or "Unknown error"
                logger.error(f"Backup failed: {error_msg}")
                return False, error_msg
                
        except subprocess.TimeoutExpired:
            error_msg = "Backup timeout (> 1 hour)"
            logger.error(error_msg)
            return False, error_msg
            
        except Exception as e:
            error_msg = f"Backup execution error: {str(e)}"
            logger.error(error_msg)
            return False, error_msg
    
    def verify_backup_integrity(self, backup_file: str) -> Tuple[bool, Dict]:
        """éªŒè¯å¤‡ä»½æ–‡ä»¶å®Œæ•´æ€§"""
        try:
            if not os.path.exists(backup_file):
                return False, {"error": "Backup file not found"}
            
            # è·å–æ–‡ä»¶ä¿¡æ¯
            file_stats = os.stat(backup_file)
            file_size = file_stats.st_size
            
            # è®¡ç®—æ–‡ä»¶å“ˆå¸Œ
            hash_md5 = hashlib.md5()
            
            if backup_file.endswith('.gz'):
                with gzip.open(backup_file, 'rb') as f:
                    for chunk in iter(lambda: f.read(4096), b""):
                        hash_md5.update(chunk)
            else:
                with open(backup_file, 'rb') as f:
                    for chunk in iter(lambda: f.read(4096), b""):
                        hash_md5.update(chunk)
            
            # åŸºæœ¬éªŒè¯ï¼šæ£€æŸ¥æ–‡ä»¶æ˜¯å¦åŒ…å«SQLå†…å®¹
            content_sample = ""
            if backup_file.endswith('.gz'):
                with gzip.open(backup_file, 'rt', encoding='utf-8') as f:
                    content_sample = f.read(1000)  # è¯»å–å‰1000å­—ç¬¦
            else:
                with open(backup_file, 'r', encoding='utf-8') as f:
                    content_sample = f.read(1000)
            
            # éªŒè¯æ˜¯å¦åŒ…å«PostgreSQLè½¬å‚¨æ ‡è¯†
            is_valid_sql = any(marker in content_sample for marker in [
                'PostgreSQL database dump',
                'CREATE DATABASE',
                'CREATE TABLE',
                '-- Name:', 
                '-- Type: TABLE'
            ])
            
            verification_result = {
                "file_size_bytes": file_size,
                "file_size_mb": round(file_size / 1024 / 1024, 2),
                "md5_hash": hash_md5.hexdigest(),
                "contains_sql_content": is_valid_sql,
                "verified_at": datetime.now().isoformat()
            }
            
            if file_size > 0 and is_valid_sql:
                logger.info(f"Backup verification passed: {backup_file}")
                return True, verification_result
            else:
                logger.warning(f"Backup verification failed: {backup_file}")
                return False, verification_result
                
        except Exception as e:
            error_result = {"error": str(e), "verified_at": datetime.now().isoformat()}
            logger.error(f"Backup verification error: {e}")
            return False, error_result
    
    def cleanup_old_backups(self) -> int:
        """æ¸…ç†æ—§å¤‡ä»½æ–‡ä»¶"""
        try:
            backup_files = []
            
            # è·å–æ‰€æœ‰å¤‡ä»½æ–‡ä»¶
            for filename in os.listdir(self.backup_dir):
                if filename.startswith('tcm_db_') and (filename.endswith('.sql') or filename.endswith('.sql.gz')):
                    file_path = os.path.join(self.backup_dir, filename)
                    file_stat = os.stat(file_path)
                    backup_files.append((file_path, file_stat.st_mtime))
            
            # æŒ‰ä¿®æ”¹æ—¶é—´æ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
            backup_files.sort(key=lambda x: x[1], reverse=True)
            
            # åˆ é™¤è¶…è¿‡é™åˆ¶çš„æ—§æ–‡ä»¶
            deleted_count = 0
            for file_path, _ in backup_files[self.max_backups:]:
                try:
                    os.remove(file_path)
                    deleted_count += 1
                    logger.info(f"Deleted old backup: {os.path.basename(file_path)}")
                except Exception as e:
                    logger.warning(f"Failed to delete {file_path}: {e}")
            
            logger.info(f"Cleanup completed: {deleted_count} old backups deleted")
            return deleted_count
            
        except Exception as e:
            logger.error(f"Cleanup error: {e}")
            return 0
    
    def create_backup(self, backup_type: str = 'full') -> Dict:
        """åˆ›å»ºå¤‡ä»½å¹¶è¿”å›ç»“æœ"""
        start_time = datetime.now()
        backup_file = self.create_backup_filename(backup_type)
        
        result = {
            "backup_type": backup_type,
            "start_time": start_time.isoformat(),
            "backup_file": backup_file,
            "success": False,
            "error": None,
            "file_info": None,
            "verification": None,
            "duration_seconds": 0
        }
        
        try:
            # æ‰§è¡Œå¤‡ä»½
            success, message = self.execute_pg_dump(backup_file, backup_type)
            
            if success:
                # éªŒè¯å¤‡ä»½
                verify_success, verify_info = self.verify_backup_integrity(backup_file)
                result["verification"] = verify_info
                result["success"] = verify_success
                
                if verify_success:
                    result["file_info"] = {
                        "path": backup_file,
                        "size_mb": verify_info["file_size_mb"],
                        "md5_hash": verify_info["md5_hash"]
                    }
                    
                    # æ¸…ç†æ—§å¤‡ä»½
                    deleted_count = self.cleanup_old_backups()
                    result["cleanup"] = {"deleted_old_backups": deleted_count}
                    
                    logger.info(f"Backup completed successfully: {backup_file}")
                else:
                    result["error"] = "Backup verification failed"
                    # åˆ é™¤éªŒè¯å¤±è´¥çš„å¤‡ä»½æ–‡ä»¶
                    if os.path.exists(backup_file):
                        os.remove(backup_file)
            else:
                result["error"] = message
                # åˆ é™¤å¤±è´¥çš„å¤‡ä»½æ–‡ä»¶
                if os.path.exists(backup_file):
                    os.remove(backup_file)
            
        except Exception as e:
            result["error"] = str(e)
            logger.error(f"Backup process error: {e}")
        
        finally:
            end_time = datetime.now()
            result["end_time"] = end_time.isoformat()
            result["duration_seconds"] = (end_time - start_time).total_seconds()
        
        return result
    
    def list_backups(self) -> List[Dict]:
        """åˆ—å‡ºæ‰€æœ‰å¤‡ä»½æ–‡ä»¶"""
        try:
            backups = []
            
            for filename in os.listdir(self.backup_dir):
                if filename.startswith('tcm_db_') and (filename.endswith('.sql') or filename.endswith('.sql.gz')):
                    file_path = os.path.join(self.backup_dir, filename)
                    file_stat = os.stat(file_path)
                    
                    # è§£ææ–‡ä»¶åè·å–å¤‡ä»½ç±»å‹å’Œæ—¶é—´
                    parts = filename.replace('.sql.gz', '').replace('.sql', '').split('_')
                    backup_type = parts[2] if len(parts) >= 3 else 'unknown'
                    backup_time = parts[3] if len(parts) >= 4 else 'unknown'
                    
                    backups.append({
                        "filename": filename,
                        "full_path": file_path,
                        "backup_type": backup_type,
                        "backup_time": backup_time,
                        "size_mb": round(file_stat.st_size / 1024 / 1024, 2),
                        "created_at": datetime.fromtimestamp(file_stat.st_ctime).isoformat(),
                        "modified_at": datetime.fromtimestamp(file_stat.st_mtime).isoformat()
                    })
            
            # æŒ‰åˆ›å»ºæ—¶é—´å€’åºæ’åˆ—
            backups.sort(key=lambda x: x['created_at'], reverse=True)
            return backups
            
        except Exception as e:
            logger.error(f"Failed to list backups: {e}")
            return []
    
    def restore_backup(self, backup_file: str, target_database: str = None) -> Dict:
        """æ¢å¤å¤‡ä»½ï¼ˆå±é™©æ“ä½œï¼Œè¯·è°¨æ…ä½¿ç”¨ï¼‰"""
        target_db = target_database or self.db_config['database']
        
        result = {
            "backup_file": backup_file,
            "target_database": target_db, 
            "success": False,
            "error": None,
            "start_time": datetime.now().isoformat()
        }
        
        if not os.path.exists(backup_file):
            result["error"] = "Backup file not found"
            return result
        
        try:
            # éªŒè¯å¤‡ä»½æ–‡ä»¶
            verify_success, verify_info = self.verify_backup_integrity(backup_file)
            if not verify_success:
                result["error"] = "Backup file verification failed"
                return result
            
            # æ„å»ºpsqlæ¢å¤å‘½ä»¤
            cmd = [
                'psql',
                f"--host={self.db_config['host']}",
                f"--port={self.db_config['port']}",
                f"--username={self.db_config['username']}",
                f"--dbname={target_db}",
                '--quiet'
            ]
            
            # è®¾ç½®ç¯å¢ƒå˜é‡
            env = os.environ.copy()
            env['PGPASSWORD'] = self.db_config['password']
            
            logger.warning(f"Starting database restore from {backup_file} to {target_db}")
            
            if backup_file.endswith('.gz'):
                # ä»å‹ç¼©æ–‡ä»¶æ¢å¤
                with gzip.open(backup_file, 'rt', encoding='utf-8') as gz_file:
                    restore_result = subprocess.run(
                        cmd,
                        stdin=gz_file,
                        stdout=subprocess.PIPE,
                        stderr=subprocess.PIPE,
                        env=env,
                        text=True,
                        timeout=3600
                    )
            else:
                # ä»æ™®é€šæ–‡ä»¶æ¢å¤
                with open(backup_file, 'r', encoding='utf-8') as sql_file:
                    restore_result = subprocess.run(
                        cmd,
                        stdin=sql_file,
                        stdout=subprocess.PIPE,
                        stderr=subprocess.PIPE,
                        env=env,
                        text=True,
                        timeout=3600
                    )
            
            if restore_result.returncode == 0:
                result["success"] = True
                logger.info(f"Database restore completed successfully")
            else:
                result["error"] = restore_result.stderr or "Unknown restore error"
                logger.error(f"Database restore failed: {result['error']}")
        
        except Exception as e:
            result["error"] = str(e)
            logger.error(f"Restore process error: {e}")
        
        finally:
            result["end_time"] = datetime.now().isoformat()
        
        return result

def create_backup_schedule_script():
    """åˆ›å»ºå¤‡ä»½è®¡åˆ’è„šæœ¬"""
    script_content = '''#!/bin/bash
# auto_backup_tcm.sh - TCMæ•°æ®åº“è‡ªåŠ¨å¤‡ä»½è„šæœ¬
# æ·»åŠ åˆ°crontab: 0 2 * * * /opt/tcm/auto_backup_tcm.sh >> /opt/tcm/logs/backup.log 2>&1

cd /opt/tcm
python3 -c "
from database_backup_system import PostgreSQLBackupSystem
import json

# åˆ›å»ºå¤‡ä»½ç³»ç»Ÿ
backup_system = PostgreSQLBackupSystem()

# æ‰§è¡Œå…¨é‡å¤‡ä»½
result = backup_system.create_backup('full')

# è¾“å‡ºç»“æœ
print(f'Backup completed at {result[\"end_time\"]}')
print(f'Success: {result[\"success\"]}')
if result[\"success\"]:
    print(f'File: {result[\"file_info\"][\"path\"]}')
    print(f'Size: {result[\"file_info\"][\"size_mb\"]}MB')
else:
    print(f'Error: {result[\"error\"]}')
"
'''
    
    script_path = "/opt/tcm/auto_backup_tcm.sh"
    with open(script_path, 'w') as f:
        f.write(script_content)
    
    # è®¾ç½®æ‰§è¡Œæƒé™
    os.chmod(script_path, 0o755)
    
    print(f"Backup schedule script created: {script_path}")
    print("To schedule daily backups at 2 AM, run:")
    print("crontab -e")
    print("Add: 0 2 * * * /opt/tcm/auto_backup_tcm.sh >> /opt/tcm/logs/backup.log 2>&1")

# æµ‹è¯•å’Œå‘½ä»¤è¡Œå·¥å…·
if __name__ == "__main__":
    import sys
    
    backup_system = PostgreSQLBackupSystem()
    
    if len(sys.argv) == 1:
        print("TCM Database Backup System")
        print("Commands:")
        print("  python3 database_backup_system.py backup [type]    - Create backup (full/data_only/schema_only)")  
        print("  python3 database_backup_system.py list            - List all backups")
        print("  python3 database_backup_system.py verify <file>   - Verify backup integrity")
        print("  python3 database_backup_system.py schedule        - Create backup schedule script")
        print("  python3 database_backup_system.py test            - Run system test")
        
    elif sys.argv[1] == "backup":
        backup_type = sys.argv[2] if len(sys.argv) > 2 else 'full'
        print(f"Creating {backup_type} backup...")
        result = backup_system.create_backup(backup_type)
        print(json.dumps(result, indent=2))
        
    elif sys.argv[1] == "list":
        backups = backup_system.list_backups()
        print(f"Found {len(backups)} backups:")
        for backup in backups:
            print(f"  {backup['filename']} ({backup['size_mb']}MB) - {backup['backup_type']} - {backup['created_at']}")
            
    elif sys.argv[1] == "verify":
        if len(sys.argv) < 3:
            print("Usage: verify <backup_file>")
        else:
            backup_file = sys.argv[2]
            success, info = backup_system.verify_backup_integrity(backup_file)
            print(f"Verification: {'PASSED' if success else 'FAILED'}")
            print(json.dumps(info, indent=2))
            
    elif sys.argv[1] == "schedule":
        create_backup_schedule_script()
        
    elif sys.argv[1] == "test":
        print("Testing backup system...")
        
        # åˆ›å»ºæµ‹è¯•å¤‡ä»½
        result = backup_system.create_backup('schema_only')
        if result['success']:
            print("âœ… Backup creation test passed")
            
            # æµ‹è¯•å¤‡ä»½åˆ—è¡¨
            backups = backup_system.list_backups()
            print(f"âœ… Backup listing test passed ({len(backups)} backups found)")
            
            # æµ‹è¯•éªŒè¯
            if backups:
                test_file = backups[0]['full_path']
                verify_success, verify_info = backup_system.verify_backup_integrity(test_file)
                if verify_success:
                    print("âœ… Backup verification test passed")
                else:
                    print("âŒ Backup verification test failed")
            
            print("ğŸ‰ All tests passed!")
        else:
            print(f"âŒ Backup creation test failed: {result['error']}")
    
    else:
        print(f"Unknown command: {sys.argv[1]}")