#!/usr/bin/env python3
"""
Doctor Decision Tree API Routes
æ™ºèƒ½å†³ç­–æ ‘ç”ŸæˆAPIè·¯ç”±

æä¾›åŒ»ç”Ÿå†³ç­–æ ‘åˆ†æå’Œç”ŸæˆåŠŸèƒ½ï¼Œå¸®åŠ©åŒ»ç”Ÿå°†è‡ªç„¶è¯­è¨€æè¿°è½¬æ¢ä¸ºç»“æ„åŒ–çš„è¯Šç–—å†³ç­–æ ‘
"""

from fastapi import APIRouter, HTTPException, Depends, Request
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials
from pydantic import BaseModel
from typing import List, Dict, Any, Optional
from datetime import datetime
import json
import logging
import asyncio
import sqlite3

# å¯¼å…¥å¿…è¦çš„æœåŠ¡
from services.famous_doctor_learning_system import FamousDoctorLearningSystem
from api.security_integration import get_current_user
from core.security.rbac_system import UserSession, UserRole
from core.prescription.tcm_formula_analyzer import TCMFormulaAnalyzer
from core.doctor_management.doctor_auth import doctor_auth_manager
from config.settings import AI_CONFIG

# æ£€æŸ¥Dashscopeå¯ç”¨æ€§
try:
    import dashscope
    DASHSCOPE_AVAILABLE = True
except ImportError:
    DASHSCOPE_AVAILABLE = False

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# åˆ›å»ºè·¯ç”±å™¨
router = APIRouter(prefix="/api", tags=["doctor-decision-tree"])

# åˆå§‹åŒ–æœåŠ¡
doctor_learning_system = FamousDoctorLearningSystem()
formula_analyzer = TCMFormulaAnalyzer()
security_bearer = HTTPBearer(auto_error=False)

# æ··åˆè®¤è¯ä¾èµ–å‡½æ•° - æ”¯æŒRBAC sessionå’ŒåŒ»ç”ŸJWT token
async def get_current_user_or_doctor(
    request: Request,
    credentials: Optional[HTTPAuthorizationCredentials] = Depends(security_bearer)
) -> UserSession:
    """
    æ··åˆè®¤è¯ï¼šä¼˜å…ˆä½¿ç”¨RBAC sessionï¼Œfallbackåˆ°åŒ»ç”ŸJWT token

    è¿™ä¸ªå‡½æ•°è§£å†³äº†ç³»ç»Ÿä¸­å­˜åœ¨ä¸¤å¥—è®¤è¯æœºåˆ¶çš„é—®é¢˜ï¼š
    1. RBACç³»ç»Ÿï¼šä½¿ç”¨user_sessionsè¡¨
    2. åŒ»ç”Ÿç³»ç»Ÿï¼šä½¿ç”¨doctorsè¡¨çš„JWT token
    """
    logger.info(f"ğŸ” [è®¤è¯]å¼€å§‹æ··åˆè®¤è¯æµç¨‹, æœ‰credentials: {credentials is not None and credentials.credentials is not None}")

    # 1. å…ˆå°è¯•RBACè®¤è¯ï¼ˆåŒ…æ‹¬ç»Ÿä¸€è®¤è¯ç³»ç»Ÿï¼‰
    try:
        user_session = await get_current_user(request, credentials)
        if user_session:
            # ğŸ”§ ä¿®å¤ï¼šå…¼å®¹ç»Ÿä¸€è®¤è¯ç³»ç»Ÿçš„ roles (List[str]) å’Œæ—§ç³»ç»Ÿçš„ role
            user_roles = getattr(user_session, 'roles', [getattr(user_session, 'role', None)])
            if isinstance(user_roles, str):
                user_roles = [user_roles]

            logger.info(f"ğŸ” [è®¤è¯]RBACè®¤è¯æˆåŠŸ: user={user_session.user_id}, roles={user_roles}")

            # æ£€æŸ¥æ˜¯å¦æœ‰åŒ»ç”Ÿæˆ–ç®¡ç†å‘˜è§’è‰²
            has_doctor_role = any(
                role in ['DOCTOR', 'ADMIN', UserRole.DOCTOR, UserRole.ADMIN]
                for role in user_roles if role
            )

            if has_doctor_role:
                logger.info(f"âœ… ç»Ÿä¸€è®¤è¯éªŒè¯é€šè¿‡: user={user_session.user_id}, roles={user_roles}")
                return user_session
            else:
                logger.warning(f"âš ï¸ ç”¨æˆ·æ— åŒ»ç”Ÿæƒé™: user={user_session.user_id}, roles={user_roles}")
    except Exception as e:
        logger.info(f"ğŸ” [è®¤è¯]RBACè®¤è¯å¤±è´¥: {e}")

    # 2. å°è¯•åŒ»ç”ŸJWT tokenè®¤è¯
    if credentials and credentials.credentials:
        token = credentials.credentials
        logger.info(f"ğŸ” [è®¤è¯]å°è¯•åŒ»ç”ŸJWTè®¤è¯, tokenå‰ç¼€: {token[:20]}...")
        doctor_payload = doctor_auth_manager.verify_auth_token(token)

        logger.info(f"ğŸ” [è®¤è¯]JWTéªŒè¯ç»“æœ: {doctor_payload is not None}")

        if doctor_payload:
            # ä»doctorsè¡¨è·å–åŒ»ç”Ÿä¿¡æ¯
            conn = sqlite3.connect("/opt/tcm-ai/data/user_history.sqlite")
            conn.row_factory = sqlite3.Row
            cursor = conn.cursor()

            cursor.execute("""
                SELECT * FROM doctors WHERE id = ? AND status = 'active'
            """, (doctor_payload['doctor_id'],))

            doctor = cursor.fetchone()
            conn.close()

            if doctor:
                # åˆ›å»ºä¸´æ—¶UserSessionå¯¹è±¡
                from datetime import datetime, timedelta
                # ä½¿ç”¨license_noä½œä¸ºuser_id (åŒ»ç”Ÿçš„å”¯ä¸€æ ‡è¯†)
                doctor_user_id = doctor['license_no']
                logger.info(f"åŒ»ç”ŸJWTè®¤è¯æˆåŠŸ: {doctor['name']} ({doctor_user_id})")

                return UserSession(
                    user_id=doctor_user_id,
                    role=UserRole.DOCTOR,
                    permissions=set(),  # åŒ»ç”Ÿé»˜è®¤æœ‰æ‰€æœ‰åŒ»ç”Ÿæƒé™
                    session_token=token,
                    created_at=datetime.now(),
                    expires_at=datetime.now() + timedelta(days=7),
                    ip_address=request.client.host if request.client else "unknown",
                    user_agent=request.headers.get("User-Agent", "Unknown"),
                    last_activity=datetime.now(),
                    is_active=True
                )

    # 3. è®¤è¯å¤±è´¥ï¼ŒæŠ›å‡º403é”™è¯¯
    raise HTTPException(
        status_code=403,
        detail="éœ€è¦åŒ»ç”Ÿæˆ–ç®¡ç†å‘˜æƒé™ã€‚è¯·å…ˆç™»å½•ã€‚"
    )

# è¯·æ±‚/å“åº”æ¨¡å‹
class ThinkingAnalysisRequest(BaseModel):
    disease_name: str
    thinking_process: str

class ThinkingAnalysisResponse(BaseModel):
    success: bool
    message: str
    data: Optional[Dict[str, Any]] = None

class DecisionTreeRequest(BaseModel):
    disease_name: str
    thinking_process: str
    selected_schools: List[str]

class DecisionTreeResponse(BaseModel):
    success: bool
    message: str
    data: Optional[Dict[str, Any]] = None

class SaveDecisionTreeRequest(BaseModel):
    disease_name: str
    thinking_process: str
    selected_schools: List[str]
    decision_tree: Dict[str, Any]
    is_template: bool = True

# V3ç‰ˆæœ¬çš„æ•°æ®æ¨¡å‹ - åˆ†æ”¯è·¯å¾„ç»“æ„
class PathStep(BaseModel):
    type: str  # symptom, condition, diagnosis, treatment, formula
    content: str
    condition: Optional[str] = None
    result: Optional[bool] = None

class DecisionPath(BaseModel):
    id: str
    steps: List[PathStep]
    keywords: List[str]
    created_by: str

class SaveDecisionTreeV3Request(BaseModel):
    disease_name: str
    paths: List[DecisionPath]
    integration_enabled: bool = True

class SymptomMatchRequest(BaseModel):
    symptoms: List[str]
    disease_context: Optional[str] = None

# ä¸­åŒ»æµæ´¾æ˜ å°„
SCHOOL_MAPPING = {
    'zhongjing': 'å¼ ä»²æ™¯ç»æ–¹æ´¾',
    'tianshi': 'å¶å¤©å£«æ¸©ç—…æ´¾',
    'dongyuan': 'æä¸œå£è„¾èƒƒæ´¾',
    'qingan': 'éƒ‘é’¦å®‰ç«ç¥æ´¾',
    'duzhou': 'åˆ˜æ¸¡èˆŸç»æ–¹æ´¾',
    'comprehensive': 'ç»¼åˆå„æ´¾è§‚ç‚¹'
}

@router.post("/analyze_thinking", response_model=ThinkingAnalysisResponse)
async def analyze_thinking(
    request: ThinkingAnalysisRequest,
    current_user: UserSession = Depends(get_current_user)
):
    """
    åˆ†æåŒ»ç”Ÿçš„è¯Šç–—æ€ç»´è¿‡ç¨‹
    
    Args:
        request: åŒ…å«ç–¾ç—…åç§°å’Œæ€ç»´è¿‡ç¨‹çš„è¯·æ±‚
        current_user: å½“å‰ç”¨æˆ·ä¿¡æ¯
        
    Returns:
        åˆ†æç»“æœï¼ŒåŒ…å«å…³é”®è¦ç‚¹ã€é—æ¼è€ƒè™‘ç‚¹å’Œå»ºè®®æµç¨‹
    """
    try:
        logger.info(f"ç”¨æˆ· {current_user.user_id} è¯·æ±‚åˆ†æè¯Šç–—æ€ç»´: {request.disease_name}")
        
        # æ„å»ºAIåˆ†ææç¤ºè¯
        analysis_prompt = f"""
        ä½œä¸ºä¸€ä½ç»éªŒä¸°å¯Œçš„ä¸­åŒ»ä¸“å®¶ï¼Œè¯·åˆ†æä»¥ä¸‹åŒ»ç”Ÿå¯¹"{request.disease_name}"çš„è¯Šç–—æ€ç»´è¿‡ç¨‹ï¼š

        åŒ»ç”Ÿçš„æ€ç»´æè¿°ï¼š
        {request.thinking_process}

        è¯·ä»ä»¥ä¸‹å‡ ä¸ªæ–¹é¢è¿›è¡Œåˆ†æï¼š

        1. **å…³é”®è¯Šæ–­è¦ç‚¹æå–**: è¯†åˆ«åŒ»ç”Ÿå·²ç»è€ƒè™‘åˆ°çš„é‡è¦è¯Šæ–­è¦ç´ 
        2. **å¯èƒ½é—æ¼çš„è€ƒè™‘ç‚¹**: æŒ‡å‡ºå¯èƒ½è¢«å¿½ç•¥ä½†é‡è¦çš„è¯Šæ–­å› ç´ 
        3. **å»ºè®®çš„è¯Šç–—æµç¨‹**: æä¾›ä¼˜åŒ–çš„è¯Šç–—æµç¨‹å»ºè®®

        è¯·ä»¥JSONæ ¼å¼è¿”å›åˆ†æç»“æœï¼š
        {{
            "key_points": ["è¦ç‚¹1", "è¦ç‚¹2", ...],
            "missing_considerations": ["é—æ¼ç‚¹1", "é—æ¼ç‚¹2", ...],
            "suggested_workflow": "å»ºè®®çš„å®Œæ•´è¯Šç–—æµç¨‹æè¿°"
        }}
        """
        
        # è°ƒç”¨AIåˆ†æ
        try:
            analysis_result = await doctor_learning_system.analyze_doctor_thinking(
                thinking_process=request.thinking_process,
                disease_name=request.disease_name,
                analysis_prompt=analysis_prompt
            )
            
            # è§£æJSONç»“æœ
            if isinstance(analysis_result, str):
                try:
                    analysis_data = json.loads(analysis_result)
                except json.JSONDecodeError:
                    # å¦‚æœè§£æå¤±è´¥ï¼Œåˆ›å»ºé»˜è®¤ç»“æ„
                    analysis_data = {
                        "key_points": ["AIåˆ†æç»“æœè§£æä¸­ï¼Œè¯·ç¨åæŸ¥çœ‹è¯¦ç»†åˆ†æ"],
                        "missing_considerations": ["æ­£åœ¨è¿›è¡Œæ·±åº¦åˆ†æ..."],
                        "suggested_workflow": analysis_result[:200] + "..."
                    }
            else:
                analysis_data = analysis_result

            return ThinkingAnalysisResponse(
                success=True,
                message="æ€ç»´åˆ†æå®Œæˆ",
                data=analysis_data
            )
            
        except Exception as ai_error:
            logger.error(f"AIåˆ†æå¤±è´¥: {ai_error}")
            # è¿”å›æ¨¡æ‹Ÿåˆ†æç»“æœä½œä¸ºåå¤‡
            return ThinkingAnalysisResponse(
                success=True,
                message="åˆ†æå®Œæˆï¼ˆä½¿ç”¨åå¤‡åˆ†æï¼‰",
                data={
                    "key_points": [
                        f"ä¸»è¦å…³æ³¨ç–¾ç—…ï¼š{request.disease_name}",
                        "å·²è€ƒè™‘ç—‡çŠ¶åˆ†æå’Œæ²»ç–—æ–¹æ¡ˆ",
                        "å…·å¤‡åŸºæœ¬çš„ä¸­åŒ»è¾¨è¯æ€ç»´"
                    ],
                    "missing_considerations": [
                        "å»ºè®®è¡¥å……å››è¯Šä¿¡æ¯æ”¶é›†",
                        "è€ƒè™‘æ‚£è€…ä½“è´¨å·®å¼‚",
                        "æ³¨æ„å¹¶å‘ç—‡å’Œç¦å¿Œç—‡",
                        "åŠ å¼ºéšè®¿è§‚å¯Ÿè®¡åˆ’"
                    ],
                    "suggested_workflow": "1. è¯¦ç»†å››è¯Šæ”¶é›† â†’ 2. ç»¼åˆè¾¨è¯åˆ†æ â†’ 3. ç¡®å®šæ²»åˆ™æ²»æ³• â†’ 4. æ–¹è¯é€‰æ‹© â†’ 5. ç–—æ•ˆè¯„ä¼°ä¸è°ƒæ•´"
                }
            )
        
    except Exception as e:
        logger.error(f"åˆ†æè¯Šç–—æ€ç»´å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"åˆ†æå¤±è´¥: {str(e)}")

@router.post("/generate_decision_tree", response_model=DecisionTreeResponse)
async def generate_decision_tree(
    request: DecisionTreeRequest,
    current_user: UserSession = Depends(get_current_user)
):
    """
    ç”Ÿæˆæ™ºèƒ½å†³ç­–æ ‘
    
    Args:
        request: åŒ…å«ç–¾ç—…ä¿¡æ¯ã€æ€ç»´è¿‡ç¨‹å’Œé€‰æ‹©æµæ´¾çš„è¯·æ±‚
        current_user: å½“å‰ç”¨æˆ·ä¿¡æ¯
        
    Returns:
        ç”Ÿæˆçš„å†³ç­–æ ‘ç»“æ„å’Œæµæ´¾å»ºè®®
    """
    try:
        logger.info(f"ç”¨æˆ· {current_user.user_id} è¯·æ±‚ç”Ÿæˆå†³ç­–æ ‘: {request.disease_name}")
        
        # è½¬æ¢æµæ´¾åç§°
        selected_school_names = []
        for school_id in request.selected_schools:
            school_name = SCHOOL_MAPPING.get(school_id, school_id)
            selected_school_names.append(school_name)
        
        # æ„å»ºå†³ç­–æ ‘ç”Ÿæˆæç¤ºè¯
        tree_prompt = f"""
        åŸºäºä»¥ä¸‹ä¿¡æ¯ç”Ÿæˆä¸­åŒ»è¯Šç–—å†³ç­–æ ‘ï¼š

        ç–¾ç—…åç§°ï¼š{request.disease_name}
        åŒ»ç”Ÿæ€ç»´è¿‡ç¨‹ï¼š{request.thinking_process}
        å‚è€ƒæµæ´¾ï¼š{', '.join(selected_school_names)}

        è¯·ç”Ÿæˆä¸€ä¸ªç»“æ„åŒ–çš„å†³ç­–æ ‘ï¼ŒåŒ…å«ä»¥ä¸‹å±‚çº§ï¼š
        1. ä¸»è¦ç—‡çŠ¶è¯†åˆ«
        2. è¾¨è¯åˆ†å‹
        3. æ²»ç–—æ–¹æ¡ˆ
        4. æ–¹è¯é€‰æ‹©

        é‡è¦ï¼šæ¯ä¸ªèŠ‚ç‚¹éƒ½åº”è¯¥æœ‰æ˜ç¡®çš„åˆ†æ”¯æ¡ä»¶ï¼Œæ–¹ä¾¿åŒ»ç”Ÿè¿›è¡Œé€»è¾‘åˆ¤æ–­ã€‚

        è¿”å›JSONæ ¼å¼ï¼š
        {{
            "tree": {{
                "levels": [
                    {{
                        "title": "ç—‡çŠ¶è¯†åˆ«",
                        "type": "symptom",
                        "nodes": [
                            {{"name": "ç—‡çŠ¶1", "description": "è¯¦ç»†æè¿°", "condition": "ç—‡çŠ¶æ˜æ˜¾ï¼Ÿ", "id": "sym_1"}},
                            {{"name": "ç—‡çŠ¶2", "description": "è¯¦ç»†æè¿°", "condition": "ç—‡çŠ¶è½»å¾®ï¼Ÿ", "id": "sym_2"}}
                        ],
                        "branches": [
                            {{"condition": "ç—‡çŠ¶è¡¨ç°ç¨‹åº¦", "result": "positive", "target_nodes": ["ç—‡çŠ¶1", "ç—‡çŠ¶2"]}}
                        ]
                    }},
                    {{
                        "title": "è¾¨è¯åˆ†å‹",
                        "type": "diagnosis",
                        "nodes": [
                            {{"name": "è¯å‹1", "description": "è¯å€™ç‰¹ç‚¹", "condition": "èˆŒçº¢è‹”åšï¼Ÿ", "id": "diag_1"}},
                            {{"name": "è¯å‹2", "description": "è¯å€™ç‰¹ç‚¹", "condition": "é¢è‰²èé»„ï¼Ÿ", "id": "diag_2"}}
                        ],
                        "branches": [
                            {{"condition": "èˆŒçº¢è‹”åšï¼Ÿ", "result": "positive", "target_nodes": ["è¯å‹1"]}},
                            {{"condition": "é¢è‰²èé»„ï¼Ÿ", "result": "positive", "target_nodes": ["è¯å‹2"]}}
                        ]
                    }},
                    {{
                        "title": "æ²»ç–—æ–¹æ¡ˆ",
                        "type": "treatment",
                        "nodes": [
                            {{"name": "æ–¹æ¡ˆ1", "description": "æ²»ç–—è¯¦æƒ…", "condition": "éœ€æ¸…çƒ­ï¼Ÿ", "id": "treat_1"}},
                            {{"name": "æ–¹æ¡ˆ2", "description": "æ²»ç–—è¯¦æƒ…", "condition": "éœ€è¡¥ç›Šï¼Ÿ", "id": "treat_2"}}
                        ],
                        "branches": [
                            {{"condition": "æ²»ç–—æ–¹å‘", "result": "positive", "target_nodes": ["æ–¹æ¡ˆ1", "æ–¹æ¡ˆ2"]}}
                        ]
                    }},
                    {{
                        "title": "æ–¹è¯é€‰æ‹©",
                        "type": "formula",
                        "nodes": [
                            {{"name": "ä¸»æ–¹", "description": "é¦–é€‰æ–¹å‰‚", "condition": "æ ‡å‡†å‰‚é‡ï¼Ÿ", "id": "form_1"}},
                            {{"name": "åŠ å‡æ–¹", "description": "ä¸ªä½“åŒ–è°ƒæ•´", "condition": "éœ€åŠ å‡ï¼Ÿ", "id": "form_2"}}
                        ],
                        "branches": [
                            {{"condition": "ç”¨è¯ç­–ç•¥", "result": "positive", "target_nodes": ["ä¸»æ–¹", "åŠ å‡æ–¹"]}}
                        ]
                    }}
                ]
            }},
            "school_suggestions": [
                {{
                    "school": "æµæ´¾åç§°",
                    "advice": "å…·ä½“å»ºè®®å†…å®¹"
                }}
            ]
        }}
        """
        
        try:
            # è°ƒç”¨AIç”Ÿæˆå†³ç­–æ ‘
            tree_result = await doctor_learning_system.generate_decision_tree(
                disease_name=request.disease_name,
                thinking_process=request.thinking_process,
                schools=selected_school_names,
                tree_prompt=tree_prompt
            )
            
            # è§£æç»“æœ
            if isinstance(tree_result, str):
                try:
                    tree_data = json.loads(tree_result)
                except json.JSONDecodeError:
                    # è§£æå¤±è´¥æ—¶è¿”å›é”™è¯¯
                    return DecisionTreeResponse(
                        success=False,
                        message="AIå“åº”æ ¼å¼é”™è¯¯ï¼ŒJSONè§£æå¤±è´¥",
                        data=None
                    )
            else:
                tree_data = tree_result

            return DecisionTreeResponse(
                success=True,
                message="å†³ç­–æ ‘ç”Ÿæˆå®Œæˆ",
                data=tree_data
            )
            
        except Exception as ai_error:
            logger.error(f"AIç”Ÿæˆå†³ç­–æ ‘å¤±è´¥: {ai_error}")
            # AIå¤±è´¥æ—¶ç›´æ¥è¿”å›é”™è¯¯
            return DecisionTreeResponse(
                success=False,
                message=f"AIç”Ÿæˆå¤±è´¥: {str(ai_error)}",
                data=None
            )
        
    except Exception as e:
        logger.error(f"ç”Ÿæˆå†³ç­–æ ‘å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"ç”Ÿæˆå¤±è´¥: {str(e)}")

@router.post("/save_decision_tree")
async def save_decision_tree(
    request: SaveDecisionTreeRequest,
    current_user: UserSession = Depends(get_current_user)
):
    """
    ä¿å­˜å†³ç­–æ ‘åˆ°çŸ¥è¯†åº“
    
    Args:
        request: åŒ…å«å†³ç­–æ ‘æ•°æ®çš„ä¿å­˜è¯·æ±‚
        current_user: å½“å‰ç”¨æˆ·ä¿¡æ¯
        
    Returns:
        ä¿å­˜ç»“æœ
    """
    try:
        logger.info(f"ç”¨æˆ· {current_user.user_id} ä¿å­˜å†³ç­–æ ‘: {request.disease_name}")
        
        # æ„å»ºä¿å­˜æ•°æ®
        save_data = {
            "disease_name": request.disease_name,
            "thinking_process": request.thinking_process,
            "selected_schools": request.selected_schools,
            "decision_tree": request.decision_tree,
            "is_template": request.is_template,
            "created_by": current_user.user_id,
            "created_at": datetime.now().isoformat()
        }
        
        # è¿™é‡Œåº”è¯¥è°ƒç”¨æ•°æ®åº“ä¿å­˜åŠŸèƒ½
        # ç›®å‰å…ˆè®°å½•æ—¥å¿—ï¼Œè¡¨ç¤ºä¿å­˜æˆåŠŸ
        logger.info(f"å†³ç­–æ ‘ä¿å­˜æ•°æ®: {save_data}")
        
        return {
            "success": True,
            "message": "å†³ç­–æ ‘å·²æˆåŠŸä¿å­˜åˆ°çŸ¥è¯†åº“",
            "data": {
                "saved_id": f"dt_{current_user.user_id}_{hash(request.disease_name) % 10000}",
                "saved_at": datetime.now().isoformat()
            }
        }
        
    except Exception as e:
        logger.error(f"ä¿å­˜å†³ç­–æ ‘å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"ä¿å­˜å¤±è´¥: {str(e)}")

def create_default_tree_structure(disease_name: str, schools: List[str]) -> Dict[str, Any]:
    """
    åˆ›å»ºé»˜è®¤çš„å†³ç­–æ ‘ç»“æ„ï¼Œæ”¯æŒåˆ†æ”¯æ¡ä»¶å’Œäº¤äº’å¼ç¼–è¾‘
    
    Args:
        disease_name: ç–¾ç—…åç§°
        schools: é€‰æ‹©çš„æµæ´¾åˆ—è¡¨
        
    Returns:
        åŒ…å«åˆ†æ”¯æ¡ä»¶çš„å†³ç­–æ ‘æ•°æ®ç»“æ„
    """
    return {
        "tree": {
            "levels": [
                {
                    "title": "ä¸»è¦ç—‡çŠ¶è¯†åˆ«",
                    "type": "symptom",
                    "nodes": [
                        {"name": f"{disease_name}ä¸»è¯", "description": "éœ€è¦è¯¦ç»†è§‚å¯Ÿçš„ä¸»è¦è¡¨ç°", "id": "root_symptom"}
                    ],
                    "branches": []
                },
                {
                    "title": "ç—‡çŠ¶ç»†åˆ†æ",
                    "type": "symptom", 
                    "nodes": [
                        {"name": "å…¸å‹ç—‡çŠ¶", "description": "æœ€å¸¸è§çš„ä¸»è¦ç—‡çŠ¶", "condition": "ç—‡çŠ¶æ˜æ˜¾ï¼Ÿ"},
                        {"name": "ä¼´éšç—‡çŠ¶", "description": "ç›¸å…³çš„æ¬¡è¦ç—‡çŠ¶", "condition": "ç—‡çŠ¶è½»å¾®ï¼Ÿ"},
                        {"name": "è¯±å‘å› ç´ ", "description": "å¯èƒ½çš„ç—…å› åˆ†æ", "condition": "æœ‰è¯±å› ï¼Ÿ"}
                    ],
                    "branches": [
                        {"condition": "ç—‡çŠ¶è¡¨ç°", "result": "positive", "target_nodes": ["å…¸å‹ç—‡çŠ¶", "ä¼´éšç—‡çŠ¶", "è¯±å‘å› ç´ "]}
                    ]
                },
                {
                    "title": "è¾¨è¯åˆ†å‹",
                    "type": "diagnosis",
                    "nodes": [
                        {"name": "å®è¯", "description": "é‚ªæ°”ç››å®çš„è¯å€™ç±»å‹", "condition": "èˆŒçº¢è‹”åšï¼Ÿ"},
                        {"name": "è™šè¯", "description": "æ­£æ°”è™šå¼±çš„è¯å€™", "condition": "é¢è‰²èé»„ï¼Ÿ"},
                        {"name": "è™šå®å¤¹æ‚", "description": "è™šå®å¹¶è§çš„å¤åˆè¯å€™", "condition": "ç—‡çŠ¶å¤æ‚ï¼Ÿ"}
                    ],
                    "branches": [
                        {"condition": "èˆŒçº¢è‹”åšï¼Ÿ", "result": "positive", "target_nodes": ["å®è¯"]},
                        {"condition": "é¢è‰²èé»„ï¼Ÿ", "result": "positive", "target_nodes": ["è™šè¯"]},
                        {"condition": "ç—‡çŠ¶å¤æ‚ï¼Ÿ", "result": "positive", "target_nodes": ["è™šå®å¤¹æ‚"]}
                    ]
                },
                {
                    "title": "æ²»æ³•æ–¹è¯",
                    "type": "formula",
                    "nodes": [
                        {"name": "é»„è¿è§£æ¯’æ±¤", "description": "æ¸…çƒ­è§£æ¯’æ–¹å‰‚", "condition": "éœ€æ¸…çƒ­ï¼Ÿ"},
                        {"name": "å››å›å­æ±¤", "description": "è¡¥æ°”å¥è„¾æ–¹å‰‚", "condition": "éœ€è¡¥ç›Šï¼Ÿ"},
                        {"name": "åŠå¤æ³»å¿ƒæ±¤", "description": "å¯’çƒ­å¹¶ç”¨ï¼Œè°ƒå’Œä¸­ç„¦", "condition": "éœ€æ”»è¡¥ï¼Ÿ"}
                    ],
                    "branches": [
                        {"condition": "æ¸…çƒ­æ²»ç–—", "result": "positive", "target_nodes": ["é»„è¿è§£æ¯’æ±¤"]},
                        {"condition": "è¡¥ç›Šæ²»ç–—", "result": "positive", "target_nodes": ["å››å›å­æ±¤"]}, 
                        {"condition": "æ”»è¡¥å¹¶ç”¨", "result": "positive", "target_nodes": ["åŠå¤æ³»å¿ƒæ±¤"]}
                    ]
                }
            ]
        },
        "school_suggestions": [
            {
                "school": school,
                "advice": f"ä»{school}çš„è§’åº¦ï¼Œå»ºè®®é‡ç‚¹å…³æ³¨ç›¸å…³çš„è¯Šç–—è¦ç‚¹å’Œç‰¹è‰²æ²»æ³•"
            } for school in schools[:3]  # é™åˆ¶å»ºè®®æ•°é‡
        ]
    }

@router.post("/save_decision_tree_v3")
async def save_decision_tree_v3(
    request: SaveDecisionTreeV3Request,
    current_user: UserSession = Depends(get_current_user)
):
    """
    ä¿å­˜V3ç‰ˆæœ¬çš„å†³ç­–æ ‘ï¼ˆåˆ†æ”¯è·¯å¾„ç»“æ„ï¼‰
    
    Args:
        request: åŒ…å«åˆ†æ”¯è·¯å¾„æ•°æ®çš„ä¿å­˜è¯·æ±‚
        current_user: å½“å‰ç”¨æˆ·ä¿¡æ¯
        
    Returns:
        ä¿å­˜ç»“æœ
    """
    try:
        logger.info(f"ç”¨æˆ· {current_user.user_id} ä¿å­˜V3å†³ç­–æ ‘: {request.disease_name}")
        
        # æ„å»ºä¿å­˜æ•°æ®
        save_data = {
            "disease_name": request.disease_name,
            "paths": [path.dict() for path in request.paths],
            "integration_enabled": request.integration_enabled,
            "version": "v3",
            "created_by": current_user.user_id,
            "created_at": datetime.now().isoformat()
        }
        
        # è¿™é‡Œåº”è¯¥è°ƒç”¨æ•°æ®åº“ä¿å­˜åŠŸèƒ½
        logger.info(f"V3å†³ç­–æ ‘ä¿å­˜æ•°æ®: {save_data}")
        
        return {
            "success": True,
            "message": "å†³ç­–æ ‘è·¯å¾„å·²æˆåŠŸä¿å­˜ï¼Œç°å·²å¯ç”¨é—®è¯Šé›†æˆåŠŸèƒ½",
            "data": {
                "saved_id": f"dtv3_{current_user.user_id}_{hash(request.disease_name) % 10000}",
                "saved_at": datetime.now().isoformat(),
                "paths_count": len(request.paths)
            }
        }
        
    except Exception as e:
        logger.error(f"ä¿å­˜V3å†³ç­–æ ‘å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"ä¿å­˜å¤±è´¥: {str(e)}")

@router.post("/match_symptoms_to_paths")
async def match_symptoms_to_paths(
    request: SymptomMatchRequest,
    current_user: UserSession = Depends(get_current_user)
):
    """
    ç—‡çŠ¶åŒ¹é…å†³ç­–è·¯å¾„ï¼ˆç”¨äºé—®è¯Šé›†æˆï¼‰
    
    Args:
        request: åŒ…å«ç—‡çŠ¶åˆ—è¡¨çš„åŒ¹é…è¯·æ±‚
        current_user: å½“å‰ç”¨æˆ·ä¿¡æ¯
        
    Returns:
        åŒ¹é…çš„å†³ç­–è·¯å¾„å’Œæ¨èæ–¹å‰‚
    """
    try:
        logger.info(f"ç—‡çŠ¶åŒ¹é…è¯·æ±‚: {request.symptoms}")
        
        # è¿™é‡Œåº”è¯¥ä»æ•°æ®åº“åŠ è½½è¯¥ç–¾ç—…çš„æ‰€æœ‰å†³ç­–è·¯å¾„
        # ç°åœ¨ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®æ¼”ç¤ºåŒ¹é…é€»è¾‘
        
        sample_paths = [
            {
                "id": "path_1",
                "steps": [
                    {"type": "symptom", "content": "å¤±çœ "},
                    {"type": "condition", "content": "èˆŒçº¢è‹”é»„", "result": True},
                    {"type": "diagnosis", "content": "å¿ƒç«æ—ºç››"},
                    {"type": "treatment", "content": "æ¸…å¿ƒç«"},
                    {"type": "formula", "content": "é»„è¿é˜¿èƒ¶æ±¤"}
                ],
                "keywords": ["å¤±çœ ", "å¤šæ¢¦", "å¿ƒçƒ¦", "å£å¹²", "èˆŒçº¢", "è‹”é»„"],
                "match_score": 0
            },
            {
                "id": "path_2",
                "steps": [
                    {"type": "symptom", "content": "å¤±çœ "},
                    {"type": "condition", "content": "é¢è‰²èé»„", "result": True},
                    {"type": "diagnosis", "content": "å¿ƒè„¾ä¸¤è™š"},
                    {"type": "treatment", "content": "è¡¥ç›Šå¿ƒè„¾"},
                    {"type": "formula", "content": "å½’è„¾æ±¤"}
                ],
                "keywords": ["å¤±çœ ", "å¿ƒæ‚¸", "å¥å¿˜", "é¢è‰²èé»„", "èˆŒæ·¡", "è„‰å¼±"],
                "match_score": 0
            }
        ]
        
        # è®¡ç®—åŒ¹é…åˆ†æ•°
        user_symptoms_set = set([s.lower() for s in request.symptoms])
        
        for path in sample_paths:
            path_keywords_set = set([k.lower() for k in path["keywords"]])
            # è®¡ç®—äº¤é›†æ¯”ä¾‹
            intersection = user_symptoms_set.intersection(path_keywords_set)
            path["match_score"] = len(intersection) / len(path_keywords_set) if path_keywords_set else 0
            path["matched_keywords"] = list(intersection)
        
        # æŒ‰åŒ¹é…åˆ†æ•°æ’åº
        sample_paths.sort(key=lambda x: x["match_score"], reverse=True)
        
        # é€‰æ‹©æœ€ä½³åŒ¹é…è·¯å¾„
        best_match = sample_paths[0] if sample_paths and sample_paths[0]["match_score"] > 0.3 else None
        
        if best_match:
            recommended_formula = None
            treatment_method = None
            
            for step in best_match["steps"]:
                if step["type"] == "formula":
                    recommended_formula = step["content"]
                elif step["type"] == "treatment":
                    treatment_method = step["content"]
            
            return {
                "success": True,
                "message": "æ‰¾åˆ°åŒ¹é…çš„è¯Šç–—è·¯å¾„",
                "data": {
                    "matched_path": best_match,
                    "recommended_formula": recommended_formula,
                    "treatment_method": treatment_method,
                    "match_confidence": best_match["match_score"],
                    "matched_keywords": best_match["matched_keywords"]
                }
            }
        else:
            return {
                "success": True,
                "message": "æœªæ‰¾åˆ°é«˜åº¦åŒ¹é…çš„è·¯å¾„ï¼Œå»ºè®®æ‰‹åŠ¨è¯Šæ–­",
                "data": {
                    "matched_path": None,
                    "alternative_paths": sample_paths[:2],
                    "suggestion": "ç—‡çŠ¶æè¿°å¯èƒ½éœ€è¦æ›´è¯¦ç»†ï¼Œæˆ–è¯¥ç—…ç—‡æš‚æ— å¯¹åº”çš„å†³ç­–è·¯å¾„"
                }
            }
        
    except Exception as e:
        logger.error(f"ç—‡çŠ¶åŒ¹é…å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"åŒ¹é…å¤±è´¥: {str(e)}")


# V3ç‰ˆæœ¬æ–°å¢API - å¯è§†åŒ–æ„å»ºå™¨æ”¯æŒ

class VisualDecisionTreeRequest(BaseModel):
    disease_name: str
    thinking_process: Optional[str] = ""
    include_tcm_analysis: bool = True
    complexity_level: str = "standard"  # simple, standard, complex
    use_ai: Optional[bool] = None  # æ–°å¢ï¼šæ‰‹åŠ¨æŒ‡å®šAIæ¨¡å¼
    enable_smart_branching: bool = False  # æ–°å¢ï¼šæ™ºèƒ½å¹´é¾„åˆ†æ”¯åŠŸèƒ½

class TCMTheoryAnalysisRequest(BaseModel):
    tree_data: Dict[str, Any]
    disease_name: str

class MissingLogicDetectionRequest(BaseModel):
    disease_name: str
    current_paths: List[Dict[str, Any]]
    existing_nodes: List[Dict[str, Any]]

class UserPreferencesRequest(BaseModel):
    ai_mode_preferred: bool = True
    complexity_level: str = "standard"
    favorite_schools: List[str] = []

class DiagnosticCompletenessRequest(BaseModel):
    disease_name: str
    thinking_process: str
    patient_info: Optional[Dict[str, Any]] = None  # æ‚£è€…ä¿¡æ¯ï¼šå¹´é¾„ã€æ€§åˆ«ç­‰
    custom_templates: Dict[str, Any] = {}

@router.post("/generate_visual_decision_tree")
async def generate_visual_decision_tree(
    request: VisualDecisionTreeRequest
):
    """
    æ™ºèƒ½ç”Ÿæˆå†³ç­–æ ‘ï¼ˆæ··åˆæ¨¡å¼ï¼šAI+æ¨¡æ¿ï¼‰
    
    Args:
        request: åŒ…å«ç–¾ç—…åç§°å’Œç”Ÿæˆé€‰é¡¹çš„è¯·æ±‚
        
    Returns:
        æ™ºèƒ½å†³ç­–æ ‘æ•°æ®ï¼ˆåŒ…å«æ•°æ®æ¥æºæ ‡è¯†ï¼‰
    """
    try:
        logger.info(f"è¯·æ±‚æ™ºèƒ½ç”Ÿæˆå†³ç­–æ ‘: {request.disease_name}")
        
        try:
            # ğŸ” APIè·¯ç”±è°ƒè¯•ä¿¡æ¯
            print(f"ğŸ“¡ APIè·¯ç”±è°ƒè¯•:")
            print(f"  - ç–¾ç—…åç§°: {request.disease_name}")
            print(f"  - æ€ç»´è¿‡ç¨‹é•¿åº¦: {len(request.thinking_process.strip()) if request.thinking_process else 0}")
            print(f"  - use_ai: {request.use_ai}")
            print(f"  - è°ƒç”¨doctor_learning_system.generate_decision_paths...")
            
            # è°ƒç”¨æ–°çš„æ™ºèƒ½ç”Ÿæˆæ–¹æ³•
            generation_result = await doctor_learning_system.generate_decision_paths(
                disease_name=request.disease_name,
                thinking_process=request.thinking_process,
                use_ai=request.use_ai,  # ä½¿ç”¨å‰ç«¯ä¼ é€’çš„å‚æ•°
                include_tcm_analysis=request.include_tcm_analysis,
                complexity_level=request.complexity_level,
                enable_smart_branching=request.enable_smart_branching  # æ–°å¢æ™ºèƒ½åˆ†æ”¯å‚æ•°
            )
            
            print(f"ğŸ“¡ APIè·¯ç”±è¿”å›ç»“æœ:")
            print(f"  - source: {generation_result.get('source', 'MISSING')}")
            print(f"  - ai_generated: {generation_result.get('ai_generated', 'MISSING')}")
            print(f"  - user_thinking_used: {generation_result.get('user_thinking_used', 'MISSING')}")
            
            return {
                "success": True,
                "message": f"{generation_result['source'].upper()}ç”Ÿæˆå®Œæˆ",
                "data": generation_result,
                "ai_status": {
                    "enabled": doctor_learning_system.ai_enabled,
                    "source": generation_result['source'],
                    "generation_time": generation_result.get('generation_time', 'æœªçŸ¥')
                }
            }
            
        except Exception as ai_error:
            logger.error(f"æ™ºèƒ½ç”Ÿæˆå†³ç­–æ ‘å¤±è´¥: {ai_error}")
            # AIå¤±è´¥æ—¶ç›´æ¥è¿”å›é”™è¯¯ï¼Œä¸ä½¿ç”¨ç¡¬ç¼–ç æ¨¡æ¿
            return {
                "success": False,
                "message": f"AIç”Ÿæˆå¤±è´¥: {str(ai_error)}",
                "data": None,
                "ai_status": {
                    "enabled": doctor_learning_system.ai_enabled,
                    "source": "ai_failed",
                    "error": str(ai_error)
                }
            }
        
    except Exception as e:
        logger.error(f"ç”Ÿæˆå†³ç­–æ ‘å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"ç”Ÿæˆå¤±è´¥: {str(e)}")

@router.post("/analyze_tree_tcm_theory")
async def analyze_tree_tcm_theory(
    request: TCMTheoryAnalysisRequest
):
    """
    ä½¿ç”¨AIè¿›è¡Œä¸­åŒ»ç†è®ºåˆ†æï¼ˆæ··åˆæ¨¡å¼ï¼‰
    
    Args:
        request: åŒ…å«å†³ç­–æ ‘æ•°æ®çš„åˆ†æè¯·æ±‚
        
    Returns:
        ä¸­åŒ»ç†è®ºåˆ†æç»“æœå’Œæ”¹è¿›å»ºè®®
    """
    try:
        logger.info(f"è¯·æ±‚TCMç†è®ºåˆ†æ: {request.disease_name}")
        
        try:
            # ä¼˜å…ˆå°è¯•AIåˆ†æ
            analysis_result = await doctor_learning_system.analyze_tcm_theory_with_ai(
                tree_data=request.tree_data,
                disease_name=request.disease_name
            )
            
            # æ ¼å¼åŒ–åˆ†æç»“æœä¸ºå‰ç«¯æ˜¾ç¤ºæ ¼å¼
            formatted_analysis = format_tcm_analysis_for_display(analysis_result)
            formatted_suggestions = format_tcm_suggestions_for_display(analysis_result)
            
            return {
                "success": True,
                "message": f"AIç†è®ºåˆ†æå®Œæˆï¼ˆ{doctor_learning_system.ai_enabled and 'AI' or 'æ¨¡æ¿'}æ¨¡å¼ï¼‰",
                "data": {
                    "analysis": formatted_analysis,
                    "suggestions": formatted_suggestions,
                    "source": "ai" if doctor_learning_system.ai_enabled else "template",
                    "ai_enabled": doctor_learning_system.ai_enabled
                }
            }
            
        except Exception as ai_error:
            logger.error(f"TCMç†è®ºåˆ†æå¤±è´¥: {ai_error}")
            # è¿”å›é»˜è®¤åˆ†æ
            default_analysis = create_default_tcm_analysis(request.disease_name)
            formatted_default_analysis = format_tcm_analysis_for_display(default_analysis)
            formatted_default_suggestions = format_tcm_suggestions_for_display(default_analysis)
            
            return {
                "success": True,
                "message": "ç†è®ºåˆ†æå®Œæˆï¼ˆæ¨¡æ¿æ¨¡å¼ï¼‰",
                "data": {
                    "analysis": formatted_default_analysis,
                    "suggestions": formatted_default_suggestions,
                    "source": "template_fallback",
                    "ai_enabled": False,
                    "error": str(ai_error)
                }
            }
        
    except Exception as e:
        logger.error(f"TCMç†è®ºåˆ†æå¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"åˆ†æå¤±èµ…: {str(e)}")

@router.post("/detect_missing_logic")
async def detect_missing_logic(
    request: MissingLogicDetectionRequest
):
    """
    æ£€æµ‹å†³ç­–æ ‘é—æ¼çš„è¯Šç–—é€»è¾‘ - ç®€åŒ–ç‰ˆæœ¬
    
    ç›´æ¥è¿”å›é¢„å®šä¹‰çš„å»ºè®®ï¼Œé¿å…å¤æ‚çš„AIè°ƒç”¨å¯¼è‡´å¡æ­»
    """
    try:
        logger.info(f"è¯·æ±‚é—æ¼é€»è¾‘æ£€æµ‹: {request.disease_name}")
        
        # ç›´æ¥è¿”å›ç®€åŒ–çš„é—æ¼é€»è¾‘åˆ†æï¼Œé¿å…å¤æ‚å¤„ç†
        detection_data = create_simple_missing_logic_analysis(request.disease_name, request.existing_nodes)
        
        return {
            "success": True,
            "message": "é—æ¼é€»è¾‘æ£€æµ‹å®Œæˆ",
            "data": detection_data
        }
        
    except Exception as e:
        logger.error(f"é—æ¼é€»è¾‘æ£€æµ‹å¤±è´¥: {e}")
        # ç¡®ä¿å§‹ç»ˆè¿”å›æœ‰æ•ˆå“åº”
        return {
            "success": True,
            "message": "æ£€æµ‹å®Œæˆï¼ˆåŸºç¡€åˆ†æï¼‰",
            "data": {
                "missing_analyses": [
                    {
                        "category": "åŸºç¡€åˆ†æ",
                        "items": [
                            {
                                "type": "general_suggestion",
                                "content": "å»ºè®®å®Œå–„å†³ç­–æ ‘",
                                "description": "å½“å‰å†³ç­–æ ‘å¯ä»¥è¿›ä¸€æ­¥ç»†åŒ–",
                                "importance": "medium"
                            }
                        ]
                    }
                ],
                "quick_additions": [
                    {
                        "title": "åŸºç¡€è¡¥å……",
                        "path_data": {"steps": [{"type": "condition", "content": "è¡¥å……åˆ¤æ–­æ¡ä»¶"}]}
                    }
                ]
            }
        }

def create_simple_missing_logic_analysis(disease_name: str, existing_nodes: List[Dict[str, Any]]) -> Dict[str, Any]:
    """åˆ›å»ºç®€åŒ–çš„é—æ¼é€»è¾‘åˆ†æï¼Œé¿å…å¤æ‚å¤„ç†"""
    
    # è·å–ç°æœ‰èŠ‚ç‚¹çš„è¯å‹å’Œæ¡ä»¶
    existing_diagnoses = set()
    existing_conditions = set()
    
    for node in existing_nodes:
        if node.get("type") == "diagnosis":
            existing_diagnoses.add(node.get("name", ""))
        elif node.get("type") == "condition":
            existing_conditions.add(node.get("name", ""))
    
    # å¸¸è§è¯å‹å’Œæ¡ä»¶åº“
    disease_knowledge = {
        "å¤±çœ ": {
            "syndromes": ["å¿ƒç«æ—ºç››è¯", "å¿ƒè„¾ä¸¤è™šè¯", "è‚éƒåŒ–ç«è¯", "å¿ƒè‚¾ä¸äº¤è¯", "ç—°çƒ­æ‰°å¿ƒè¯"],
            "conditions": ["èˆŒçº¢è‹”é»„", "èˆŒæ·¡è‹”ç™½", "èƒ¸èƒèƒ€æ»¡", "äº”å¿ƒçƒ¦çƒ­", "ç—°å¤šå’³å—½"],
            "formulas": ["é»„è¿é˜¿èƒ¶æ±¤", "å½’è„¾æ±¤", "é€é¥æ•£", "å¤©ç‹è¡¥å¿ƒä¸¹", "æ¸©èƒ†æ±¤"]
        },
        "èƒƒç—›": {
            "syndromes": ["è„¾èƒƒè™šå¯’è¯", "è‚æ°”çŠ¯èƒƒè¯", "èƒƒé˜´ä¸è¶³è¯", "æ¹¿çƒ­ä¸­é˜»è¯", "ç˜€è¡€é˜»ç»œè¯"],
            "conditions": ["å–œæ¸©å–œæŒ‰", "èƒ€ç—›æ‹’æŒ‰", "å£å¹²å’½ç‡¥", "å£è‹¦é»è…»", "åˆºç—›å›ºå®š"],
            "formulas": ["ç†ä¸­æ±¤", "æŸ´èƒ¡ç–è‚æ•£", "éº¦é—¨å†¬æ±¤", "é»„èŠ©æ±¤", "å¤±ç¬‘æ•£"]
        },
        "å¤´ç—›": {
            "syndromes": ["é£å¯’å¤´ç—›", "é£çƒ­å¤´ç—›", "è‚é˜³ä¸Šäº¢", "ç—°æµŠå¤´ç—›", "è¡€ç˜€å¤´ç—›"],
            "conditions": ["æ¶å¯’å‘çƒ­", "å’½çº¢å£å¹²", "çœ©æ™•è€³é¸£", "å¤´é‡å¦‚è£¹", "ç—›å¦‚é”¥åˆº"],
            "formulas": ["å·èŠèŒ¶è°ƒæ•£", "æ¡‘èŠé¥®", "å¤©éº»é’©è—¤é¥®", "åŠå¤ç™½æœ¯å¤©éº»æ±¤", "è¡€åºœé€ç˜€æ±¤"]
        }
    }
    
    current_disease = disease_knowledge.get(disease_name, {
        "syndromes": [f"{disease_name}è™šè¯", f"{disease_name}å®è¯", f"{disease_name}è™šå®å¤¹æ‚è¯"],
        "conditions": ["èˆŒè±¡å˜åŒ–", "è„‰è±¡ç‰¹ç‚¹", "ä½“è´¨å› ç´ "],
        "formulas": ["è¡¥ç›Šæ–¹å‰‚", "æ¸…çƒ­æ–¹å‰‚", "è°ƒå’Œæ–¹å‰‚"]
    })
    
    # æ‰¾å‡ºé—æ¼çš„å†…å®¹
    missing_syndromes = [s for s in current_disease["syndromes"] if s not in existing_diagnoses]
    missing_conditions = [c for c in current_disease["conditions"] if c not in existing_conditions]
    
    missing_analyses = []
    
    if missing_syndromes:
        missing_analyses.append({
            "category": "è¯å‹åˆ†æ",
            "items": [
                {
                    "type": "missing_syndrome",
                    "content": syndrome,
                    "description": f"{disease_name}çš„{syndrome}æ˜¯å¸¸è§è¯å‹ï¼Œå»ºè®®è¡¥å……",
                    "importance": "high",
                    "suggested_addition": {
                        "step_type": "diagnosis",
                        "step_content": syndrome
                    }
                } for syndrome in missing_syndromes[:3]
            ]
        })
    
    if missing_conditions:
        missing_analyses.append({
            "category": "åˆ¤æ–­æ¡ä»¶",
            "items": [
                {
                    "type": "missing_condition",
                    "content": condition,
                    "description": f"å»ºè®®å¢åŠ {condition}çš„ä¸´åºŠè§‚å¯Ÿ",
                    "importance": "medium",
                    "suggested_addition": {
                        "step_type": "condition",
                        "step_content": condition
                    }
                } for condition in missing_conditions[:3]
            ]
        })
    
    quick_additions = [
        {
            "title": "è¡¥å……é‰´åˆ«è¯Šæ–­",
            "path_data": {
                "steps": [
                    {"type": "condition", "content": "å…¸å‹ç—‡çŠ¶ç‰¹å¾"},
                    {"type": "diagnosis", "content": f"ç¡®è¯Š{disease_name}"}
                ]
            }
        },
        {
            "title": "æ·»åŠ é¢„åè¯„ä¼°",
            "path_data": {
                "steps": [
                    {"type": "condition", "content": "æ²»ç–—æ•ˆæœè¯„ä¼°"},
                    {"type": "treatment", "content": "è°ƒæ•´æ²»ç–—æ–¹æ¡ˆ"}
                ]
            }
        }
    ]
    
    return {
        "missing_analyses": missing_analyses,
        "quick_additions": quick_additions
    }

def create_default_visual_tree(disease_name: str) -> Dict[str, Any]:
    """åˆ›å»ºé»˜è®¤çš„å¯è§†åŒ–å†³ç­–æ ‘æ•°æ®"""
    return {
        "paths": [
            {
                "id": f"{disease_name}_path_1",
                "title": f"{disease_name}å®çƒ­è¯è·¯å¾„",
                "steps": [
                    {"type": "symptom", "content": f"{disease_name}"},
                    {"type": "condition", "content": "èˆŒçº¢è‹”é»„", "options": ["æ˜¯", "å¦"]},
                    {"type": "diagnosis", "content": "å®çƒ­è¯"},
                    {"type": "treatment", "content": "æ¸…çƒ­æ³•"},
                    {"type": "formula", "content": "é»„è¿è§£æ¯’æ±¤"}
                ],
                "keywords": [disease_name, "èˆŒçº¢", "è‹”é»„", "å®çƒ­"],
                "tcm_theory": "å®åˆ™æ³»ä¹‹ï¼Œçƒ­è€…æ¸…ä¹‹"
            },
            {
                "id": f"{disease_name}_path_2", 
                "title": f"{disease_name}è™šå¯’è¯è·¯å¾„",
                "steps": [
                    {"type": "symptom", "content": f"{disease_name}"},
                    {"type": "condition", "content": "èˆŒæ·¡è‹”ç™½", "options": ["æ˜¯", "å¦"]},
                    {"type": "diagnosis", "content": "è™šå¯’è¯"},
                    {"type": "treatment", "content": "æ¸©è¡¥æ³•"},
                    {"type": "formula", "content": "ç†ä¸­æ±¤"}
                ],
                "keywords": [disease_name, "èˆŒæ·¡", "è‹”ç™½", "è™šå¯’"],
                "tcm_theory": "è™šåˆ™è¡¥ä¹‹ï¼Œå¯’è€…çƒ­ä¹‹"
            }
        ],
        "suggested_layout": {
            "auto_arrange": True,
            "spacing": {"horizontal": 300, "vertical": 150}
        }
    }

def format_tcm_analysis_for_display(analysis_data: Dict[str, Any]) -> str:
    """å°†TCMåˆ†ææ•°æ®æ ¼å¼åŒ–ä¸ºå‰ç«¯æ˜¾ç¤ºæ ¼å¼"""
    try:
        theory_analysis = analysis_data.get("theory_analysis", {})
        score = theory_analysis.get("overall_score", 75)
        strengths = theory_analysis.get("strengths", [])
        weaknesses = theory_analysis.get("weaknesses", [])
        basis = theory_analysis.get("theoretical_basis", "")
        
        display_text = f"""
        <div style="margin-bottom: 15px;">
            <h3 style="color: #1e40af; margin: 0 0 10px 0;">ğŸ“Š ç†è®ºåˆç†æ€§è¯„åˆ†: {score}/100</h3>
            
            <div style="background: #f0f9ff; padding: 12px; border-radius: 6px; margin-bottom: 10px;">
                <strong style="color: #059669;">âœ… ç†è®ºä¼˜åŠ¿:</strong><br>
                {('<br>'.join([f'â€¢ {s}' for s in strengths]) if strengths else 'â€¢ åŸºæœ¬ç¬¦åˆä¸­åŒ»ç†è®º')}
            </div>
            
            <div style="background: #fef3c7; padding: 12px; border-radius: 6px; margin-bottom: 10px;">
                <strong style="color: #d97706;">âš ï¸ æ”¹è¿›å»ºè®®:</strong><br>
                {('<br>'.join([f'â€¢ {w}' for w in weaknesses]) if weaknesses else 'â€¢ å¯è¿›ä¸€æ­¥å®Œå–„ç†è®ºç»†èŠ‚')}
            </div>
            
            <div style="background: #f3f4f6; padding: 12px; border-radius: 6px; font-size: 11px;">
                <strong>ğŸ“š ç†è®ºä¾æ®:</strong><br>
                {basis}
            </div>
        </div>
        """
        
        return display_text.strip()
        
    except Exception as e:
        return f"<div style='color: #ef4444;'>ç†è®ºåˆ†ææ ¼å¼åŒ–å¤±è´¥: {str(e)}</div>"

def format_tcm_suggestions_for_display(analysis_data: Dict[str, Any]) -> Dict[str, Any]:
    """å°†TCMå»ºè®®æ•°æ®æ ¼å¼åŒ–ä¸ºå‰ç«¯æ˜¾ç¤ºæ ¼å¼"""
    try:
        suggestions_data = analysis_data.get("improvement_suggestions", [])
        supplements_data = analysis_data.get("knowledge_supplements", [])
        
        missing_differentials = []
        additional_conditions = []
        theoretical_basis = ""
        
        for suggestion in suggestions_data:
            if suggestion.get("type") == "theory_enhancement":
                missing_differentials.append(suggestion.get("description", ""))
            elif suggestion.get("type") == "differential_diagnosis":
                additional_conditions.append(suggestion.get("description", ""))
        
        if supplements_data:
            theoretical_basis = "; ".join([s.get("content", "") for s in supplements_data])
        
        return {
            "missing_differentials": missing_differentials or ["å»ºè®®åŠ å¼ºç†è®ºåˆ†æ"],
            "additional_conditions": additional_conditions or ["å®Œå–„åˆ¤æ–­æ¡ä»¶"],
            "theoretical_basis": theoretical_basis or "åŸºäºä¼ ç»Ÿä¸­åŒ»ç†è®ºä½“ç³»"
        }
        
    except Exception as e:
        return {
            "missing_differentials": ["æ ¼å¼åŒ–å¤±è´¥ï¼Œè¯·é‡è¯•"],
            "additional_conditions": ["æ•°æ®å¤„ç†å¼‚å¸¸"],
            "theoretical_basis": "æ— æ³•è·å–ç†è®ºä¾æ®"
        }

def create_default_tcm_analysis(disease_name: str) -> Dict[str, Any]:
    """åˆ›å»ºé»˜è®¤çš„TCMç†è®ºåˆ†æ - ä¾§é‡ç†è®ºè¯„ä¼°"""
    
    # ç†è®ºåˆ†æä¾§é‡äºè¯„ä¼°å†³ç­–æ ‘çš„ä¸­åŒ»ç†è®ºåˆç†æ€§
    theory_knowledge = {
        "å¤±çœ ": {
            "strengths": ["ä½“ç°äº†å¿ƒä¸»ç¥æ˜çš„ç†è®º", "è€ƒè™‘äº†è™šå®å¯’çƒ­çš„è¾¨è¯", "æ–¹è¯é€‰æ‹©ç¬¦åˆç—…æœº"],
            "weaknesses": ["å¯åŠ å¼ºè„è…‘å…³ç³»åˆ†æ", "éœ€è¡¥å……æ—¶é—´åŒ»å­¦ç†è®º", "å®œç»†åŒ–ä½“è´¨è¾¨è¯†"],
            "basis": "å¤±çœ ä¸€è¯ï¼Œè™½è´£ä¹‹äºå¿ƒï¼Œç„¶äº”è„çš†èƒ½è‡´ä¹‹ã€‚å¿ƒè‚¾ä¸äº¤ã€è‚éƒåŒ–ç«ã€è„¾è™šä¸è¿çš†ä¸ºå¸¸è§ç—…æœº",
            "score": 82
        },
        "èƒƒç—›": {
            "strengths": ["ä½“ç°äº†è„¾èƒƒä¸ºåå¤©ä¹‹æœ¬", "è€ƒè™‘äº†è‚æœ¨å…‹åœŸç†è®º", "æ³¨æ„äº†å¯’çƒ­è™šå®"],
            "weaknesses": ["å¯è¡¥å……å…­è…‘ä»¥é€šä¸ºç”¨", "éœ€åŠ å¼ºæƒ…å¿—å› ç´ ", "å®œé‡è§†é¥®é£Ÿè°ƒæŠ¤"],
            "basis": "èƒƒç—›å¤šå› é¥®é£Ÿã€æƒ…å¿—ã€æ„Ÿå—å¤–é‚ªç­‰å¯¼è‡´èƒƒå¤±å’Œé™ã€‚è‚èƒƒä¸å’Œæœ€ä¸ºå¸¸è§",
            "score": 78
        }
    }
    
    current_theory = theory_knowledge.get(disease_name, {
        "strengths": ["åŸºæœ¬è¾¨è¯æ€è·¯æ¸…æ™°", "ç—‡çŠ¶ä¸æ²»æ³•å¯¹åº”", "æ–¹è¯é€‰æ‹©åˆç†"],
        "weaknesses": ["å¯æ·±åŒ–ç—…æœºåˆ†æ", "éœ€è¡¥å……ç»å…¸ä¾æ®", "å®œåŠ å¼ºä¸ªä½“åŒ–"],
        "basis": f"åŸºäºä¸­åŒ»{disease_name}çš„ä¼ ç»Ÿè¾¨è¯è®ºæ²»ç†è®ºä½“ç³»",
        "score": 75
    })
    
    return {
        "theory_analysis": {
            "overall_score": current_theory["score"],
            "strengths": current_theory["strengths"],
            "weaknesses": current_theory["weaknesses"],
            "theoretical_basis": current_theory["basis"]
        },
        "improvement_suggestions": [
            {
                "type": "theory_enhancement",
                "description": f"åŠ å¼º{disease_name}çš„ç—…æœºç†è®ºé˜è¿°",
                "priority": "high"
            },
            {
                "type": "differential_diagnosis", 
                "description": "è¡¥å……ç»å…¸æ–¹ä¹¦ç†è®ºä¾æ®",
                "priority": "medium"
            },
            {
                "type": "individualization",
                "description": "ç»†åŒ–è„è…‘å…³ç³»åˆ†æ",
                "priority": "medium"
            }
        ],
        "knowledge_supplements": [
            {
                "topic": "ç—…æœºç†è®º",
                "content": f"{disease_name}çš„åŸºæœ¬ç—…æœºå’Œç—…ç†ç”Ÿç†",
                "source": "ä¸­åŒ»å†…ç§‘å­¦"
            },
            {
                "topic": "æ–¹å‰‚é…ä¼",
                "content": f"æ²»ç–—{disease_name}çš„ç»å…¸æ–¹å‰‚åŠå…¶é…ä¼åŸç†",
                "source": "æ–¹å‰‚å­¦"
            },
            {
                "topic": "ä¸´åºŠç»éªŒ",
                "content": f"ååŒ»æ²»ç–—{disease_name}çš„ç‰¹è‰²ç»éªŒ",
                "source": "ä¸´åºŠå®è·µ"
            }
        ]
    }

def create_default_missing_logic_analysis(disease_name: str) -> Dict[str, Any]:
    """åˆ›å»ºé»˜è®¤çš„é—æ¼é€»è¾‘åˆ†æ"""
    return {
        "missing_analyses": [
            {
                "category": "è¯å‹åˆ†æ",
                "items": [
                    {
                        "type": "missing_syndrome",
                        "content": f"{disease_name}çš„å°‘è§è¯å‹",
                        "description": "å¯èƒ½é—æ¼çš„ç‰¹æ®Šè¯å€™è¡¨ç°",
                        "importance": "medium",
                        "suggested_addition": {
                            "step_type": "diagnosis",
                            "step_content": "ç‰¹æ®Šè¯å‹è¯Šæ–­"
                        }
                    }
                ]
            },
            {
                "category": "é‰´åˆ«è¯Šæ–­",
                "items": [
                    {
                        "type": "differential_diagnosis",
                        "content": "ç›¸å…³ç–¾ç—…é‰´åˆ«",
                        "description": "éœ€è¦ä¸ç±»ä¼¼ç–¾ç—…è¿›è¡Œé‰´åˆ«",
                        "importance": "high",
                        "suggested_addition": {
                            "step_type": "condition",
                            "step_content": "é‰´åˆ«è¯Šæ–­è¦ç‚¹"
                        }
                    }
                ]
            }
        ],
        "quick_additions": [
            {
                "title": "è¡¥å……é‰´åˆ«è¯Šæ–­è·¯å¾„",
                "path_data": {
                    "steps": [
                        {"type": "condition", "content": "æ˜¯å¦ä¼´æœ‰å…¶ä»–ç—‡çŠ¶"},
                        {"type": "diagnosis", "content": "æ’é™¤ç›¸å…³ç–¾ç—…"}
                    ]
                }
            }
        ]
    }

@router.get("/user_preferences/{user_id}")
async def get_user_preferences(
    user_id: str,
    current_user: UserSession = Depends(get_current_user)
):
    """è·å–ç”¨æˆ·åå¥½è®¾ç½®"""
    try:
        # æƒé™æ£€æŸ¥ï¼šåªèƒ½è®¿é—®è‡ªå·±çš„åå¥½è®¾ç½®
        # ğŸ”§ ä¿®å¤ï¼šå…¼å®¹ç»Ÿä¸€è®¤è¯ç³»ç»Ÿ
        user_roles = getattr(current_user, 'roles', [getattr(current_user, 'role', None)])
        is_admin = any(role in ['admin', 'ADMIN', UserRole.ADMIN] for role in user_roles if role)

        if current_user.user_id != user_id and not is_admin:
            raise HTTPException(status_code=403, detail="æ— æƒé™è®¿é—®")
        
        preferences = doctor_learning_system.get_user_preferences(user_id)
        
        return {
            "success": True,
            "message": "è·å–ç”¨æˆ·åå¥½æˆåŠŸ",
            "data": preferences
        }
        
    except Exception as e:
        logger.error(f"è·å–ç”¨æˆ·åå¥½å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"è·å–å¤±è´¥: {str(e)}")

@router.post("/user_preferences/{user_id}")
async def save_user_preferences(
    user_id: str,
    request: UserPreferencesRequest,
    current_user: UserSession = Depends(get_current_user)
):
    """ä¿å­˜ç”¨æˆ·åå¥½è®¾ç½®"""
    try:
        # æƒé™æ£€æŸ¥ï¼šåªèƒ½ä¿®æ”¹è‡ªå·±çš„åå¥½è®¾ç½®
        # ğŸ”§ ä¿®å¤ï¼šå…¼å®¹ç»Ÿä¸€è®¤è¯ç³»ç»Ÿ
        user_roles = getattr(current_user, 'roles', [getattr(current_user, 'role', None)])
        is_admin = any(role in ['admin', 'ADMIN', UserRole.ADMIN] for role in user_roles if role)

        if current_user.user_id != user_id and not is_admin:
            raise HTTPException(status_code=403, detail="æ— æƒé™ä¿®æ”¹")
        
        preferences = {
            "ai_mode_preferred": request.ai_mode_preferred,
            "complexity_level": request.complexity_level,
            "favorite_schools": request.favorite_schools,
            "custom_templates": request.custom_templates
        }
        
        doctor_learning_system.save_user_preferences(user_id, preferences)
        
        return {
            "success": True,
            "message": "ç”¨æˆ·åå¥½ä¿å­˜æˆåŠŸ",
            "data": preferences
        }
        
    except Exception as e:
        logger.error(f"ä¿å­˜ç”¨æˆ·åå¥½å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"ä¿å­˜å¤±è´¥: {str(e)}")

@router.get("/ai_status")
async def get_ai_status():
    """è·å–AIåŠŸèƒ½çŠ¶æ€"""
    try:
        return {
            "success": True,
            "message": "AIçŠ¶æ€è·å–æˆåŠŸ",
            "data": {
                "ai_enabled": doctor_learning_system.ai_enabled,
                "ai_model": getattr(doctor_learning_system, 'ai_model', 'unknown'),
                "dashscope_available": DASHSCOPE_AVAILABLE,
                "learning_enabled": getattr(doctor_learning_system, 'learning_enabled', False),
                "features": {
                    "decision_tree_generation": doctor_learning_system.ai_enabled,
                    "theory_analysis": doctor_learning_system.ai_enabled,
                    "hybrid_mode": True,
                    "user_learning": getattr(doctor_learning_system, 'learning_enabled', False)
                }
            }
        }
        
    except Exception as e:
        logger.error(f"è·å–AIçŠ¶æ€å¤±è´¥: {e}")
        return {
            "success": False,
            "message": f"è·å–å¤±è´¥: {str(e)}",
            "data": {
                "ai_enabled": False,
                "error": str(e)
            }
        }

@router.post("/feedback/decision_tree/{tree_id}")
async def submit_decision_tree_feedback(
    tree_id: str,
    feedback_score: int,
    improvement_notes: str = "",
    current_user: UserSession = Depends(get_current_user)
):
    """æäº¤å†³ç­–æ ‘åé¦ˆç”¨äºå­¦ä¹ æ”¹è¿›"""
    try:
        if not (1 <= feedback_score <= 5):
            raise HTTPException(status_code=400, detail="è¯„åˆ†å¿…é¡»åœ¨1-5ä¹‹é—´")
        
        # è¿™é‡Œå¯ä»¥è®°å½•ç”¨æˆ·åé¦ˆåˆ°å­¦ä¹ æ•°æ®åº“
        # ç›®å‰ç®€åŒ–å¤„ç†
        logger.info(f"æ”¶åˆ°å†³ç­–æ ‘åé¦ˆ - ç”¨æˆ·: {current_user.user_id}, æ ‘ID: {tree_id}, è¯„åˆ†: {feedback_score}")
        
        return {
            "success": True,
            "message": "åé¦ˆæäº¤æˆåŠŸï¼Œæ„Ÿè°¢æ‚¨çš„å®è´µæ„è§ï¼",
            "data": {
                "feedback_id": f"fb_{tree_id}_{current_user.user_id}",
                "submitted_at": datetime.now().isoformat()
            }
        }
        
    except Exception as e:
        logger.error(f"æäº¤å†³ç­–æ ‘åé¦ˆå¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"æäº¤å¤±è´¥: {str(e)}")

@router.post("/analyze_diagnostic_completeness")
async def analyze_diagnostic_completeness(
    request: DiagnosticCompletenessRequest,
    current_user: UserSession = Depends(get_current_user)
):
    """
    æ™ºèƒ½åˆ†æè¯Šç–—æµç¨‹å®Œæ•´æ€§
    
    åˆ†æåŒ»ç”Ÿè¾“å…¥çš„è¯Šç–—æ€è·¯ï¼Œè¯†åˆ«ç¼ºå¤±çš„æ ‡å‡†è¯Šç–—è¦ç´ ï¼Œ
    å¹¶æä¾›æ™ºèƒ½è¡¥å……å»ºè®®
    """
    try:
        logger.info(f"è¯Šç–—æµç¨‹å®Œæ•´æ€§åˆ†æ - ç–¾ç—…: {request.disease_name}, ç”¨æˆ·: {current_user.user_id}")
        
        # è°ƒç”¨ååŒ»å­¦ä¹ ç³»ç»Ÿè¿›è¡Œå®Œæ•´æ€§åˆ†æ
        completeness_result = await doctor_learning_system._analyze_diagnostic_completeness(
            request.disease_name, 
            request.thinking_process
        )
        
        # æ·»åŠ æ‚£è€…ä¿¡æ¯è€ƒè™‘ï¼ˆå¦‚æœæä¾›ï¼‰
        if request.patient_info:
            age = request.patient_info.get("age")
            gender = request.patient_info.get("gender")
            
            # åŸºäºå¹´é¾„å’Œæ€§åˆ«è°ƒæ•´å»ºè®®
            if age:
                if age < 18:
                    completeness_result["recommendations"].append("å„¿ç«¥æ‚£è€…éœ€ç‰¹åˆ«æ³¨æ„è¯ç‰©å‰‚é‡è°ƒæ•´")
                elif age > 65:
                    completeness_result["recommendations"].append("è€å¹´æ‚£è€…éœ€è€ƒè™‘è„è…‘åŠŸèƒ½è¡°é€€ï¼Œç”¨è¯å®œæ¸©å’Œ")
            
            if gender:
                if gender == "å¥³":
                    completeness_result["recommendations"].append("å¥³æ€§æ‚£è€…éœ€è€ƒè™‘æœˆç»ã€å¦Šå¨ ç­‰ç”Ÿç†ç‰¹ç‚¹")
        
        # ç”Ÿæˆè¯¦ç»†çš„æ”¹è¿›å»ºè®®
        improvement_suggestions = []
        for missing_item in completeness_result["missing_items"]:
            suggestion = await _generate_item_specific_suggestion(
                missing_item, request.disease_name, request.thinking_process
            )
            improvement_suggestions.append(suggestion)
        
        return {
            "success": True,
            "message": f"è¯Šç–—æµç¨‹å®Œæ•´æ€§åˆ†æå®Œæˆ",
            "data": {
                "completeness_rate": completeness_result["completeness_rate"],
                "present_items": completeness_result["present_items"],
                "missing_items": completeness_result["missing_items"],
                "recommendations": completeness_result["recommendations"],
                "improvement_suggestions": improvement_suggestions,
                "patient_considerations": request.patient_info or {},
                "analysis_summary": {
                    "total_items": 9,
                    "present_count": len(completeness_result["present_items"]),
                    "missing_count": len(completeness_result["missing_items"]),
                    "completeness_level": _get_completeness_level(completeness_result["completeness_rate"])
                }
            }
        }
        
    except Exception as e:
        logger.error(f"è¯Šç–—æµç¨‹å®Œæ•´æ€§åˆ†æå¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"åˆ†æå¤±è´¥: {str(e)}")

async def _generate_item_specific_suggestion(missing_item: Dict[str, Any], disease_name: str, thinking_process: str) -> Dict[str, Any]:
    """ä¸ºç‰¹å®šç¼ºå¤±é¡¹ç›®ç”Ÿæˆå…·ä½“å»ºè®®"""
    item_key = missing_item["key"]
    
    # åŸºäºä¸åŒé¡¹ç›®ç±»å‹ç”Ÿæˆé’ˆå¯¹æ€§å»ºè®®
    suggestions_map = {
        "four_diagnosis": {
            "suggestion": f"å»ºè®®è¡¥å……{disease_name}çš„å…¸å‹èˆŒè„‰è±¡",
            "examples": ["èˆŒè´¨çº¢è‹”é»„åš", "è„‰è±¡å¼¦æ•°", "é¢è‰²èé»„", "å£°éŸ³ä½å¾®"],
            "importance": "high"
        },
        "pathogenesis": {
            "suggestion": f"å»ºè®®åˆ†æ{disease_name}çš„ç—…å› ç—…æœº",
            "examples": ["å¤–æ„Ÿé£é‚ª", "è„¾èƒƒè™šå¼±", "è‚æ°”éƒç»“", "è‚¾é˜³ä¸è¶³"],
            "importance": "high"
        },
        "modifications": {
            "suggestion": "å»ºè®®æ·»åŠ éšç—‡åŠ å‡æ–¹æ¡ˆ",
            "examples": ["ä¼´å‘çƒ­åŠ é“¶èŠ±ã€è¿ç¿˜", "ä¾¿ç§˜åŠ å¤§é»„ã€èŠ’ç¡", "å¤±çœ åŠ é…¸æ£ä»ã€é¾™éª¨"],
            "importance": "medium"
        },
        "prognosis_care": {
            "suggestion": "å»ºè®®æ·»åŠ é¢„åè°ƒç†æŒ‡å¯¼",
            "examples": ["é¥®é£Ÿè°ƒå…»", "æƒ…å¿—è°ƒæ‘„", "èµ·å±…æœ‰å¸¸", "é€‚åº¦è¿åŠ¨"],
            "importance": "medium"
        }
    }
    
    return suggestions_map.get(item_key, {
        "suggestion": f"å»ºè®®è¡¥å……{missing_item['description']}",
        "examples": [],
        "importance": "low"
    })

def _get_completeness_level(rate: float) -> str:
    """è·å–å®Œæ•´åº¦ç­‰çº§"""
    if rate >= 0.9:
        return "ä¼˜ç§€"
    elif rate >= 0.7:
        return "è‰¯å¥½"
    elif rate >= 0.5:
        return "ä¸€èˆ¬"
    else:
        return "éœ€æ”¹è¿›"

# ======================== æ–°å¢ï¼šè¯Šç–—ä¿¡æ¯æå–å’Œå¤„æ–¹ç”Ÿæˆ ========================

class PrescriptionExtractionRequest(BaseModel):
    """å¤„æ–¹æå–è¯·æ±‚"""
    thinking_process: str
    patient_age: Optional[int] = None  # æ‚£è€…å¹´é¾„
    patient_gender: Optional[str] = None  # æ‚£è€…æ€§åˆ« male/female
    patient_weight: Optional[float] = None  # æ‚£è€…ä½“é‡(kg)
    special_conditions: List[str] = []  # ç‰¹æ®Šæƒ…å†µï¼špregnancy, lactation, elderlyç­‰

@router.post("/extract_prescription_info")
async def extract_prescription_info(
    request: PrescriptionExtractionRequest
):
    """
    ä»è¯Šç–—æ€è·¯ä¸­æå–ç—…ç§ã€ç—…æƒ…ã€å¤„æ–¹ä¿¡æ¯ï¼Œå¹¶ç”Ÿæˆä¸ªæ€§åŒ–ç”¨é‡
    
    Args:
        request: åŒ…å«è¯Šç–—æ€è·¯å’Œæ‚£è€…ä¿¡æ¯çš„è¯·æ±‚
        
    Returns:
        æå–çš„è¯Šç–—ä¿¡æ¯å’Œä¸ªæ€§åŒ–å¤„æ–¹
    """
    try:
        logger.info(f"å¼€å§‹æå–è¯Šç–—ä¿¡æ¯ï¼Œæ€è·¯é•¿åº¦: {len(request.thinking_process)}")
        
        # è°ƒç”¨AIæå–ç»“æ„åŒ–ä¿¡æ¯
        extraction_result = await _extract_clinical_info_with_ai(
            request.thinking_process,
            request.patient_age,
            request.patient_gender,
            request.patient_weight,
            request.special_conditions
        )
        
        return {
            "success": True,
            "message": "è¯Šç–—ä¿¡æ¯æå–æˆåŠŸ",
            "data": extraction_result
        }
        
    except Exception as e:
        logger.error(f"è¯Šç–—ä¿¡æ¯æå–å¤±è´¥: {e}")
        return {
            "success": False,
            "message": f"æå–å¤±è´¥: {str(e)}",
            "data": None
        }

async def _extract_clinical_info_with_ai(
    thinking_process: str,
    patient_age: Optional[int],
    patient_gender: Optional[str],
    patient_weight: Optional[float],
    special_conditions: List[str]
) -> Dict[str, Any]:
    """ä½¿ç”¨AIæå–ä¸´åºŠä¿¡æ¯å¹¶ç”Ÿæˆä¸ªæ€§åŒ–å¤„æ–¹"""
    
    # æ„å»ºæ‚£è€…ä¿¡æ¯æè¿°
    patient_info = _build_patient_info_description(
        patient_age, patient_gender, patient_weight, special_conditions
    )
    
    # ğŸ”§ æ™ºèƒ½æ£€æµ‹ï¼šåˆ¤æ–­æ€è·¯ä¸­æ˜¯å¦å·²æ˜ç¡®äººç¾¤ç”¨è¯
    age_group_detected = _detect_age_group_in_thinking(thinking_process)
    
    # æ„å»ºAIæç¤ºè¯
    prompt = f"""
è¯·ä»ä»¥ä¸‹ä¸­åŒ»è¯Šç–—æ€è·¯ä¸­æå–ç»“æ„åŒ–ä¿¡æ¯ï¼Œå¹¶æ ¹æ®æ‚£è€…ç‰¹å¾ç”Ÿæˆä¸ªæ€§åŒ–å¤„æ–¹ï¼š

è¯Šç–—æ€è·¯ï¼š{thinking_process}

æ‚£è€…ä¿¡æ¯ï¼š{patient_info}
è¯Šç–—æ€è·¯åˆ†æï¼š{age_group_detected['description']}

è¯·æå–ä»¥ä¸‹ä¿¡æ¯å¹¶ä»¥JSONæ ¼å¼è¿”å›ï¼š
{{
    "disease_name": "ç—…ç§åç§°ï¼ˆä»æ€è·¯ä¸­æå–ï¼‰",
    "symptom_description": "ä¸»è¦ç—‡çŠ¶æè¿°ï¼ˆè¯¦ç»†åˆ—å‡ºæ‰€æœ‰ç—‡çŠ¶ï¼‰",
    "tongue_pulse": "èˆŒè„‰è±¡æè¿°",
    "syndrome_differentiation": "ä¸­åŒ»è¯å‹è¯Šæ–­",
    "treatment_principle": "æ²»ç–—æ–¹æ³•",
    "base_prescription": {{
        "name": "æ–¹å‰‚åç§°",
        "composition": [
            {{
                "herb_name": "è¯æåç§°",
                "standard_dose": "æˆäººæ ‡å‡†å‰‚é‡ï¼ˆå…‹ï¼‰",
                "current_dose": "å½“å‰æ‚£è€…æ¨èå‰‚é‡ï¼ˆå…‹ï¼‰",
                "function": "åŠŸæ•ˆä½œç”¨"
            }}
        ]
    }},
    "dosage_adjustments": {{
        "age_factor": "å¹´é¾„è°ƒæ•´è¯´æ˜",
        "gender_factor": "æ€§åˆ«è€ƒè™‘äº‹é¡¹",
        "weight_factor": "ä½“é‡è°ƒæ•´è¯´æ˜",
        "special_notes": "ç‰¹æ®Šæ³¨æ„äº‹é¡¹"
    }},
    "administration": {{
        "preparation": "ç…ç…®æ–¹æ³•",
        "dosage": "æœç”¨å‰‚é‡å’Œé¢‘æ¬¡",
        "course": "ç–—ç¨‹å»ºè®®",
        "precautions": "æ³¨æ„äº‹é¡¹"
    }}
}}

å‰‚é‡è°ƒæ•´åŸåˆ™ï¼ˆæ™ºèƒ½è¯†åˆ«æ¨¡å¼ï¼‰ï¼š
{_generate_dosage_adjustment_rules(age_group_detected, patient_age, patient_weight, special_conditions)}
"""

    try:
        # è°ƒç”¨AIç”Ÿæˆ
        response = await asyncio.to_thread(
            dashscope.Generation.call,
            model=AI_CONFIG.get('decision_tree_model', 'qwen-max'),
            prompt=prompt,
            result_format='message'
        )
        
        if response.status_code == 200:
            content = response.output.choices[0]['message']['content']
            
            # è§£æJSONå“åº”
            ai_result = _parse_prescription_json(content)
            
            return ai_result
        else:
            raise Exception(f"AIè°ƒç”¨å¤±è´¥: {response.message}")
            
    except Exception as e:
        logger.error(f"AIæå–å¤±è´¥: {e}")
        # è¿”å›åŸºç¡€è§£æç»“æœ
        return _basic_prescription_extraction(thinking_process, patient_age, patient_gender)

def _build_patient_info_description(
    age: Optional[int],
    gender: Optional[str],
    weight: Optional[float],
    special_conditions: List[str]
) -> str:
    """æ„å»ºæ‚£è€…ä¿¡æ¯æè¿°"""
    info_parts = []
    
    if age is not None:
        if age < 18:
            info_parts.append(f"å„¿ç«¥æ‚£è€…ï¼Œ{age}å²")
        elif age > 65:
            info_parts.append(f"è€å¹´æ‚£è€…ï¼Œ{age}å²")
        else:
            info_parts.append(f"æˆå¹´æ‚£è€…ï¼Œ{age}å²")
    
    if gender:
        gender_map = {"male": "ç”·æ€§", "female": "å¥³æ€§"}
        info_parts.append(gender_map.get(gender, gender))
    
    if weight is not None:
        if weight < 50:
            info_parts.append(f"ä½“é‡{weight}kgï¼ˆåè½»ï¼‰")
        elif weight > 80:
            info_parts.append(f"ä½“é‡{weight}kgï¼ˆåé‡ï¼‰")
        else:
            info_parts.append(f"ä½“é‡{weight}kg")
    
    if special_conditions:
        condition_map = {
            "pregnancy": "å¦Šå¨ æœŸ",
            "lactation": "å“ºä¹³æœŸ",
            "elderly": "é«˜é¾„",
            "diabetes": "ç³–å°¿ç—…",
            "hypertension": "é«˜è¡€å‹",
            "liver_disease": "è‚ç—…",
            "kidney_disease": "è‚¾ç—…"
        }
        special_desc = [condition_map.get(c, c) for c in special_conditions]
        info_parts.append(f"ç‰¹æ®Šæƒ…å†µï¼š{', '.join(special_desc)}")
    
    return "ï¼›".join(info_parts) if info_parts else "æ— ç‰¹æ®Šæƒ…å†µ"

def _parse_prescription_json(content: str) -> Dict[str, Any]:
    """è§£æAIè¿”å›çš„å¤„æ–¹JSON"""
    import re
    import json
    
    # å°è¯•å¤šç§JSONæå–æ¨¡å¼
    json_patterns = [
        r'```json\s*(\{[\s\S]*?\})\s*```',
        r'```\s*(\{[\s\S]*?\})\s*```',
        r'(\{[\s\S]*?\})'
    ]
    
    for pattern in json_patterns:
        json_match = re.search(pattern, content)
        if json_match:
            json_content = json_match.group(1)
            try:
                return json.loads(json_content)
            except json.JSONDecodeError:
                continue
    
    # å¦‚æœJSONè§£æå¤±è´¥ï¼Œè¿”å›åŸºç¡€ç»“æ„
    return {
        "disease_name": "ä¿¡æ¯æå–å¤±è´¥",
        "symptom_description": content[:200] + "..." if len(content) > 200 else content,
        "error": "JSONè§£æå¤±è´¥ï¼Œè¯·æ£€æŸ¥AIå“åº”æ ¼å¼"
    }

def _basic_prescription_extraction(
    thinking_process: str,
    age: Optional[int],
    gender: Optional[str]
) -> Dict[str, Any]:
    """åŸºç¡€çš„å¤„æ–¹ä¿¡æ¯æå–ï¼ˆå½“AIå¤±è´¥æ—¶çš„å¤‡ç”¨æ–¹æ¡ˆï¼‰"""
    import re
    
    # åŸºç¡€ä¿¡æ¯æå–
    disease_match = re.search(r'(\w+ä¸\w+|\w+ç—…|\w+ç—‡)', thinking_process)
    disease_name = disease_match.group(1) if disease_match else "æœªæ˜ç¡®ç—…å"
    
    # ç—‡çŠ¶æå–
    symptom_patterns = [
        r'ç—‡è§[:ï¼š]([^ã€‚]+)',
        r'è¡¨ç°ä¸º([^ã€‚]+)',
        r'ç—‡çŠ¶([^ã€‚]+)'
    ]
    symptoms = []
    for pattern in symptom_patterns:
        matches = re.findall(pattern, thinking_process)
        symptoms.extend(matches)
    
    # æ–¹å‰‚æå–
    prescription_match = re.search(r'æ–¹è¯[:ï¼š]([^ã€‚]+)', thinking_process)
    prescription_name = prescription_match.group(1).strip() if prescription_match else "æœªæ˜ç¡®æ–¹å‰‚"
    
    return {
        "disease_name": disease_name,
        "symptom_description": "ï¼Œ".join(symptoms) if symptoms else "ç—‡çŠ¶ä¿¡æ¯æå–å¤±è´¥",
        "base_prescription": {
            "name": prescription_name,
            "composition": []
        },
        "note": "åŸºç¡€æå–ç»“æœï¼Œå»ºè®®æ‰‹åŠ¨è¡¥å……"
    }

# ======================== åŒ»ç”Ÿæ€ç»´åº“åŠŸèƒ½ ========================

class ClinicalPatternRequest(BaseModel):
    """ä¸´åºŠæ¨¡å¼ä¿å­˜è¯·æ±‚"""
    disease_name: str
    thinking_process: str
    tree_structure: Dict[str, Any]
    clinical_patterns: Dict[str, Any]
    doctor_expertise: Dict[str, Any]

@router.post("/save_clinical_pattern")
async def save_clinical_pattern(
    request: ClinicalPatternRequest,
    current_user: UserSession = Depends(get_current_user)
):
    """
    ä¿å­˜ä¸´åºŠå†³ç­–æ¨¡å¼åˆ°åŒ»ç”Ÿæ€ç»´åº“
    
    Args:
        request: ä¸´åºŠæ¨¡å¼æ•°æ®
        current_user: å½“å‰ç”¨æˆ·ä¼šè¯
        
    Returns:
        ä¿å­˜ç»“æœ
    """
    try:
        # ğŸ”§ ä¿®å¤ï¼šç»Ÿä¸€è®¤è¯ç³»ç»Ÿä½¿ç”¨ roles (List[str])ï¼Œè€Œé role
        roles = getattr(current_user, 'roles', [getattr(current_user, 'role', None)])
        if isinstance(roles, str):
            roles = [roles]

        logger.info(f"åŒ»ç”Ÿæ€ç»´åº“ä¿å­˜è¯·æ±‚ - ç”¨æˆ·: {current_user.user_id}, è§’è‰²: {roles}")

        # ğŸ” æƒé™éªŒè¯ï¼šç¡®ä¿æ˜¯åŒ»ç”Ÿç”¨æˆ·
        # æ£€æŸ¥æ˜¯å¦æœ‰DOCTORæˆ–ADMINè§’è‰²
        has_doctor_role = any(role in ['DOCTOR', 'ADMIN', UserRole.DOCTOR, UserRole.ADMIN] for role in roles if role)

        if not has_doctor_role:
            # ğŸ”§ ä¸´æ—¶è§£å†³æ–¹æ¡ˆï¼šå¦‚æœæ˜¯åŒ¿åç”¨æˆ·ï¼Œå°è¯•åˆ›å»ºä¸´æ—¶åŒ»ç”Ÿèº«ä»½
            is_anonymous = any(role in ['ANONYMOUS', UserRole.ANONYMOUS] for role in roles if role)
            if is_anonymous:
                doctor_id = await _create_or_get_temp_doctor_identity(request.disease_name)
                logger.info(f"ä¸ºåŒ¿åç”¨æˆ·åˆ›å»ºä¸´æ—¶åŒ»ç”Ÿèº«ä»½: {doctor_id}")
            else:
                raise HTTPException(
                    status_code=403,
                    detail="ä»…åŒ»ç”Ÿç”¨æˆ·å¯ä¿å­˜ä¸´åºŠå†³ç­–æ¨¡å¼åˆ°æ€ç»´åº“"
                )
        else:
            doctor_id = current_user.user_id
            logger.info(f"âœ… ä½¿ç”¨åŒ»ç”Ÿç”¨æˆ·IDä¿å­˜å†³ç­–æ ‘: {doctor_id}")
        
        # ğŸ—„ï¸ ä¿å­˜åˆ°æ•°æ®åº“
        pattern_data = {
            "doctor_id": doctor_id,
            "disease_name": request.disease_name,
            "thinking_process": request.thinking_process,
            "tree_structure": json.dumps(request.tree_structure),
            "clinical_patterns": json.dumps(request.clinical_patterns),
            "doctor_expertise": json.dumps(request.doctor_expertise),
            "usage_count": 0,
            "created_at": datetime.now().isoformat(),
            "updated_at": datetime.now().isoformat()
        }
        
        pattern_id = await _save_pattern_to_database(pattern_data)
        
        # ğŸ“Š åˆ†ææ¨¡å¼ç±»å‹
        pattern_type = _analyze_pattern_type(request.clinical_patterns, request.doctor_expertise)
        
        logger.info(f"ä¸´åºŠæ¨¡å¼ä¿å­˜æˆåŠŸ: pattern_id={pattern_id}, doctor_id={doctor_id}")
        
        return {
            "success": True,
            "message": f"ä¸´åºŠå†³ç­–æ¨¡å¼å·²æˆåŠŸä¿å­˜åˆ°åŒ»ç”Ÿ {doctor_id} çš„æ€ç»´åº“",
            "data": {
                "pattern_id": pattern_id,
                "doctor_id": doctor_id,
                "pattern_type": pattern_type,
                "disease_name": request.disease_name,
                "saved_at": datetime.now().isoformat()
            }
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ä¿å­˜ä¸´åºŠæ¨¡å¼å¤±è´¥: {e}")
        return {
            "success": False,
            "message": f"ä¿å­˜å¤±è´¥: {str(e)}"
        }

# ======================== æ€ç»´åº“æŸ¥è¯¢åŠŸèƒ½ ========================

@router.get("/get_doctor_patterns/{doctor_id}")
async def get_doctor_clinical_patterns(
    doctor_id: str,
    disease_name: Optional[str] = None,
    current_user: UserSession = Depends(get_current_user)
):
    """
    è·å–åŒ»ç”Ÿçš„ä¸´åºŠå†³ç­–æ¨¡å¼
    
    Args:
        doctor_id: åŒ»ç”ŸID
        disease_name: ç–¾ç—…åç§°ï¼ˆå¯é€‰ï¼Œç”¨äºç²¾ç¡®åŒ¹é…ï¼‰
        current_user: å½“å‰ç”¨æˆ·ä¼šè¯
        
    Returns:
        åŒ»ç”Ÿçš„ä¸´åºŠå†³ç­–æ¨¡å¼åˆ—è¡¨
    """
    try:
        logger.info(f"è·å–åŒ»ç”Ÿ {doctor_id} çš„ä¸´åºŠæ¨¡å¼")
        
        # ğŸ—„ï¸ ä»æ•°æ®åº“æŸ¥è¯¢ä¸´åºŠæ¨¡å¼
        db_path = "/opt/tcm-ai/data/user_history.sqlite"
        
        with sqlite3.connect(db_path) as conn:
            conn.row_factory = sqlite3.Row
            
            if disease_name:
                # ç²¾ç¡®åŒ¹é…ç–¾ç—…åç§°
                query = """
                    SELECT * FROM doctor_clinical_patterns 
                    WHERE doctor_id = ? AND disease_name = ?
                    ORDER BY created_at DESC
                """
                params = (doctor_id, disease_name)
            else:
                # è·å–æ‰€æœ‰æ¨¡å¼
                query = """
                    SELECT * FROM doctor_clinical_patterns 
                    WHERE doctor_id = ?
                    ORDER BY created_at DESC
                """
                params = (doctor_id,)
            
            patterns = conn.execute(query, params).fetchall()
            
            patterns_data = []
            for pattern in patterns:
                pattern_data = {
                    "pattern_id": pattern["id"],  # ğŸ”§ ä¿®å¤ï¼šæ•°æ®åº“åˆ—åæ˜¯ idï¼Œä¸æ˜¯ pattern_id
                    "doctor_id": pattern["doctor_id"],
                    "disease_name": pattern["disease_name"],
                    "thinking_process": pattern["thinking_process"],
                    "tree_structure": json.loads(pattern["tree_structure"]) if pattern["tree_structure"] else {},
                    "clinical_patterns": json.loads(pattern["clinical_patterns"]) if pattern["clinical_patterns"] else {},
                    "doctor_expertise": json.loads(pattern["doctor_expertise"]) if pattern["doctor_expertise"] else {},
                    "usage_count": pattern["usage_count"],
                    "created_at": pattern["created_at"],
                    "updated_at": pattern["updated_at"]
                }
                patterns_data.append(pattern_data)
        
        return {
            "success": True,
            "message": f"æ‰¾åˆ° {len(patterns_data)} ä¸ªä¸´åºŠå†³ç­–æ¨¡å¼",
            "data": {
                "doctor_id": doctor_id,
                "disease_name": disease_name,
                "patterns": patterns_data,
                "total_count": len(patterns_data)
            }
        }
        
    except Exception as e:
        logger.error(f"è·å–ä¸´åºŠæ¨¡å¼å¤±è´¥: {e}")
        return {
            "success": False,
            "message": f"ä¿å­˜å¤±è´¥: {str(e)}",
            "data": None
        }

async def _create_or_get_temp_doctor_identity(disease_name: str) -> str:
    """ä¸ºåŒ¿åç”¨æˆ·åˆ›å»ºä¸´æ—¶åŒ»ç”Ÿèº«ä»½"""
    # ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨å›ºå®šçš„åŒ¿ååŒ»ç”ŸIDï¼Œè€Œä¸æ˜¯æ¯æ¬¡ç”Ÿæˆæ–°çš„
    # è¿™æ ·å¯ä»¥ç¡®ä¿åŒä¸€ä¸ªç”¨æˆ·çš„æ‰€æœ‰å†³ç­–æ ‘éƒ½å…³è”åˆ°åŒä¸€ä¸ªID
    temp_id = "anonymous_doctor"

    logger.info(f"ä¸ºåŒ¿åç”¨æˆ·ä½¿ç”¨å›ºå®šåŒ»ç”ŸID: {temp_id}")

    return temp_id

async def _save_pattern_to_database(pattern_data: Dict[str, Any]) -> str:
    """ä¿å­˜æ¨¡å¼åˆ°æ•°æ®åº“"""
    import sqlite3
    import uuid
    
    pattern_id = str(uuid.uuid4())
    
    # è¿æ¥æ•°æ®åº“
    conn = sqlite3.connect("/opt/tcm-ai/data/user_history.sqlite")
    cursor = conn.cursor()
    
    try:
        # åˆ›å»ºè¡¨ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS doctor_clinical_patterns (
                id TEXT PRIMARY KEY,
                doctor_id TEXT NOT NULL,
                disease_name TEXT NOT NULL,
                thinking_process TEXT NOT NULL,
                tree_structure TEXT NOT NULL,
                clinical_patterns TEXT NOT NULL,
                doctor_expertise TEXT NOT NULL,
                usage_count INTEGER DEFAULT 0,
                created_at TEXT NOT NULL,
                updated_at TEXT NOT NULL,
                UNIQUE(doctor_id, disease_name)
            )
        """)
        
        # æ’å…¥æˆ–æ›´æ–°è®°å½•
        cursor.execute("""
            INSERT OR REPLACE INTO doctor_clinical_patterns 
            (id, doctor_id, disease_name, thinking_process, tree_structure, 
             clinical_patterns, doctor_expertise, usage_count, created_at, updated_at)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        """, (
            pattern_id,
            pattern_data["doctor_id"],
            pattern_data["disease_name"],
            pattern_data["thinking_process"],
            pattern_data["tree_structure"],
            pattern_data["clinical_patterns"],
            pattern_data["doctor_expertise"],
            pattern_data["usage_count"],
            pattern_data["created_at"],
            pattern_data["updated_at"]
        ))
        
        conn.commit()
        logger.info(f"ä¸´åºŠæ¨¡å¼å·²ä¿å­˜åˆ°æ•°æ®åº“: {pattern_id}")
        
        return pattern_id
        
    except Exception as e:
        logger.error(f"æ•°æ®åº“ä¿å­˜å¤±è´¥: {e}")
        raise
    finally:
        conn.close()

def _analyze_pattern_type(clinical_patterns: Dict[str, Any], doctor_expertise: Dict[str, Any]) -> str:
    """åˆ†æä¸´åºŠæ¨¡å¼ç±»å‹"""
    
    # åŸºäºç—‡çŠ¶æ•°é‡åˆ¤æ–­å¤æ‚åº¦
    symptom_count = len(clinical_patterns.get("symptom_clusters", []))
    pathway_count = len(clinical_patterns.get("diagnostic_pathways", []))
    
    if symptom_count >= 5 and pathway_count >= 3:
        complexity = "å¤æ‚å‹"
    elif symptom_count >= 3 or pathway_count >= 2:
        complexity = "æ ‡å‡†å‹"  
    else:
        complexity = "ç®€åŒ–å‹"
    
    # åŸºäºåŒ»ç”Ÿä¸“é•¿åˆ¤æ–­ç±»å‹
    schools = doctor_expertise.get("schools", [])
    specialties = doctor_expertise.get("specialties", [])
    
    if "å¼ ä»²æ™¯" in schools:
        style = "ç»æ–¹æ´¾"
    elif "æä¸œå£" in schools:
        style = "è„¾èƒƒæ´¾"
    elif "éƒ‘é’¦å®‰" in schools:
        style = "ç«ç¥æ´¾"
    elif "å¶å¤©å£«" in schools:
        style = "æ¸©ç—…æ´¾"
    else:
        style = "ç»¼åˆæ´¾"
    
    return f"{style}-{complexity}"

def _detect_age_group_in_thinking(thinking_process: str) -> Dict[str, Any]:
    """æ™ºèƒ½æ£€æµ‹è¯Šç–—æ€è·¯ä¸­æ˜¯å¦å·²æ˜ç¡®å¹´é¾„ç¾¤ä½“ç”¨è¯"""
    import re
    
    # å„¿ç«¥ç›¸å…³å…³é”®è¯
    pediatric_keywords = ['å°å„¿', 'å„¿ç«¥', 'å¹¼å„¿', 'å©´å„¿', 'æ–°ç”Ÿå„¿', 'å­¦é¾„å‰', 'å­¦é¾„å„¿ç«¥']
    
    # è€å¹´ç›¸å…³å…³é”®è¯  
    elderly_keywords = ['è€å¹´', 'é«˜é¾„', 'å¹´è¿ˆ', 'è€äºº']
    
    # æˆäººç›¸å…³å…³é”®è¯
    adult_keywords = ['æˆäºº', 'æˆå¹´äºº', 'å£®å¹´']
    
    thinking_lower = thinking_process.lower()
    
    # æ£€æµ‹å„¿ç«¥ç”¨è¯
    for keyword in pediatric_keywords:
        if keyword in thinking_process:
            return {
                "detected": True,
                "age_group": "pediatric", 
                "keyword": keyword,
                "description": f"è¯Šç–—æ€è·¯ä¸­æ˜ç¡®æåŠ'{keyword}'ï¼Œè¯´æ˜å·²æ˜¯{keyword}ä¸“ç”¨å¤„æ–¹ï¼Œå‰‚é‡æ— éœ€è°ƒæ•´"
            }
    
    # æ£€æµ‹è€å¹´ç”¨è¯
    for keyword in elderly_keywords:
        if keyword in thinking_process:
            return {
                "detected": True,
                "age_group": "elderly",
                "keyword": keyword, 
                "description": f"è¯Šç–—æ€è·¯ä¸­æ˜ç¡®æåŠ'{keyword}'ï¼Œè¯´æ˜å·²æ˜¯{keyword}ä¸“ç”¨å¤„æ–¹ï¼Œå‰‚é‡æ— éœ€è°ƒæ•´"
            }
    
    # æ£€æµ‹æˆäººç”¨è¯
    for keyword in adult_keywords:
        if keyword in thinking_process:
            return {
                "detected": True,
                "age_group": "adult",
                "keyword": keyword,
                "description": f"è¯Šç–—æ€è·¯ä¸­æ˜ç¡®æåŠ'{keyword}'ï¼Œä½¿ç”¨æ ‡å‡†æˆäººå‰‚é‡"
            }
    
    return {
        "detected": False,
        "age_group": "unspecified",
        "keyword": None,
        "description": "è¯Šç–—æ€è·¯ä¸­æœªæ˜ç¡®å¹´é¾„ç¾¤ä½“ï¼Œéœ€æ ¹æ®æ‚£è€…ä¿¡æ¯æ™ºèƒ½è°ƒæ•´å‰‚é‡"
    }

def _generate_dosage_adjustment_rules(
    age_group_detected: Dict[str, Any],
    patient_age: Optional[int],
    patient_weight: Optional[float], 
    special_conditions: List[str]
) -> str:
    """ç”Ÿæˆä¸ªæ€§åŒ–çš„å‰‚é‡è°ƒæ•´è§„åˆ™"""
    
    rules = []
    
    # 1. å¦‚æœæ€è·¯ä¸­å·²æ˜ç¡®å¹´é¾„ç¾¤ä½“
    if age_group_detected["detected"]:
        if age_group_detected["age_group"] == "pediatric":
            rules.append("âœ… æ£€æµ‹åˆ°è¯Šç–—æ€è·¯å·²æ˜ç¡®ä¸ºå„¿ç«¥ç”¨è¯ï¼Œä¿æŒåŸå¤„æ–¹å‰‚é‡ï¼Œæ— éœ€è°ƒæ•´")
            rules.append("âš ï¸ ä¸¥ç¦å¯¹å·²é€‚é…çš„å„¿ç«¥å‰‚é‡å†æ¬¡å‡é‡")
        elif age_group_detected["age_group"] == "elderly":
            rules.append("âœ… æ£€æµ‹åˆ°è¯Šç–—æ€è·¯å·²æ˜ç¡®ä¸ºè€å¹´ç”¨è¯ï¼Œä¿æŒåŸå¤„æ–¹å‰‚é‡")
        else:
            rules.append("âœ… æ£€æµ‹åˆ°è¯Šç–—æ€è·¯å·²æ˜ç¡®ä¸ºæˆäººç”¨è¯ï¼Œä¿æŒæ ‡å‡†å‰‚é‡")
    else:
        # 2. æ ¹æ®æ‚£è€…ä¿¡æ¯è°ƒæ•´
        rules.append("ğŸ“‹ è¯Šç–—æ€è·¯ä¸­æœªæ˜ç¡®å¹´é¾„ç¾¤ä½“ï¼Œæ ¹æ®æ‚£è€…ä¿¡æ¯æ™ºèƒ½è°ƒæ•´ï¼š")
        
        if patient_age and patient_age < 18:
            rules.append(f"   - æ‚£è€…{patient_age}å²ï¼Œå„¿ç«¥å‰‚é‡ï¼šæˆäººæ ‡å‡†å‰‚é‡çš„50-70%")
        elif patient_age and patient_age > 65:
            rules.append(f"   - æ‚£è€…{patient_age}å²ï¼Œè€å¹´å‰‚é‡ï¼šæˆäººæ ‡å‡†å‰‚é‡çš„70-80%")
        
        if patient_weight:
            if patient_weight < 50:
                rules.append(f"   - æ‚£è€…ä½“é‡{patient_weight}kgï¼Œé€‚å½“å‡é‡10-20%")
            elif patient_weight > 80:
                rules.append(f"   - æ‚£è€…ä½“é‡{patient_weight}kgï¼Œå¯é€‚å½“å¢é‡10-15%")
    
    # 3. ç‰¹æ®Šæƒ…å†µ
    if special_conditions:
        rules.append("ğŸš¨ ç‰¹æ®Šæƒ…å†µè°ƒæ•´ï¼š")
        condition_map = {
            "pregnancy": "å¦Šå¨ æœŸï¼šé¿å…æ´»è¡€åŒ–ç˜€ã€ç ´æ°”è¯ç‰©ï¼Œå‡é‡ä½¿ç”¨",
            "lactation": "å“ºä¹³æœŸï¼šæ³¨æ„è¯ç‰©å¯¹å©´å„¿çš„å½±å“",
            "diabetes": "ç³–å°¿ç—…ï¼šæ³¨æ„é¿å…å‡ç³–è¯ç‰©",
            "hypertension": "é«˜è¡€å‹ï¼šæ³¨æ„é¿å…å‡å‹è¯ç‰©"
        }
        for condition in special_conditions:
            if condition in condition_map:
                rules.append(f"   - {condition_map[condition]}")
    
    rules.append("\nğŸ’¡ æ ¸å¿ƒåŸåˆ™ï¼šç¡®ä¿å‰‚é‡è°ƒæ•´çš„ä¸´åºŠåˆç†æ€§ï¼Œé¿å…é‡å¤è°ƒæ•´å·²é€‚é…çš„å‰‚é‡ã€‚")
    
    return "\n".join(rules)


# ======================== å†³ç­–æ ‘ä½¿ç”¨ç»Ÿè®¡åŠŸèƒ½ ========================

@router.get("/doctor-decision-tree/usage-stats/{doctor_id}")
async def get_pattern_usage_statistics(
    doctor_id: str,
    time_range: str = "all",  # today, week, month, all
    current_user: UserSession = Depends(get_current_user)
):
    """
    è·å–åŒ»ç”Ÿçš„å†³ç­–æ ‘ä½¿ç”¨ç»Ÿè®¡

    Args:
        doctor_id: åŒ»ç”ŸID
        time_range: æ—¶é—´èŒƒå›´ï¼ˆtoday, week, month, allï¼‰
        current_user: å½“å‰ç”¨æˆ·ä¼šè¯

    Returns:
        å†³ç­–æ ‘ä½¿ç”¨ç»Ÿè®¡æ•°æ®
    """
    import sqlite3
    from datetime import datetime, timedelta

    try:
        logger.info(f"è·å–åŒ»ç”Ÿ {doctor_id} çš„å†³ç­–æ ‘ä½¿ç”¨ç»Ÿè®¡ï¼Œæ—¶é—´èŒƒå›´: {time_range}")

        # è®¡ç®—æ—¶é—´èŒƒå›´
        time_filter = ""
        if time_range == "today":
            time_filter = "AND DATE(c.created_at) = DATE('now')"
        elif time_range == "week":
            time_filter = "AND c.created_at >= datetime('now', '-7 days')"
        elif time_range == "month":
            time_filter = "AND c.created_at >= datetime('now', '-30 days')"

        conn = sqlite3.connect("/opt/tcm-ai/data/user_history.sqlite")
        conn.row_factory = sqlite3.Row
        cursor = conn.cursor()

        # 1. è·å–æ€»ä½“ç»Ÿè®¡
        cursor.execute(f"""
            SELECT
                COUNT(DISTINCT p.id) as total_patterns,
                COUNT(DISTINCT c.uuid) as total_calls,
                COUNT(DISTINCT CASE WHEN pr.status = 'reviewed' THEN c.uuid END) as success_calls,
                ROUND(CAST(COUNT(DISTINCT CASE WHEN c.used_pattern_id IS NOT NULL THEN c.uuid END) AS FLOAT) /
                      NULLIF(COUNT(DISTINCT c.uuid), 0) * 100, 2) as coverage_rate
            FROM doctor_clinical_patterns p
            LEFT JOIN consultations c ON c.used_pattern_id = p.id {time_filter}
            LEFT JOIN prescriptions pr ON pr.consultation_id = c.uuid
            WHERE p.doctor_id = ?
        """, (doctor_id,))

        overall_stats = dict(cursor.fetchone())

        # 2. è·å–æ¯ä¸ªå†³ç­–æ ‘çš„è¯¦ç»†ç»Ÿè®¡
        cursor.execute(f"""
            SELECT
                p.id as pattern_id,
                p.disease_name,
                p.thinking_process,
                p.created_at as pattern_created_at,
                COUNT(DISTINCT c.uuid) as call_count,
                COUNT(DISTINCT CASE WHEN pr.status = 'reviewed' THEN c.uuid END) as success_count,
                ROUND(CAST(COUNT(DISTINCT CASE WHEN pr.status = 'reviewed' THEN c.uuid END) AS FLOAT) /
                      NULLIF(COUNT(DISTINCT c.uuid), 0) * 100, 2) as success_rate,
                MAX(c.created_at) as last_used_at,
                AVG(c.pattern_match_score) as avg_match_score
            FROM doctor_clinical_patterns p
            LEFT JOIN consultations c ON c.used_pattern_id = p.id {time_filter}
            LEFT JOIN prescriptions pr ON pr.consultation_id = c.uuid
            WHERE p.doctor_id = ?
            GROUP BY p.id
            ORDER BY call_count DESC
        """, (doctor_id,))

        pattern_stats = [dict(row) for row in cursor.fetchall()]

        # 3. è·å–æ€»é—®è¯Šæ•°ï¼ˆç”¨äºè®¡ç®—ä½¿ç”¨ç‡ï¼‰
        cursor.execute(f"""
            SELECT COUNT(*) as total_consultations
            FROM consultations c
            WHERE 1=1 {time_filter}
        """)

        total_consultations = cursor.fetchone()[0]

        conn.close()

        # è®¡ç®—æ¯ä¸ªå†³ç­–æ ‘çš„ä½¿ç”¨ç‡
        for pattern in pattern_stats:
            if total_consultations > 0:
                pattern['usage_rate'] = round((pattern['call_count'] / total_consultations) * 100, 2)
            else:
                pattern['usage_rate'] = 0

        return {
            "success": True,
            "data": {
                "overall": {
                    **overall_stats,
                    "total_consultations": total_consultations,
                    "time_range": time_range
                },
                "patterns": pattern_stats
            }
        }

    except Exception as e:
        logger.error(f"è·å–å†³ç­–æ ‘ä½¿ç”¨ç»Ÿè®¡å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"è·å–ç»Ÿè®¡å¤±è´¥: {str(e)}")


@router.get("/doctor-decision-tree/usage-detail/{pattern_id}")
async def get_pattern_usage_detail(
    pattern_id: str,
    limit: int = 50,
    current_user: UserSession = Depends(get_current_user)
):
    """
    è·å–å•ä¸ªå†³ç­–æ ‘çš„è¯¦ç»†ä½¿ç”¨è®°å½•

    Args:
        pattern_id: å†³ç­–æ ‘ID
        limit: è¿”å›è®°å½•æ•°é‡é™åˆ¶
        current_user: å½“å‰ç”¨æˆ·ä¼šè¯

    Returns:
        å†³ç­–æ ‘è¯¦ç»†ä½¿ç”¨è®°å½•
    """
    import sqlite3

    try:
        logger.info(f"è·å–å†³ç­–æ ‘ {pattern_id} çš„è¯¦ç»†ä½¿ç”¨è®°å½•")

        conn = sqlite3.connect("/opt/tcm-ai/data/user_history.sqlite")
        conn.row_factory = sqlite3.Row
        cursor = conn.cursor()

        # 1. è·å–å†³ç­–æ ‘åŸºæœ¬ä¿¡æ¯
        cursor.execute("""
            SELECT *
            FROM doctor_clinical_patterns
            WHERE id = ?
        """, (pattern_id,))

        pattern_info = cursor.fetchone()
        if not pattern_info:
            raise HTTPException(status_code=404, detail="å†³ç­–æ ‘ä¸å­˜åœ¨")

        pattern_info = dict(pattern_info)

        # 2. è·å–ä½¿ç”¨è®°å½•åˆ—è¡¨
        cursor.execute("""
            SELECT
                c.uuid as consultation_id,
                c.patient_id,
                c.pattern_match_score,
                c.created_at as consultation_date,
                c.status as consultation_status,
                p.id as prescription_id,
                p.status as prescription_status,
                p.review_status,
                p.payment_status,
                p.diagnosis
            FROM consultations c
            LEFT JOIN prescriptions p ON p.consultation_id = c.uuid
            WHERE c.used_pattern_id = ?
            ORDER BY c.created_at DESC
            LIMIT ?
        """, (pattern_id, limit))

        usage_records = [dict(row) for row in cursor.fetchall()]

        conn.close()

        return {
            "success": True,
            "data": {
                "pattern_info": pattern_info,
                "usage_records": usage_records,
                "total_count": len(usage_records)
            }
        }

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"è·å–å†³ç­–æ ‘ä½¿ç”¨è¯¦æƒ…å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"è·å–è¯¦æƒ…å¤±è´¥: {str(e)}")


@router.get("/consultation/{consultation_id}/detail")
async def get_consultation_detail(
    consultation_id: str,
    request: Request,
    current_user: UserSession = Depends(get_current_user_or_doctor)
):
    """
    ç»Ÿä¸€çš„é—®è¯Šè¯¦æƒ…æŸ¥è¯¢API
    ç”¨äºæ‚£è€…ç«¯å’ŒåŒ»ç”Ÿç«¯æŸ¥çœ‹é—®è¯Šè¯¦æƒ…

    Args:
        consultation_id: é—®è¯ŠUUID
        current_user: å½“å‰ç”¨æˆ·ä¼šè¯

    Returns:
        é—®è¯Šå®Œæ•´è¯¦æƒ…ï¼ˆåŒ…æ‹¬å¤„æ–¹ã€å†³ç­–æ ‘ä¿¡æ¯ï¼‰
    """
    import sqlite3

    try:
        # ğŸ” è¯¦ç»†è°ƒè¯•æ—¥å¿—
        user_roles = getattr(current_user, 'roles', [getattr(current_user, 'role', None)])
        if isinstance(user_roles, str):
            user_roles = [user_roles]

        logger.info(f"ğŸ” [å†³ç­–æ ‘]è·å–é—®è¯Šè¯¦æƒ…è¯·æ±‚: consultation_id={consultation_id}, user_id={current_user.user_id}, roles={user_roles}")
        logger.info(f"ğŸ” [å†³ç­–æ ‘]current_userå®Œæ•´ä¿¡æ¯: {current_user.__dict__}")

        conn = sqlite3.connect("/opt/tcm-ai/data/user_history.sqlite")
        conn.row_factory = sqlite3.Row
        cursor = conn.cursor()

        # 1. è·å–é—®è¯ŠåŸºæœ¬ä¿¡æ¯
        cursor.execute("""
            SELECT *
            FROM consultations
            WHERE uuid = ?
        """, (consultation_id,))

        consultation = cursor.fetchone()
        if not consultation:
            raise HTTPException(status_code=404, detail="é—®è¯Šè®°å½•ä¸å­˜åœ¨")

        consultation = dict(consultation)

        # 2. è·å–å¤„æ–¹ä¿¡æ¯
        cursor.execute("""
            SELECT *
            FROM prescriptions
            WHERE consultation_id = ?
            ORDER BY created_at DESC
            LIMIT 1
        """, (consultation_id,))

        prescription = cursor.fetchone()
        if prescription:
            consultation['prescription'] = dict(prescription)

        # 3. å¦‚æœä½¿ç”¨äº†å†³ç­–æ ‘ï¼Œè·å–å†³ç­–æ ‘ä¿¡æ¯
        if consultation.get('used_pattern_id'):
            cursor.execute("""
                SELECT id, disease_name, doctor_id, thinking_process
                FROM doctor_clinical_patterns
                WHERE id = ?
            """, (consultation['used_pattern_id'],))

            pattern = cursor.fetchone()
            if pattern:
                consultation['used_pattern'] = dict(pattern)

        conn.close()

        # æƒé™æ£€æŸ¥ï¼šåªå…è®¸æ‚£è€…æœ¬äººæˆ–åŒ»ç”ŸæŸ¥çœ‹
        # ğŸ”§ ä¿®å¤ï¼šå…¼å®¹ç»Ÿä¸€è®¤è¯ç³»ç»Ÿçš„ roles (List[str]) å’Œæ—§ç³»ç»Ÿçš„ role
        user_roles = getattr(current_user, 'roles', [getattr(current_user, 'role', None)])
        if isinstance(user_roles, str):
            user_roles = [user_roles]

        # æ£€æŸ¥æ˜¯å¦æœ‰åŒ»ç”Ÿæˆ–ç®¡ç†å‘˜è§’è‰²
        has_doctor_role = any(
            role in ['DOCTOR', 'ADMIN', UserRole.DOCTOR, UserRole.ADMIN]
            for role in user_roles if role
        )

        # æƒé™éªŒè¯ï¼šå¿…é¡»æ˜¯æ‚£è€…æœ¬äºº æˆ– åŒ»ç”Ÿ/ç®¡ç†å‘˜
        if current_user.user_id != consultation['patient_id'] and not has_doctor_role:
            logger.warning(f"æƒé™æ£€æŸ¥å¤±è´¥: user={current_user.user_id}, roles={user_roles}, patient={consultation['patient_id']}")
            raise HTTPException(status_code=403, detail="æ— æƒé™æŸ¥çœ‹æ­¤é—®è¯Šè®°å½•")

        logger.info(f"âœ… æƒé™æ£€æŸ¥é€šè¿‡: user={current_user.user_id}, roles={user_roles}, is_doctor={has_doctor_role}")

        return {
            "success": True,
            "data": consultation
        }

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"è·å–é—®è¯Šè¯¦æƒ…å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"è·å–è¯¦æƒ…å¤±è´¥: {str(e)}")


# ================================
# AIæ™ºèƒ½å†³ç­–æ ‘ç”Ÿæˆ - æ€ç»´å¯¼å›¾æ¨¡å¼
# ================================

class MindMapGenerationRequest(BaseModel):
    """AIæ€ç»´å¯¼å›¾ç”Ÿæˆè¯·æ±‚"""
    doctor_input: str  # åŒ»ç”Ÿçš„è‡ªç„¶è¯­è¨€è¯Šç–—æ€è·¯
    disease_name: str = ""  # ç–¾ç—…åç§°ï¼ˆå¯é€‰ï¼Œç”¨äºè¡¥å……AIæå–å¤±è´¥çš„æƒ…å†µï¼‰
    auto_save: bool = True  # æ˜¯å¦è‡ªåŠ¨ä¿å­˜åˆ°æ€ç»´åº“

@router.post("/ai_mindmap_generate")
async def ai_mindmap_generate(
    request: MindMapGenerationRequest,
    current_user: UserSession = Depends(get_current_user_or_doctor)
):
    """
    AIæ™ºèƒ½ç”Ÿæˆæ€ç»´å¯¼å›¾å¼å†³ç­–æ ‘

    åŠŸèƒ½ï¼š
    1. æ¥æ”¶åŒ»ç”Ÿçš„è‡ªç„¶è¯­è¨€æè¿°
    2. AIè‡ªåŠ¨åˆ†æï¼šä¸»è¯ã€è¯è§ã€å¤„æ–¹ã€åŠ å‡æ³•
    3. ç”Ÿæˆæ€ç»´å¯¼å›¾å½¢å¼çš„å†³ç­–æ ‘
    4. å¯é€‰è‡ªåŠ¨ä¿å­˜åˆ°åŒ»ç”Ÿæ€ç»´åº“

    Example Input:
    ```
    {
        "doctor_input": "é£çƒ­æ„Ÿå†’ï¼šå¤–æ„Ÿé£çƒ­ï¼Œé‚ªè¢­è‚ºå«ã€‚ç—‡è§å‘çƒ­æ¶é£ï¼Œæ±—å‡ºä¸ç•…ï¼Œå¤´ç—›é¼»å¡ï¼Œå’½å–‰è‚¿ç—›ï¼Œå’³å—½ç—°é»„ï¼Œå£æ¸´æ¬²é¥®ã€‚èˆŒè¾¹å°–çº¢ï¼Œè‹”è–„é»„ï¼Œè„‰æµ®æ•°ã€‚æ²»ç–—ç”¨æ¡‘èŠé¥®åŠ å‡ï¼šæ¡‘å¶10gã€èŠèŠ±10gã€è–„è·6gã€æ¡”æ¢—6gã€è¿ç¿˜10gã€èŠ¦æ ¹15gã€ç”˜è‰3gã€‚è‹¥çƒ­é‡åŠ é»„èŠ©10gã€æ¿è“æ ¹15gï¼›è‹¥å’½ç—›ç”šåŠ å°„å¹²10gã€å±±è±†æ ¹10gã€‚",
        "auto_save": true
    }
    ```

    Returns:
        æ€ç»´å¯¼å›¾å¼å†³ç­–æ ‘ç»“æ„ + å¯è§†åŒ–æ•°æ®
    """
    try:
        # å¯¼å…¥AIç”Ÿæˆå™¨
        from core.doctor_management.ai_decision_tree_generator import get_ai_decision_tree_generator

        generator = get_ai_decision_tree_generator()

        logger.info(f"ğŸ§  [AIæ€ç»´å¯¼å›¾]ç”¨æˆ· {current_user.user_id} è¯·æ±‚ç”Ÿæˆå†³ç­–æ ‘ï¼Œè¾“å…¥é•¿åº¦: {len(request.doctor_input)}å­—, ç–¾ç—…åç§°: {request.disease_name}")

        # AIåˆ†æå¹¶ç”Ÿæˆæ€ç»´å¯¼å›¾
        mind_map_tree = await generator.analyze_and_generate(
            doctor_input=request.doctor_input,
            doctor_id=current_user.user_id,
            disease_name_hint=request.disease_name  # ä¼ é€’ç”¨æˆ·è¾“å…¥çš„ç–¾ç—…åç§°ä½œä¸ºæç¤º
        )

        # è½¬æ¢ä¸ºæ•°æ®åº“æ ¼å¼
        db_format = generator.to_database_format(mind_map_tree)

        # è‡ªåŠ¨ä¿å­˜åˆ°æ€ç»´åº“
        pattern_id = None
        if request.auto_save:
            pattern_id = await _save_mind_map_to_database(
                doctor_id=current_user.user_id,
                mind_map_data=db_format
            )
            logger.info(f"âœ… [AIæ€ç»´å¯¼å›¾]å†³ç­–æ ‘å·²ä¿å­˜åˆ°æ€ç»´åº“: {pattern_id}")

        return {
            "success": True,
            "message": "AIæ€ç»´å¯¼å›¾ç”ŸæˆæˆåŠŸ",
            "data": {
                "disease_name": mind_map_tree.disease_name,
                "main_syndrome": mind_map_tree.main_syndrome,
                "syndrome_branches": mind_map_tree.syndrome_branches,
                "nodes": mind_map_tree.nodes,
                "connections": mind_map_tree.connections,
                "metadata": mind_map_tree.metadata,
                "pattern_id": pattern_id if request.auto_save else None
            }
        }

    except Exception as e:
        logger.error(f"AIæ€ç»´å¯¼å›¾ç”Ÿæˆå¤±è´¥: {e}", exc_info=True)
        raise HTTPException(
            status_code=500,
            detail=f"AIæ€ç»´å¯¼å›¾ç”Ÿæˆå¤±è´¥: {str(e)}"
        )

async def _save_mind_map_to_database(
    doctor_id: str,
    mind_map_data: Dict[str, Any]
) -> str:
    """ä¿å­˜æ€ç»´å¯¼å›¾åˆ°æ•°æ®åº“ï¼ˆä½¿ç”¨UPSERTç­–ç•¥ï¼‰"""
    import uuid

    conn = sqlite3.connect("/opt/tcm-ai/data/user_history.sqlite")
    cursor = conn.cursor()

    # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ç›¸åŒç–¾ç—…çš„å†³ç­–æ ‘
    cursor.execute("""
        SELECT id FROM doctor_clinical_patterns
        WHERE doctor_id = ? AND disease_name = ?
    """, (doctor_id, mind_map_data['disease_name']))

    existing = cursor.fetchone()

    if existing:
        # æ›´æ–°ç°æœ‰è®°å½•
        pattern_id = existing[0]
        logger.info(f"ğŸ”„ æ›´æ–°ç°æœ‰å†³ç­–æ ‘: {pattern_id}, ç–¾ç—…={mind_map_data['disease_name']}")

        # æ„å»ºåŒ»ç”Ÿä¸“é•¿ä¿¡æ¯
        try:
            clinical_patterns = json.loads(mind_map_data['clinical_patterns'])
            doctor_expertise = json.dumps({
                "specialties": [mind_map_data['disease_name']],
                "main_syndromes": [clinical_patterns.get('main_syndrome', '')],
                "ai_generated": True,
                "updated_count": 1
            }, ensure_ascii=False)
        except:
            doctor_expertise = json.dumps({
                "specialties": [],
                "ai_generated": True
            }, ensure_ascii=False)

        cursor.execute("""
            UPDATE doctor_clinical_patterns
            SET thinking_process = ?,
                tree_structure = ?,
                clinical_patterns = ?,
                doctor_expertise = ?,
                updated_at = datetime('now')
            WHERE id = ?
        """, (
            mind_map_data['thinking_process'],
            mind_map_data['tree_structure'],
            mind_map_data['clinical_patterns'],
            doctor_expertise,
            pattern_id
        ))
    else:
        # æ’å…¥æ–°è®°å½•
        pattern_id = str(uuid.uuid4())
        logger.info(f"âœ¨ åˆ›å»ºæ–°å†³ç­–æ ‘: {pattern_id}, ç–¾ç—…={mind_map_data['disease_name']}")

        # æ„å»ºåŒ»ç”Ÿä¸“é•¿ä¿¡æ¯
        try:
            clinical_patterns = json.loads(mind_map_data['clinical_patterns'])
            doctor_expertise = json.dumps({
                "specialties": [mind_map_data['disease_name']],
                "main_syndromes": [clinical_patterns.get('main_syndrome', '')],
                "ai_generated": True
            }, ensure_ascii=False)
        except:
            doctor_expertise = json.dumps({
                "specialties": [],
                "ai_generated": True
            }, ensure_ascii=False)

        cursor.execute("""
            INSERT INTO doctor_clinical_patterns (
                id, doctor_id, disease_name, thinking_process,
                tree_structure, clinical_patterns, doctor_expertise,
                usage_count, success_count,
                created_at, updated_at
            ) VALUES (?, ?, ?, ?, ?, ?, ?, 0, 0, datetime('now'), datetime('now'))
        """, (
            pattern_id,
            doctor_id,
            mind_map_data['disease_name'],
            mind_map_data['thinking_process'],
            mind_map_data['tree_structure'],
            mind_map_data['clinical_patterns'],
            doctor_expertise
        ))

    conn.commit()
    conn.close()

    return pattern_id


# å¯¼å‡ºè·¯ç”±å™¨
__all__ = ["router"]