# main_minimal_correct.py - è…¾è®¯äº‘æœ€å°åŒ–éƒ¨ç½²ç‰ˆæœ¬
# ä»…å°†æœ¬åœ°æ¨¡å‹æ›¿æ¢ä¸ºåœ¨çº¿APIï¼Œä¿ç•™æ‰€æœ‰å…¶ä»–åŠŸèƒ½

import os
import sys

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, '/opt/tcm-ai')
sys.path.insert(0, '/opt/tcm-ai/core')
sys.path.insert(0, '/opt/tcm-ai/services')
sys.path.insert(0, '/opt/tcm-ai/database')

# å¯¼å…¥ç»Ÿä¸€é…ç½®
from config.settings import PATHS, API_CONFIG, DATABASE_CONFIG, AI_CONFIG, SECURITY_CONFIG

# åŠ å¼ºçš„åŒ»ç–—å®‰å…¨æ£€æŸ¥
ENHANCED_MEDICAL_SAFETY_PROMPT = """
**ã€ä¸¥æ ¼åŒ»ç–—å®‰å…¨è§„åˆ™ã€‘**

1. **ç—‡çŠ¶æè¿°ä¸¥æ ¼é™åˆ¶** - æœ€é«˜ä¼˜å…ˆçº§ï¼š
   - **ç»å¯¹ç¦æ­¢**ï¼šæ·»åŠ ã€æ¨æµ‹ã€ç¼–é€ æ‚£è€…æœªæ˜ç¡®æè¿°çš„ä»»ä½•ç—‡çŠ¶ç»†èŠ‚
   - **ç»å¯¹ç¦æ­¢**ï¼šä»"ä¾¿ç§˜"æ¨æµ‹å‡º"å¤§ä¾¿å¹²ç»“å¦‚æ —ï¼Œæ•°æ—¥ä¸€è¡Œ"
   - **ç»å¯¹ç¦æ­¢**ï¼šä»"æŒ‘é£Ÿ"æ¨æµ‹å‡º"é£Ÿæ¬²ä¸ä½³ï¼Œè…¹èƒ€å—³æ°”"  
   - **æ­£ç¡®åšæ³•**ï¼šåªèƒ½ä½¿ç”¨æ‚£è€…ç¡®åˆ‡çš„åŸå§‹è¡¨è¿°

2. **èˆŒè±¡è„‰è±¡ä¿¡æ¯ä¸¥æ ¼é™åˆ¶**ï¼š
   - **ç»å¯¹ç¦æ­¢**ï¼šåœ¨æ²¡æœ‰æ‚£è€…ä¸Šä¼ èˆŒè±¡å›¾ç‰‡çš„æƒ…å†µä¸‹ï¼Œæè¿°ä»»ä½•å…·ä½“çš„èˆŒè±¡ç‰¹å¾
   - **ç»å¯¹ç¦æ­¢**ï¼šç¼–é€ ä»»ä½•è„‰è±¡æè¿°ï¼ˆ"è„‰ç»†å¼±"ã€"è„‰æ¿¡ç¼“"ç­‰ï¼‰
   - **ç»å¯¹ç¦æ­¢**ï¼šä½¿ç”¨"èˆŒè‹”è–„ç™½"ã€"èˆŒè¾¹æœ‰é½¿ç—•"ã€"èˆŒè´¨æ·¡çº¢"ç­‰å…·ä½“æè¿°
   - **æ­£ç¡®åšæ³•**ï¼šå¦‚æ— å›¾åƒå’Œæ‚£è€…æè¿°ï¼Œå†™"æœªè§èˆŒè±¡è„‰è±¡ä¿¡æ¯"

3. **æœ›è¯Šåˆ‡è¯Šç¼–é€ æ£€æµ‹ - æ–°å¢ä¸¥æ ¼è§„åˆ™**ï¼š
   - **ç»å¯¹ç¦æ­¢**ï¼šåœ¨"1. æœ›è¯Š"éƒ¨åˆ†ç¼–é€ é¢è‰²ã€èˆŒè±¡ç­‰æè¿°
   - **ç»å¯¹ç¦æ­¢**ï¼šåœ¨"4. åˆ‡è¯Š"éƒ¨åˆ†ç¼–é€ è„‰è±¡æè¿°  
   - **ç»å¯¹ç¦æ­¢**ï¼šä½¿ç”¨"æç¤º"ã€"è¯´æ˜"ç­‰è¯æ±‡æš—ç¤ºä½“å¾ä¿¡æ¯
   - **æ­£ç¡®åšæ³•**ï¼šå†™"æœªè¿›è¡Œå®é™…æœ›è¯Š/åˆ‡è¯Šï¼Œå»ºè®®é¢è¯Š"

4. **æœ›è¯Šä¿¡æ¯æ¥æºéªŒè¯**ï¼š  
   - åªèƒ½åŸºäº**å½“å‰å¯¹è¯ä¸­æ‚£è€…æ˜ç¡®æè¿°**çš„ç—‡çŠ¶
   - åªèƒ½åŸºäº**å½“å‰å¯¹è¯ä¸­ä¸Šä¼ çš„å›¾åƒ**è¿›è¡Œæœ›è¯Šåˆ†æ
   - **ç»å¯¹ç¦æ­¢**ï¼šä»çŸ¥è¯†åº“æˆ–å…¶ä»–æ¥æºæ·»åŠ æ‚£è€…æœªæåŠçš„ç—‡çŠ¶ä¿¡æ¯
   - **ç»å¯¹ç¦æ­¢**ï¼šæ¨æµ‹é¢è‰²ã€ç²¾ç¥çŠ¶æ€ç­‰æ‚£è€…æœªæè¿°çš„ä½“å¾

4. **ä¸¥æ ¼ä¿¡æ¯éš”ç¦»**ï¼š
   - æ¯æ¬¡è¯Šç–—éƒ½æ˜¯ç‹¬ç«‹çš„ï¼Œä¸èƒ½ä½¿ç”¨å…¶ä»–æ‚£è€…çš„ä¿¡æ¯
   - ä¸èƒ½å‡è®¾æˆ–æ¨æµ‹æ‚£è€…çš„ä»»ä½•æœªæ˜ç¡®è¡¨è¿°çš„ç—‡çŠ¶æˆ–ä½“å¾
   - å¿…é¡»åŸºäºå½“å‰ä¼šè¯çš„å®é™…ä¿¡æ¯è¿›è¡Œåˆ†æ

**è¿åä»¥ä¸Šä»»ä½•ä¸€æ¡éƒ½æ˜¯ä¸¥é‡çš„åŒ»ç–—å®‰å…¨äº‹æ•…ï¼**
"""

def check_symptom_fabrication(ai_response: str, patient_message: str) -> str:
    """
    æ£€æŸ¥AIæ˜¯å¦ç¼–é€ äº†æ‚£è€…æœªæ˜ç¡®æè¿°çš„ç—‡çŠ¶ç»†èŠ‚
    è¿”å›ç¼–é€ çš„ç—‡çŠ¶æè¿°ï¼Œå¦‚æœæ²¡æœ‰ç¼–é€ åˆ™è¿”å›ç©ºå­—ç¬¦ä¸²
    """
    # å¸¸è§çš„ç—‡çŠ¶ç¼–é€ æ¨¡å¼
    fabricated_symptoms = [
        # ä¾¿ç§˜ç›¸å…³ç¼–é€ 
        (r'å¤§ä¾¿å¹²ç»“.*æ —', "å¤§ä¾¿å¹²ç»“å¦‚æ —"),
        (r'æ•°æ—¥ä¸€è¡Œ', "æ•°æ—¥ä¸€è¡Œ"),
        (r'å¤§ä¾¿.*å¹².*ç¡¬', "å¤§ä¾¿å¹²ç¡¬"),
        (r'å¤§ä¾¿å¹²ç»“', "å¤§ä¾¿å¹²ç»“"),  # æ–°å¢ï¼šæ‚£è€…åªè¯´ä¾¿ç§˜ï¼ŒAIæ·»åŠ å…·ä½“æè¿°
        (r'æ’ä¾¿å›°éš¾', "æ’ä¾¿å›°éš¾"),  # æ–°å¢ï¼šæ‚£è€…æœªæè¿°çš„æ’ä¾¿æƒ…å†µ
        
        # æ¶ˆåŒ–ç³»ç»Ÿç¼–é€ 
        (r'è…¹èƒ€.*å—³æ°”', "è…¹èƒ€å—³æ°”"),
        (r'è…¹èƒ€ä¸èˆ’', "è…¹èƒ€ä¸èˆ’"),
        (r'å—³æ°”é¢‘é¢‘', "å—³æ°”é¢‘é¢‘"),
        (r'é£Ÿæ¬²ä¸ä½³', "é£Ÿæ¬²ä¸ä½³"),
        (r'é£Ÿæ¬²ä¸æŒ¯', "é£Ÿæ¬²ä¸æŒ¯"),  # æ–°å¢ï¼šæ‚£è€…åªè¯´æŒ‘é£Ÿï¼ŒAIç¼–é€ é£Ÿæ¬²çŠ¶æ€
        
        # ä½“å¾ç¼–é€ 
        (r'é¢è‰²[è‹ç™½èé»„]', "é¢è‰²è‹ç™½/èé»„"),
        (r'ç²¾ç¥ç–²å€¦', "ç²¾ç¥ç–²å€¦"),
        (r'ç²¾ç¥.*ä¸æŒ¯', "ç²¾ç¥ä¸æŒ¯"),
        (r'ç¥ç–²ä¹åŠ›', "ç¥ç–²ä¹åŠ›"),
        (r'ç²¾ç¥å€¦æ€ ', "ç²¾ç¥å€¦æ€ "),  # æ–°å¢ï¼šæ‚£è€…æœªæè¿°çš„ç²¾ç¥çŠ¶æ€
        
        # æ—¶é—´å’Œç¨‹åº¦ç¼–é€ 
        (r'.*å·²ä¹…', "æŒç»­æ—¶é—´ç¼–é€ (å·²ä¹…)"),
        (r'.*æ•°æ—¥', "æ—¶é—´ç¼–é€ (æ•°æ—¥)"),
        (r'.*ä¸èˆ’', "ç¨‹åº¦ç¼–é€ (ä¸èˆ’)"),
    ]
    
    patient_keywords = set(patient_message.lower().split())
    found_fabrications = []
    
    for pattern, description in fabricated_symptoms:
        if re.search(pattern, ai_response):
            # æ£€æŸ¥æ‚£è€…æ¶ˆæ¯ä¸­æ˜¯å¦åŒ…å«ç›¸å…³å…³é”®è¯
            pattern_keywords = re.findall(r'[\u4e00-\u9fff]+', pattern.replace('.*', '').replace('[', '').replace(']', ''))
            
            # å¦‚æœAIå›å¤ä¸­çš„ç—‡çŠ¶æè¿°åœ¨æ‚£è€…æ¶ˆæ¯ä¸­æ²¡æœ‰å¯¹åº”çš„å…³é”®è¯ï¼Œåˆ™è®¤ä¸ºæ˜¯ç¼–é€ 
            if not any(keyword in patient_message for keyword in pattern_keywords if len(keyword) > 1):
                found_fabrications.append(description)
    
    return ", ".join(found_fabrications) if found_fabrications else ""


# ä¸¥æ ¼çš„æœ›è¯Šåˆ‡è¯Šç¼–é€ æ£€æµ‹
STRICT_TONGUE_PULSE_PATTERNS = [
    # æœ›è¯Šç¼–é€ æ¨¡å¼ - æ›´ä¸¥æ ¼
    (r'é¢è‰²[^ï¼Œã€‚]*?æ·¡ç™½', "é¢è‰²æ·¡ç™½æè¿°"),
    (r'é¢è‰²[^ï¼Œã€‚]*?ç•¥çº¢', "é¢è‰²ç•¥çº¢æè¿°"),
    (r'é¢è‰²[^ï¼Œã€‚]*?è‹ç™½', "é¢è‰²è‹ç™½æè¿°"),
    (r'é¢è‰²[^ï¼Œã€‚]*?æ½®çº¢', "é¢è‰²æ½®çº¢æè¿°"),
    (r'èˆŒè´¨[^ï¼Œã€‚]*?æ·¡çº¢', "èˆŒè´¨æ·¡çº¢æè¿°"),
    (r'èˆŒè´¨[^ï¼Œã€‚]*?çº¢', "èˆŒè´¨çº¢æè¿°"),
    (r'èˆŒè´¨[^ï¼Œã€‚]*?æš—', "èˆŒè´¨æš—æè¿°"),
    (r'è‹”[^ï¼Œã€‚]*?è–„ç™½', "è‹”è–„ç™½æè¿°"),
    (r'è‹”[^ï¼Œã€‚]*?è–„é»„', "è‹”è–„é»„æè¿°"),
    (r'è‹”[^ï¼Œã€‚]*?åš', "è‹”åšæè¿°"),
    (r'èˆŒè¾¹[^ï¼Œã€‚]*?é½¿ç—•', "èˆŒè¾¹é½¿ç—•æè¿°"),
    (r'èˆŒå°–[^ï¼Œã€‚]*?çº¢', "èˆŒå°–çº¢æè¿°"),
    
    # åˆ‡è¯Šç¼–é€ æ¨¡å¼ - æ›´ä¸¥æ ¼  
    (r'è„‰[^ï¼Œã€‚]*?æµ®', "è„‰æµ®æè¿°"),
    (r'è„‰[^ï¼Œã€‚]*?æ²‰', "è„‰æ²‰æè¿°"),
    (r'è„‰[^ï¼Œã€‚]*?ç¼“', "è„‰ç¼“æè¿°"),
    (r'è„‰[^ï¼Œã€‚]*?æ•°', "è„‰æ•°æè¿°"),
    (r'è„‰[^ï¼Œã€‚]*?ç»†', "è„‰ç»†æè¿°"),
    (r'è„‰[^ï¼Œã€‚]*?å¼±', "è„‰å¼±æè¿°"),
    (r'è„‰[^ï¼Œã€‚]*?æ»‘', "è„‰æ»‘æè¿°"),
    (r'è„‰[^ï¼Œã€‚]*?å¼¦', "è„‰å¼¦æè¿°"),
    (r'è„‰è±¡[^ï¼Œã€‚]*?æµ®ç¼“', "è„‰è±¡æµ®ç¼“æè¿°"),
    (r'è„‰è±¡[^ï¼Œã€‚]*?ç»†å¼±', "è„‰è±¡ç»†å¼±æè¿°"),
    (r'è„‰è±¡[^ï¼Œã€‚]*?æ²‰ç»†', "è„‰è±¡æ²‰ç»†æè¿°"),
    
    # ç»„åˆç¼–é€ æ¨¡å¼
    (r'æç¤º.*?ä¸è¶³', "æç¤ºè¯å€™æè¿°"),
    (r'è¯´æ˜.*?æœª', "è¯´æ˜ç—…æœºæè¿°"),
]

def detect_fabricated_examination(text: str, has_actual_examination: bool = False) -> list:
    """æ£€æµ‹ç¼–é€ çš„æœ›è¯Šåˆ‡è¯Šå†…å®¹"""
    if has_actual_examination:
        return []  # å¦‚æœæœ‰å®é™…æ£€æŸ¥ï¼Œåˆ™ä¸æ£€æµ‹
    
    fabricated_items = []
    
    # æ£€æµ‹æœ›è¯Šå†…å®¹
    if "æœ›è¯Š" in text or "é¢è‰²" in text or "èˆŒ" in text:
        for pattern, description in STRICT_TONGUE_PULSE_PATTERNS:
            if re.search(pattern, text):
                fabricated_items.append(f"ç¼–é€ {description}")
    
    # æ£€æµ‹åˆ‡è¯Šå†…å®¹  
    if "åˆ‡è¯Š" in text or "è„‰" in text:
        for pattern, description in STRICT_TONGUE_PULSE_PATTERNS:
            if "è„‰" in pattern and re.search(pattern, text):
                fabricated_items.append(f"ç¼–é€ {description}")
    
    return fabricated_items


# ç»¼åˆåŒ»ç–—å®‰å…¨æ£€æŸ¥å‡½æ•° (èˆŒè±¡ã€è„‰è±¡ã€ç—‡çŠ¶ç¼–é€ )
def check_medical_safety(ai_response: str, has_tongue_image: bool, patient_described_tongue: str = "", image_analysis_successful: bool = False, original_patient_message: str = "") -> tuple[bool, str]:
    """
    æ£€æŸ¥AIå›å¤ä¸­çš„åŒ»ç–—ä¿¡æ¯æ˜¯å¦å®‰å…¨ï¼ˆèˆŒè±¡ã€è„‰è±¡ã€ç—‡çŠ¶ç¼–é€ ï¼‰
    è¿”å›: (is_safe, error_message)
    
    å®‰å…¨ç­–ç•¥ï¼š
    1. èˆŒè±¡æ£€æŸ¥ï¼šæœ‰å›¾ç‰‡ä¸”åˆ†ææˆåŠŸ â†’ å…è®¸èˆŒè±¡æè¿°  
    2. è„‰è±¡æ£€æŸ¥ï¼šç»ä¸å…è®¸ç¼–é€ è„‰è±¡æè¿°
    3. ç—‡çŠ¶æ£€æŸ¥ï¼šä¸å…è®¸æ·»åŠ æ‚£è€…æœªæ˜ç¡®æè¿°çš„ç—‡çŠ¶ç»†èŠ‚
    4. æ‚£è€…è‡ªè¿°ï¼šå…è®¸AIå¼•ç”¨æ‚£è€…æ˜ç¡®æè¿°çš„å†…å®¹
    5. ã€æ–°å¢ã€‘æœ›è¯Šåˆ‡è¯Šä¸¥æ ¼æ£€æµ‹ï¼šç»ä¸å…è®¸ç¼–é€ ä»»ä½•ä½“å¾ä¿¡æ¯
    """
    
    # 1. ä¸¥æ ¼æ£€æµ‹ç¼–é€ çš„æœ›è¯Šåˆ‡è¯Šå†…å®¹
    has_actual_examination = has_tongue_image and image_analysis_successful
    fabricated_examinations = detect_fabricated_examination(ai_response, has_actual_examination)
    
    if fabricated_examinations:
        error_msg = f"æ£€æµ‹åˆ°ç¼–é€ çš„ä½“å¾ä¿¡æ¯: {', '.join(fabricated_examinations)}"
        return False, error_msg
    
    # 2. åŸæœ‰çš„æ£€æŸ¥é€»è¾‘
    # å…³é”®æ£€æŸ¥ï¼šåªæœ‰å›¾ç‰‡åˆ†æçœŸæ­£æˆåŠŸæ—¶æ‰å…è®¸èˆŒè±¡æè¿°
    if has_tongue_image and image_analysis_successful:
        return True, ""
    
    # ç¬¬ä¸€æ­¥ï¼šæ£€æŸ¥ç—‡çŠ¶ç¼–é€ 
    if original_patient_message:
        symptom_fabrication = check_symptom_fabrication(ai_response, original_patient_message)
        if symptom_fabrication:
            return False, f"æ£€æµ‹åˆ°ç—‡çŠ¶ç¼–é€ : {symptom_fabrication}"
    
    # ç¬¬äºŒæ­¥ï¼šæ£€æŸ¥æ˜¯å¦æœ‰AIç¼–é€ çš„èˆŒè±¡å’Œè„‰è±¡æè¿° - å¢å¼ºæ£€æµ‹æ¨¡å¼
    dangerous_patterns = [
        # èˆŒè±¡ç›¸å…³ - åŸºç¡€æ¨¡å¼
        r'å¾è§‚å…¶èˆŒ.*[æ·¡çº¢ç´«æš—]',           # "å¾è§‚å…¶èˆŒæ·¡çº¢"ç­‰æ˜æ˜¾ç¼–é€ 
        r'èˆŒè´¨[æ·¡çº¢ç´«æš—].*è‹”[è–„åš][ç™½é»„è…»]',    # å®Œæ•´èˆŒè±¡æè¿°
        r'æœ›è¯Šæ‰€è§.*èˆŒè‹”.*[è–„åš][ç™½é»„è…»]',     # æœ›è¯Šä¸­çš„èˆŒè±¡
        r'èˆŒ[è´¨è‰²][æ·¡çº¢ç´«æš—].*[ï¼Œ,].*è‹”',      # èˆŒè´¨+è‹”è±¡ç»„åˆ
        r'èˆŒè¾¹.*é½¿ç—•.*è‹”',                    # èˆŒè¾¹é½¿ç—•+è‹”è±¡
        r'è§‚å…¶èˆŒè±¡.*[æ·¡çº¢ç´«æš—]',              # "è§‚å…¶èˆŒè±¡"
        r'èˆŒè¯Š.*[æ·¡çº¢ç´«æš—].*è‹”',              # èˆŒè¯Šç›¸å…³
        r'èˆŒ[æ·¡çº¢ç´«æš—][ï¼Œ,].*è‹”[è–„åšå°‘][ç™½é»„è…»]',  # "èˆŒæ·¡çº¢ï¼Œè‹”è–„ç™½"æ ¼å¼
        r'<æœ›è¯Šæ‰€è§>.*èˆŒ.*[æ·¡çº¢ç´«æš—].*è‹”.*</æœ›è¯Šæ‰€è§>', # XMLæ ¼å¼ä¸­çš„æœ›è¯Š
        r'èˆŒ.*[æ·¡çº¢ç´«æš—].*æˆ–.*è‹”',            # "èˆŒæ·¡çº¢æˆ–å°‘è‹”"ç­‰
        r'è‹”[è–„åš][ç™½é»„è…»]æˆ–[å°‘æ— ]è‹”',         # "è‹”è–„ç™½æˆ–å°‘è‹”"ç­‰
        
        # èˆŒè±¡ç›¸å…³ - æ–°å¢å¼ºåŒ–æ¨¡å¼ (é’ˆå¯¹ç”¨æˆ·åé¦ˆçš„é—®é¢˜)
        r'èˆŒè±¡[ï¼š:].*èˆŒ.*[çº¢ç™½é»„]',            # "èˆŒè±¡ï¼šèˆŒè¾¹å°–çº¢"ç­‰æ¨¡å¼
        r'èˆŒè¾¹[å°–]?çº¢',                       # "èˆŒè¾¹çº¢"ã€"èˆŒè¾¹å°–çº¢"
        r'è‹”è–„[ç™½é»„]æˆ–è–„[é»„ç™½]',               # "è‹”è–„ç™½æˆ–è–„é»„"
        r'èˆŒ.*çº¢.*[ï¼Œ,].*è‹”.*[ç™½é»„]',         # "èˆŒè¾¹å°–çº¢ï¼Œè‹”è–„ç™½"
        r'èˆŒè¾¹.*çº¢.*è‹”',                      # èˆŒè¾¹çº¢+è‹”è±¡ç»„åˆ
        r'èˆŒ.*å°–.*çº¢',                        # "èˆŒå°–çº¢"ç­‰
        r'èˆŒ.*[è¾¹å°–].*çº¢.*è‹”',                # èˆŒè¾¹å°–çº¢+è‹”è±¡
        r'èˆŒ.*è‹”.*[è–„åš].*[ç™½é»„è…»]',          # ä»»ä½•èˆŒè‹”å…·ä½“æè¿°
        r'èˆŒè‹”.*[è–„åš].*[ç™½é»„è…»]',            # ç›´æ¥çš„èˆŒè‹”æè¿°
        r'èˆŒ.*çº¢.*æˆ–.*è‹”',                    # "èˆŒçº¢æˆ–è‹”ç™½"ç­‰æ¨¡å¼
        
        # è„‰è±¡ç›¸å…³ - åŸºç¡€æ¨¡å¼
        r'è„‰è±¡[æ¿¡ç¼“ç»†æ•°å¼¦æ»‘æ²‰æµ®æ´ªå¾®]',         # "è„‰è±¡æ¿¡ç¼“"ç­‰ç¼–é€ 
        r'è„‰[æ¿¡ç¼“ç»†æ•°å¼¦æ»‘æ²‰æµ®æ´ªå¾®][ï¼Œ,]',      # "è„‰ç¼“ï¼Œ"ç­‰ç¼–é€   
        r'è„‰.*[æ¿¡ç¼“ç»†æ•°å¼¦æ»‘æ²‰æµ®æ´ªå¾®].*[ï¼Œ,]',  # "è„‰è±¡ç¼“å¼±ï¼Œ"ç­‰
        r'åˆ‡è¯Š.*è„‰.*[æ¿¡ç¼“ç»†æ•°å¼¦æ»‘æ²‰æµ®æ´ªå¾®]',   # åˆ‡è¯Šä¸­çš„è„‰è±¡
        r'<æœ›è¯Šæ‰€è§>.*è„‰.*[æ¿¡ç¼“ç»†æ•°å¼¦æ»‘æ²‰æµ®æ´ªå¾®].*</æœ›è¯Šæ‰€è§>', # XMLä¸­è„‰è±¡
        r'è„‰è¯Š.*[æ¿¡ç¼“ç»†æ•°å¼¦æ»‘æ²‰æµ®æ´ªå¾®]',       # è„‰è¯Šç›¸å…³
        r'è¯Šå¾—.*è„‰.*[æ¿¡ç¼“ç»†æ•°å¼¦æ»‘æ²‰æµ®æ´ªå¾®]',   # "è¯Šå¾—è„‰è±¡"
        r'æŒ‰å…¶è„‰.*[æ¿¡ç¼“ç»†æ•°å¼¦æ»‘æ²‰æµ®æ´ªå¾®]',     # "æŒ‰å…¶è„‰"ç­‰
        
        # è„‰è±¡ç›¸å…³ - æ–°å¢å¼ºåŒ–æ¨¡å¼
        r'è„‰è±¡[ï¼š:].*è„‰.*[æ¿¡ç¼“ç»†æ•°å¼¦æ»‘æ²‰æµ®æ´ªå¾®]',  # "è„‰è±¡ï¼šè„‰æµ®æ•°"ç­‰
        r'è„‰æµ®æ•°',                            # å…·ä½“çš„è„‰è±¡æè¿°
        r'è„‰.*æµ®.*æ•°',                        # "è„‰æµ®æ•°"ç­‰ç»„åˆ
        r'è„‰.*[æ¿¡ç¼“ç»†æ•°å¼¦æ»‘æ²‰æµ®æ´ªå¾®].*[æ¿¡ç¼“ç»†æ•°å¼¦æ»‘æ²‰æµ®æ´ªå¾®]', # å¤šä¸ªè„‰è±¡ç‰¹å¾
        
        # é€šç”¨åŒ»ç–—ä¿¡æ¯ç¼–é€ æ¨¡å¼
        r'è¾¨è¯è¦ç‚¹.*èˆŒè±¡',                    # è¾¨è¯è¦ç‚¹ä¸­æåˆ°èˆŒè±¡
        r'è¾¨è¯è¦ç‚¹.*è„‰è±¡',                    # è¾¨è¯è¦ç‚¹ä¸­æåˆ°è„‰è±¡
        r'æœ›è¯Š.*èˆŒ',                          # æœ›è¯Šæåˆ°èˆŒ
        r'åˆ‡è¯Š.*è„‰',                          # åˆ‡è¯Šæåˆ°è„‰
        r'å››è¯Š.*èˆŒ.*è„‰',                      # å››è¯Šä¸­åŒæ—¶æåˆ°èˆŒè„‰
    ]
    
    found_dangerous = []
    for pattern in dangerous_patterns:
        matches = re.findall(pattern, ai_response)
        if matches:
            found_dangerous.extend(matches)
    
    # å¦‚æœæ‚£è€…è‡ªå·±æè¿°äº†èˆŒè±¡æˆ–è„‰è±¡ï¼Œä¹Ÿå…è®¸AIå¼•ç”¨
    if patient_described_tongue and found_dangerous:
        # æ£€æŸ¥æ‚£è€…æè¿°ä¸­æ˜¯å¦åŒ…å«ç›¸å…³èˆŒè±¡å’Œè„‰è±¡ç‰¹å¾
        tongue_features = ["æ·¡çº¢", "çº¢", "æš—çº¢", "ç´«", "è–„ç™½", "åšç™½", "é»„", "è…»", "é½¿ç—•"]
        pulse_features = ["æ¿¡", "ç¼“", "ç»†", "æ•°", "å¼¦", "æ»‘", "æ²‰", "æµ®", "æ´ª", "å¾®", "è„‰è±¡", "è„‰æ"]
        all_features = tongue_features + pulse_features
        
        patient_features = [feature for feature in all_features if feature in patient_described_tongue]
        
        if patient_features:
            # æ£€æŸ¥AIå›å¤ä¸­æ˜¯å¦åªæ˜¯å¼•ç”¨äº†æ‚£è€…æåˆ°çš„ç‰¹å¾
            for feature in patient_features:
                if feature in ai_response:
                    return True, ""
    
    if found_dangerous:
        error_msg = f"æ£€æµ‹åˆ°å¯èƒ½çš„æ— æ ¹æ®èˆŒè±¡/è„‰è±¡æè¿°: {found_dangerous}"
        return False, error_msg
    
    return True, ""

# æ¸…ç†AIå›å¤ä¸­çš„éæ³•åŒ»ç–—ä¿¡æ¯
def normalize_prescription_dosage(prescription_text: str) -> str:
    """è§„èŒƒåŒ–å¤„æ–¹ç”¨é‡ï¼Œå°†èŒƒå›´ç”¨é‡è½¬æ¢ä¸ºç¡®å®šç”¨é‡"""
    import re
    
    # åŒ¹é… "è¯å æ•°å­—-æ•°å­—g" çš„æ¨¡å¼
    pattern = r'(\w+)\s+(\d+)-(\d+)g'
    
    def replace_range(match):
        herb_name = match.group(1)
        min_dose = int(match.group(2))
        max_dose = int(match.group(3))
        
        # é€‰æ‹©ä¸­é—´å€¼æˆ–åå‘è¾ƒå°å€¼
        if max_dose - min_dose <= 3:
            recommended_dose = min_dose + 1  # åå‘è¾ƒå°å€¼
        else:
            recommended_dose = (min_dose + max_dose) // 2  # ä¸­é—´å€¼
            
        return f"{herb_name} {recommended_dose}g"
    
    # åº”ç”¨è§„èŒƒåŒ–
    normalized = re.sub(pattern, replace_range, prescription_text)
    return normalized

def extract_herbs_from_prescription(prescription_text: str):
    """ä»å¤„æ–¹æ–‡æœ¬ä¸­æå–è¯æä¿¡æ¯ - æ”¯æŒè¡¨æ ¼æ ¼å¼"""
    import re
    
    herbs = []
    lines = prescription_text.split('\n')
    
    # å…ˆå°è¯•è¡¨æ ¼æ ¼å¼æå–
    table_herbs = extract_herbs_from_table(prescription_text)
    if table_herbs:
        return table_herbs
    
    # å¦‚æœä¸æ˜¯è¡¨æ ¼æ ¼å¼ï¼Œä½¿ç”¨åŸæ¥çš„é€»è¾‘
    for line in lines:
        line = line.strip()
        if not line:
            continue
            
        # è·³è¿‡æ˜æ˜¾çš„æ ‡é¢˜è¡Œå’Œç”¨æ³•è¡Œ
        skip_patterns = [
            r'^ã€.*ã€‘$', r'^\*\*.*\*\*$', r'^##.*$', r'^###.*$',
            'ç”¨æ³•', 'ç…æœ', 'åˆ¶æ³•', 'åŠŸæ•ˆ', 'æ³¨æ„', 'æœæ³•', 'ã€ç”¨æ³•ã€‘', 'ã€æ³¨æ„ã€‘'
        ]
        
        should_skip = any(re.search(pattern, line, re.IGNORECASE) for pattern in skip_patterns)
        if should_skip:
            continue
        
        # å¤šç§è¯æåŒ¹é…æ¨¡å¼ - ä¿®å¤ä¸­æ–‡å­—ç¬¦åŒ¹é…
        herb_patterns = [
            # å¸¦æ‹¬å·æ ¼å¼: è–„è·ï¼ˆå‡€ï¼‰6g
            r'([\u4e00-\u9fff]+(?:ï¼ˆ[\u4e00-\u9fff]*ï¼‰)?)\s*(\d+(?:\.\d+)?)[gGgå…‹]',
            # æ ‡å‡†æ ¼å¼: äººå‚ 9g
            r'([\u4e00-\u9fff]+)\s+(\d+(?:\.\d+)?)[gGgå…‹]',
            # å¸¦å†’å·: äººå‚: 9g  
            r'([\u4e00-\u9fff]+)\s*[:ï¼š]\s*(\d+(?:\.\d+)?)[gGgå…‹]',
            # ç´§å¯†æ ¼å¼: äººå‚9g
            r'([\u4e00-\u9fff]+)(\d+(?:\.\d+)?)[gGgå…‹]',
            # åºå·æ ¼å¼: 1. äººå‚ 9g
            r'\d+[\.\)]\s*([\u4e00-\u9fff]+(?:ï¼ˆ[\u4e00-\u9fff]*ï¼‰)?)\s*(\d+(?:\.\d+)?)[gGgå…‹]',
            # ä¸­æ–‡å•ä½: äººå‚9å…‹
            r'([\u4e00-\u9fff]+(?:ï¼ˆ[\u4e00-\u9fff]*ï¼‰)?)\s*(\d+(?:\.\d+)?)å…‹',
        ]
        
        for pattern in herb_patterns:
            matches = re.findall(pattern, line)
            for match in matches:
                if len(match) == 2:
                    herb_name, dosage = match
                    # è¿‡æ»¤æ‰æ˜æ˜¾ä¸æ˜¯è¯åçš„è¯å’Œé‡å¤é¡¹
                    if len(herb_name) >= 2 and herb_name not in ['ç”¨æ³•', 'æ³¨æ„', 'åŠŸæ•ˆ', 'åˆ¶æ³•']:
                        # é¿å…é‡å¤æ·»åŠ åŒä¸€è¯æ
                        if (herb_name.strip(), dosage.strip()) not in herbs:
                            herbs.append((herb_name.strip(), dosage.strip()))
    
    return herbs

def extract_herbs_from_table(text: str):
    """ä»markdownè¡¨æ ¼ä¸­æå–è¯æä¿¡æ¯"""
    import re
    
    herbs = []
    lines = text.split('\n')
    
    # æ£€æµ‹æ˜¯å¦åŒ…å«è¡¨æ ¼æ ¼å¼
    table_indicators = ['è¯ç‰©', 'å‰‚é‡', '|', '---']
    if not any(indicator in text for indicator in table_indicators):
        return []
    
    # å¯»æ‰¾è¡¨æ ¼æ•°æ®è¡Œ
    for line in lines:
        line = line.strip()
        
        # è·³è¿‡è¡¨å¤´å’Œåˆ†éš”çº¿
        if not line or 'è¯ç‰©' in line or '---' in line or 'åŠŸæ•ˆ' in line:
            continue
            
        # åŒ¹é…è¡¨æ ¼è¡Œæ ¼å¼: | è¯å | å‰‚é‡ | å…¶ä»– |
        table_match = re.search(r'\|\s*([ä¸€-é¾Ÿ\u4e00-\u9fff]+(?:\ï¼ˆ[^ï¼‰]*\ï¼‰)?)\s*\|\s*(\d+(?:\.\d+)?)g?\s*\|', line)
        if table_match:
            herb_name = table_match.group(1).strip()
            dosage = table_match.group(2).strip()
            
            # æ¸…ç†è¯åï¼ˆå»é™¤æ‹¬å·å†…å®¹å¦‚"ï¼ˆåˆ¶ï¼‰"ï¼‰
            herb_name = re.sub(r'[ï¼ˆ\(][^ï¼‰\)]*[ï¼‰\)]', '', herb_name).strip()
            
            # è¿‡æ»¤æœ‰æ•ˆè¯å
            if len(herb_name) >= 2 and herb_name not in ['è¯ç‰©', 'å‰‚é‡', 'åŠŸæ•ˆ', 'è¯´æ˜']:
                if (herb_name, dosage) not in herbs:
                    herbs.append((herb_name, dosage))
    
    return herbs

def standardize_prescription_format(ai_response: str) -> str:
    """ç»Ÿä¸€å¤„æ–¹æ ¼å¼ä¸ºå¢å¼ºç‰ˆæ ‡å‡†æ ¼å¼ - æ”¯æŒå±‚æ¬¡æ„Ÿå’Œè§†è§‰æ•ˆæœ"""
    import re
    
    # å…ˆæ¸…ç†å¯èƒ½å­˜åœ¨çš„é‡å¤æ ‡ç­¾å’Œæ ¼å¼é”™è¯¯
    ai_response = re.sub(r'\*\*ã€å¤„æ–¹ã€‘\*\*[\s\n]*\*\*ã€å¤„æ–¹ã€‘\*\*', '**ã€å¤„æ–¹ã€‘**', ai_response)
    ai_response = re.sub(r'ã€å¤„æ–¹ã€‘[\s\n]*ã€å¤„æ–¹ã€‘', 'ã€å¤„æ–¹ã€‘', ai_response)
    ai_response = re.sub(r'\*\*ã€å¤„æ–¹ã€‘\*\*[\s\n]*\*\*\*\*', '**ã€å¤„æ–¹ã€‘**', ai_response)
    
    # æ”¹è¿›çš„å¤„æ–¹è¯†åˆ«æ­£åˆ™è¡¨è¾¾å¼ - æ”¯æŒè¡¨æ ¼æ ¼å¼
    prescription_patterns = [
        # è¡¨æ ¼æ ¼å¼ - æ–°å¢
        (r'(?:\|\s*è¯ç‰©.*?\|.*?\n.*?---.*?\n)(.*?)(?=\n\n|---|###|$)', 'è¡¨æ ¼æ ¼å¼'),
        # XMLæ ¼å¼
        (r'<å¤„æ–¹[^>]*>(.*?)</å¤„æ–¹>', 'XML'),
        # æ ‡å‡†æ ‡è®°æ ¼å¼ - æ”¹è¿›ç‰ˆ
        (r'ã€å¤„æ–¹ã€‘[ï¼š:]?\s*(.*?)(?=\n\n|ã€[^ã€‘]*ã€‘|\*\*ã€|$)', 'æ ‡å‡†æ ‡è®°'),
        (r'\*\*ã€å¤„æ–¹ã€‘\*\*[ï¼š:]?\s*(.*?)(?=\n\n|ã€[^ã€‘]*ã€‘|\*\*ã€|$)', 'æ ‡å‡†æ ‡è®°å¸¦æ˜Ÿå·'),
        # å…¶ä»–å¸¸è§æ ¼å¼
        (r'(?:å¤„æ–¹|æ–¹å‰‚|è¯æ–¹)[ï¼š:]?\s*(.*?)(?=\n\n|\nã€|\n\*\*|$)', 'é€šç”¨'),
    ]
    
    processed = False
    
    for pattern, pattern_name in prescription_patterns:
        if processed:
            break
            
        matches = list(re.finditer(pattern, ai_response, re.DOTALL | re.IGNORECASE))
        
        for match in matches:
            original_prescription = match.group(1).strip() if len(match.groups()) > 0 else match.group(0).strip()
            
            # ç¡®ä¿å¤„æ–¹å†…å®¹æœ‰æ•ˆ
            if len(original_prescription) < 3:
                continue
                
            # ä½¿ç”¨æ–°çš„è¯ææå–å‡½æ•°
            herbs = extract_herbs_from_prescription(original_prescription)
            
            if not herbs or len(herbs) < 1:
                continue
            
            # ç”Ÿæˆå¢å¼ºç‰ˆæ ‡å‡†æ ¼å¼ - å±‚æ¬¡æ¸…æ™°ã€è§†è§‰ç¾è§‚
            standardized_prescription = generate_enhanced_prescription_format(herbs)
            
            # æ›¿æ¢åŸå§‹å¤„æ–¹ - å®Œå…¨æ›¿æ¢æ•´ä¸ªè¡¨æ ¼åŒºåŸŸ
            ai_response = ai_response.replace(match.group(0), standardized_prescription)
            processed = True
            break
    
    return ai_response

def generate_enhanced_prescription_format(herbs: list) -> str:
    """ç”Ÿæˆå¢å¼ºç‰ˆå¤„æ–¹æ ¼å¼ - å±‚æ¬¡åˆ†æ˜ã€è§†è§‰ç¾è§‚"""
    
    # ğŸ¯ å¤„æ–¹æ ‡é¢˜ - æ˜¾çœ¼çš„æ ‡é¢˜
    prescription_text = "\n\n" + "=" * 50 + "\n"
    prescription_text += "# ğŸ¥ **ä¸­åŒ»å¤„æ–¹å•**\n"
    prescription_text += "=" * 50 + "\n\n"
    
    # ğŸ’Š å¤„æ–¹å†…å®¹ - æ¸…æ™°çš„è¯ç‰©åˆ—è¡¨
    prescription_text += "## **ğŸ“‹ å¤„æ–¹ç»„æˆ**\n\n"
    
    herb_count = len(herbs)
    for i, (herb_name, dosage) in enumerate(herbs, 1):
        # ä½¿ç”¨ç¼–å·å’Œé¢œè‰²å¼ºè°ƒ
        prescription_text += f"**{i}.** **`{herb_name}`** â€”â€”â€” **{dosage}g**\n"
    
    prescription_text += f"\n> **å¤„æ–¹è¯å‘³æ€»æ•°ï¼š** {herb_count} å‘³\n\n"
    
    # ğŸ”¥ ç…æœæ–¹æ³• - è¯¦ç»†ç”¨æ³•è¯´æ˜
    prescription_text += "## **âš¡ ç…æœæ–¹æ³•**\n\n"
    prescription_text += "### **ç…åˆ¶æ–¹æ³•ï¼š**\n"
    prescription_text += "- ğŸ”¸ **ç¬¬ä¸€ç…ï¼š** åŠ æ¸…æ°´500mlï¼Œæµ¸æ³¡30åˆ†é’Ÿåï¼Œå¤§ç«ç…®æ²¸è½¬å°ç«ç…ç…®25åˆ†é’Ÿ\n"
    prescription_text += "- ğŸ”¸ **ç¬¬äºŒç…ï¼š** åŠ æ¸…æ°´400mlï¼Œç›´æ¥ç…ç…®20åˆ†é’Ÿ\n"
    prescription_text += "- ğŸ”¸ **æ··åˆï¼š** ä¸¤æ¬¡è¯æ±æ··åˆï¼Œçº¦å¾—è¯æ¶²300ml\n\n"
    
    prescription_text += "### **æœç”¨æ–¹æ³•ï¼š**\n"
    prescription_text += "- ğŸ”¸ **ç”¨é‡ï¼š** æ¯æ—¥1å‰‚ï¼Œåˆ†2æ¬¡æ¸©æœ\n"
    prescription_text += "- ğŸ”¸ **æ—¶é—´ï¼š** é¥­å1å°æ—¶æœç”¨ï¼ˆæ—©æ™šå„1æ¬¡ï¼‰\n"
    prescription_text += "- ğŸ”¸ **æ¸©åº¦ï¼š** æ¸©çƒ­æœç”¨ï¼Œé¿å…è¿‡çƒ«æˆ–è¿‡å‡‰\n\n"
    
    # ğŸ“ ç”¨è¯æ³¨æ„äº‹é¡¹
    prescription_text += "## **âš ï¸ é‡è¦æ³¨æ„äº‹é¡¹**\n\n"
    prescription_text += "### **ğŸš¨ å®‰å…¨æé†’ï¼š**\n"
    prescription_text += "- **â— å¿…é¡»åœ¨æ‰§ä¸šä¸­åŒ»å¸ˆæŒ‡å¯¼ä¸‹ä½¿ç”¨**\n"
    prescription_text += "- **â— å­•å¦‡ã€å“ºä¹³æœŸå¦‡å¥³æ…ç”¨**\n"
    prescription_text += "- **â— æœè¯æœŸé—´å¿Œé£Ÿç”Ÿå†·ã€è¾›è¾£ã€æ²¹è…»é£Ÿç‰©**\n"
    prescription_text += "- **â— å¦‚æœ‰è¿‡æ•å²ï¼Œè¯·å‘ŠçŸ¥åŒ»å¸ˆ**\n\n"
    
    prescription_text += "### **ğŸ‘€ ç”¨è¯è§‚å¯Ÿï¼š**\n"
    prescription_text += "- ğŸ”¹ è§‚å¯Ÿç—‡çŠ¶å˜åŒ–æƒ…å†µ\n"
    prescription_text += "- ğŸ”¹ æ³¨æ„æœ‰æ— ä¸è‰¯ååº”\n"
    prescription_text += "- ğŸ”¹ è®°å½•æœè¯åçš„æ„Ÿå—\n\n"
    
    # ğŸ”„ å¤è¯Šè¦æ±‚
    prescription_text += "## **ğŸ”„ å¤è¯Šå®‰æ’**\n\n"
    prescription_text += "### **ğŸ“… å¤è¯Šæ—¶é—´ï¼š**\n"
    prescription_text += "- **é¦–æ¬¡å¤è¯Šï¼š** æœè¯3å¤©å\n"
    prescription_text += "- **åç»­å¤è¯Šï¼š** æ¯å‘¨1æ¬¡ï¼Œå…±3æ¬¡\n\n"
    
    prescription_text += "### **ğŸ“‹ å¤è¯Šè¦ç‚¹ï¼š**\n"
    prescription_text += "- âœ… ä¸»è¦ç—‡çŠ¶å˜åŒ–æƒ…å†µ\n"
    prescription_text += "- âœ… è¯ç‰©ç–—æ•ˆåŠä¸è‰¯ååº”\n"
    prescription_text += "- âœ… é£Ÿæ¬²ã€ç¡çœ ã€äºŒä¾¿æƒ…å†µ\n"
    prescription_text += "- âœ… èˆŒè±¡ã€è„‰è±¡å˜åŒ–\n\n"
    
    # ğŸ“ åŒ»ç–—å…è´£å£°æ˜
    prescription_text += "## **ğŸ“ åŒ»ç–—å…è´£å£°æ˜**\n\n"
    prescription_text += "> **ğŸ”´ é‡è¦å£°æ˜ï¼š**\n"
    prescription_text += "> æœ¬å¤„æ–¹ä¸ºAIè¾…åŠ©ç”Ÿæˆçš„ä¸­åŒ»å»ºè®®ï¼Œä»…ä¾›å‚è€ƒï¼Œä¸èƒ½æ›¿ä»£æ­£è§„åŒ»é™¢çš„ä¸“ä¸šè¯Šæ–­å’Œæ²»ç–—ã€‚\n"
    prescription_text += "> - **å»ºè®®åœ¨æ‰§ä¸šä¸­åŒ»å¸ˆæŒ‡å¯¼ä¸‹ä½¿ç”¨**\n\n"
    
    prescription_text += "---\n"
    prescription_text += "*ğŸ•’ å¤„æ–¹ç”Ÿæˆæ—¶é—´ï¼š" + "ä»Šæ—¥" + "  |  ğŸ’» AIä¸­åŒ»åŠ©æ‰‹*\n"
    prescription_text += "---\n\n"
    
    return prescription_text

def enhance_diagnosis_format(ai_response: str) -> str:
    """å¢å¼ºæ•´ä½“è¯Šç–—æ–¹æ¡ˆçš„æ ¼å¼åŒ– - ä¸ºæ‰€æœ‰åŒ»ç”Ÿå›å¤æ·»åŠ å±‚æ¬¡æ„Ÿ"""
    import re
    
    # 1. å¼ºåŒ–æ ‡é¢˜å±‚æ¬¡
    # å°†ã€xxxã€‘æ ¼å¼è½¬æ¢ä¸ºæ›´æ˜¾çœ¼çš„æ ¼å¼
    ai_response = re.sub(r'ã€([^ã€‘]+)ã€‘', r'## **ğŸ”¸ \1**', ai_response)
    
    # 2. å¼ºåŒ–é‡è¦åŒ»å­¦æœ¯è¯­
    medical_terms = [
        'è¾¨è¯è®ºæ²»', 'è¯å‹', 'ç—…æœº', 'æ²»æ³•', 'æ–¹å‰‚', 'åŠ å‡',
        'è„¾è™š', 'è‚éƒ', 'è‚¾é˜³è™š', 'è‚¾é˜´è™š', 'è¡€ç˜€', 'ç—°æ¹¿',
        'é£å¯’', 'é£çƒ­', 'æ¹¿çƒ­', 'å¯’æ¹¿', 'æ°”æ»', 'è¡€è™š'
    ]
    
    for term in medical_terms:
        ai_response = re.sub(f'({term})', r'**\1**', ai_response)
    
    # 3. å¢å¼ºç—‡çŠ¶æè¿°çš„å¯è¯»æ€§
    symptom_keywords = ['å¤´ç—›', 'å‘çƒ­', 'å’³å—½', 'èƒ¸é—·', 'è…¹ç—›', 'ä¾¿ç§˜', 'è…¹æ³»', 'å¤±çœ ', 'ç–²å€¦']
    for symptom in symptom_keywords:
        ai_response = re.sub(f'({symptom})', r'**`\1`**', ai_response)
    
    # 4. ä¸ºé‡è¦æé†’æ·»åŠ è§†è§‰å¼ºè°ƒ
    ai_response = re.sub(r'(è¯·.*?å°±åŒ»|å»ºè®®.*?åŒ»å¸ˆ|æ³¨æ„.*?äº‹é¡¹)', r'> **âš ï¸ \1**', ai_response)
    
    # 5. ä¸ºæ–¹å‰‚åæ·»åŠ ç‰¹æ®Šæ ¼å¼
    formula_pattern = r'([ä¸€-ä¹å]+[æ±¤|æ•£|ä¸¸|è†|æ±|é¥®])'
    ai_response = re.sub(formula_pattern, r'**ğŸ“œ `\1`**', ai_response)
    
    return ai_response

def detect_and_filter_western_medicine(ai_response: str) -> tuple[bool, str]:
    """æ£€æµ‹å¹¶è¿‡æ»¤è¥¿åŒ»å†…å®¹ - åªæ¸…ç†æ˜ç¡®çš„è¥¿è¯æ¨èå’Œè¥¿åŒ»æ£€æŸ¥å»ºè®®"""
    import re
    
    # åªæ£€æµ‹æ˜ç¡®éœ€è¦è¿‡æ»¤çš„è¥¿åŒ»å†…å®¹ - å¤§å¹…ç¼©å‡å…³é”®è¯åˆ—è¡¨
    western_medicine_keywords = {
        # è¥¿è¯åç§° - åªä¿ç•™æ˜ç¡®çš„è¥¿è¯æ¨è
        'è¥¿è¯': ['å¥¥ç¾æ‹‰å”‘', 'é˜¿å¸åŒ¹æ—', 'å¸ƒæ´›èŠ¬', 'å¤´å­¢', 'é˜¿è«è¥¿æ—', 'é’éœ‰ç´ ', 'æ°¨èŒ¶ç¢±', 
               'åœ°å¡ç±³æ¾', 'æ³¼å°¼æ¾', 'ç¾æ‰˜æ´›å°”', 'ç¡è‹¯åœ°å¹³', 'é˜¿æ‰˜ä¼ä»–æ±€', 'äºŒç”²åŒèƒ',
               'èƒ°å²›ç´ ', 'åæ³•æ—', 'æ°¯å¡æ ¼é›·', 'é›·è´æ‹‰å”‘', 'å¤šæ½˜ç«‹é…®', 'è’™è„±çŸ³æ•£'],
        
        # è¥¿åŒ»æ£€æŸ¥é¡¹ç›® - åªæ£€æµ‹æ˜ç¡®çš„æ£€æŸ¥å»ºè®®
        'æ£€æŸ¥å»ºè®®': ['å»ºè®®åšCT', 'å»ºè®®åšMRI', 'å»ºè®®åšæ ¸ç£', 'å»ºè®®åšBè¶…', 'å»ºè®®åšå½©è¶…', 
                   'å»ºè®®åšXå…‰', 'å»ºè®®åšèƒƒé•œ', 'å»ºè®®åšè‚ é•œ', 'éœ€è¦åšè¡€å¸¸è§„', 'éœ€è¦æŸ¥è‚åŠŸèƒ½',
                   'å»ºè®®ç—…ç†æ£€æŸ¥', 'å»ºè®®æ´»æ£€', 'å»ºè®®ç©¿åˆº', 'å»ºè®®é€ å½±'],
        
        # æ˜ç¡®çš„è¥¿åŒ»è¯Šæ–­æœ¯è¯­ - ç§»é™¤"é«˜è¡€å‹"ç­‰å¸¸è§ç—…åï¼Œåªä¿ç•™ä¸¥é‡ç–¾ç—…
        'ä¸¥é‡ç–¾ç—…': ['ç™Œç—‡', 'æ¶æ€§è‚¿ç˜¤', 'å¿ƒè‚Œæ¢—æ­»', 'è„‘æ¢—æ­»'],
    }
    
    # æ£€æµ‹è¥¿åŒ»å†…å®¹
    found_western_content = []
    
    # ä¸­åŒ»åˆç†ä¸Šä¸‹æ–‡å…³é”®è¯ - å¦‚æœå›å¤åŒ…å«è¿™äº›ï¼Œè¯´æ˜æ˜¯åœ¨ä¸­åŒ»è¯­å¢ƒä¸‹è®¨è®º
    tcm_context_keywords = ['ä¸­åŒ»', 'ä¸­è¯', 'è¾¨è¯', 'è„è…‘', 'ç»ç»œ', 'æ°”è¡€', 'é˜´é˜³', 'å¯’çƒ­', 'è™šå®', 
                           'é£å¯’', 'é£çƒ­', 'æ¹¿çƒ­', 'ç—°æ¹¿', 'è¡€ç˜€', 'æ°”æ»', 'è‚éƒ', 'è„¾è™š', 'è‚¾è™š',
                           'æ¸©é˜³', 'æ»‹é˜´', 'æ¸…çƒ­', 'ç¥›æ¹¿', 'åŒ–ç—°', 'æ´»è¡€', 'ç†æ°”', 'è¯å€™', 'æ–¹å‰‚']
    
    # æ£€æŸ¥æ˜¯å¦åœ¨ä¸­åŒ»ä¸Šä¸‹æ–‡ä¸­
    has_tcm_context = any(tcm_keyword in ai_response for tcm_keyword in tcm_context_keywords)
    
    # å¦‚æœå·²ç»æ˜¯ä¸­åŒ»ä¸Šä¸‹æ–‡ï¼Œåªæ£€æµ‹æ˜ç¡®çš„è¥¿è¯æ¨è
    if has_tcm_context:
        # åªæ£€æµ‹è¥¿è¯æ¨è
        for keyword in western_medicine_keywords['è¥¿è¯']:
            if f"å»ºè®®æœç”¨{keyword}" in ai_response or f"å¯ä»¥ç”¨{keyword}" in ai_response:
                found_western_content.append(f"è¥¿è¯æ¨è:{keyword}")
    else:
        # éä¸­åŒ»ä¸Šä¸‹æ–‡ï¼Œæ£€æµ‹æ‰€æœ‰è¥¿åŒ»å†…å®¹
        for category, keywords in western_medicine_keywords.items():
            for keyword in keywords:
                if keyword in ai_response:
                    found_western_content.append(f"{category}:{keyword}")
    
    # å¦‚æœå‘ç°éœ€è¦è¿‡æ»¤çš„è¥¿åŒ»å†…å®¹ï¼Œåªç§»é™¤è¯¥éƒ¨åˆ†å†…å®¹ï¼Œä¸æ›¿æ¢æ•´ä¸ªå›å¤
    if found_western_content:
        logger.warning(f"æ£€æµ‹åˆ°è¥¿åŒ»å†…å®¹: {found_western_content}")
        
        # åˆ é™¤è¥¿è¯æ¨èè¯­å¥ï¼Œä½†ä¿ç•™å…¶ä»–å†…å®¹
        filtered_response = ai_response
        
        # ç§»é™¤è¥¿è¯æ¨èè¯­å¥
        for keyword in western_medicine_keywords['è¥¿è¯']:
            patterns = [
                f"å»ºè®®æœç”¨{keyword}[^ã€‚]*ã€‚?",
                f"å¯ä»¥ç”¨{keyword}[^ã€‚]*ã€‚?",
                f"æ¨è{keyword}[^ã€‚]*ã€‚?",
                f"ä½¿ç”¨{keyword}[^ã€‚]*ã€‚?"
            ]
            for pattern in patterns:
                filtered_response = re.sub(pattern, "", filtered_response)
        
        # ç§»é™¤æ£€æŸ¥å»ºè®®è¯­å¥
        for keyword in western_medicine_keywords['æ£€æŸ¥å»ºè®®']:
            pattern = f"{keyword}[^ã€‚]*ã€‚?"
            filtered_response = re.sub(pattern, "", filtered_response)
        
        # æ¸…ç†å¤šä½™çš„ç©ºè¡Œå’Œæ ¼å¼
        filtered_response = re.sub(r'\n\s*\n\s*\n', '\n\n', filtered_response)
        filtered_response = filtered_response.strip()
        
        # å¦‚æœè¿‡æ»¤åå†…å®¹å¤ªå°‘ï¼Œæ·»åŠ ä¸­åŒ»å»ºè®®
        if len(filtered_response) < 100:
            filtered_response += "\n\nå»ºè®®é€šè¿‡ä¸­åŒ»è¾¨è¯è®ºæ²»çš„æ–¹å¼è¿›è¡Œè°ƒç†ï¼Œè¯·è¯¦ç»†æè¿°ç—‡çŠ¶ä»¥ä¾¿å‡†ç¡®è¯Šæ–­ã€‚"
        
        return True, filtered_response
    
    return False, ai_response

def sanitize_ai_response(ai_response: str, has_tongue_image: bool, patient_described_tongue: str = "", image_analysis_successful: bool = False, original_patient_message: str = "") -> str:
    """æ¸…ç†AIå›å¤ä¸­çš„éæ³•èˆŒè±¡ã€è„‰è±¡ã€ç—‡çŠ¶ç¼–é€ å’Œå¤„æ–¹ç¼–é€ ä¿¡æ¯"""
    
    # é¦–å…ˆæ£€æŸ¥èˆŒè±¡ã€è„‰è±¡ã€ç—‡çŠ¶å®‰å…¨
    is_safe, error_msg = check_medical_safety(ai_response, has_tongue_image, patient_described_tongue, image_analysis_successful, original_patient_message)
    
    # å¦‚æœå‘ç°ä¼ ç»Ÿçš„åŒ»ç–—å®‰å…¨é—®é¢˜ï¼ˆèˆŒè±¡ã€è„‰è±¡ã€ç—‡çŠ¶ç¼–é€ ï¼‰ï¼Œå…ˆå¤„ç†
    tongue_pulse_cleaned = False
    if not is_safe:
        logger.warning(f"å‘ç°åŒ»ç–—å®‰å…¨é—®é¢˜: {error_msg}")
        tongue_pulse_cleaned = True
    
    # å¦‚æœæ²¡æœ‰å›¾ç‰‡ä¸Šä¼ æˆ–å›¾ç‰‡åˆ†æå¤±è´¥ï¼Œæ¸…ç†æ‰€æœ‰èˆŒè±¡è„‰è±¡æè¿°
    if not has_tongue_image or not image_analysis_successful:
        
        # æ¸…ç†ç­–ç•¥1: å¤„ç†XMLæ ¼å¼çš„æœ›è¯Šéƒ¨åˆ†
        if '<æœ›è¯Šæ‰€è§>' in ai_response and '</æœ›è¯Šæ‰€è§>' in ai_response:
            safer_observation = '<æœ›è¯Šæ‰€è§>å› æœªä¸Šä¼ èˆŒè±¡å›¾ç‰‡ï¼Œå»ºè®®æ‚£è€…åœ¨å……è¶³å…‰çº¿ä¸‹æ‹æ‘„èˆŒè±¡ç…§ç‰‡ä»¥ä¾¿æ›´å‡†ç¡®çš„æœ›è¯Šåˆ†æã€‚</æœ›è¯Šæ‰€è§>'
            ai_response = re.sub(r'<æœ›è¯Šæ‰€è§>.*?</æœ›è¯Šæ‰€è§>', safer_observation, ai_response, flags=re.DOTALL)
            logger.info("å·²æ›¿æ¢XMLæœ›è¯Šéƒ¨åˆ†ä¸ºå®‰å…¨æç¤º")
        
        # æ¸…ç†ç­–ç•¥2: å¤„ç†"è¾¨è¯è¦ç‚¹"ä¸­çš„èˆŒè±¡è„‰è±¡æè¿°
        if "è¾¨è¯è¦ç‚¹" in ai_response:
            # æ›¿æ¢èˆŒè±¡æè¿°è¡Œ
            ai_response = re.sub(
                r'- èˆŒè±¡ï¼š.*?[\n\r]', 
                '- èˆŒè±¡ï¼šå› æœªè¿›è¡Œå®é™…èˆŒè¯Šï¼Œå»ºè®®æ‚£è€…é¢è¯Šæ—¶ç”±åŒ»å¸ˆè§‚å¯ŸèˆŒè±¡\n', 
                ai_response
            )
            # æ›¿æ¢è„‰è±¡æè¿°è¡Œ
            ai_response = re.sub(
                r'- è„‰è±¡ï¼š.*?[\n\r]', 
                '- è„‰è±¡ï¼šå› æœªè¿›è¡Œå®é™…è„‰è¯Šï¼Œå»ºè®®æ‚£è€…é¢è¯Šæ—¶ç”±åŒ»å¸ˆè¿›è¡Œè„‰è±¡è¯Šæ–­\n', 
                ai_response
            )
            logger.info("å·²æ¸…ç†è¾¨è¯è¦ç‚¹ä¸­çš„èˆŒè±¡è„‰è±¡æè¿°")
        
        # æ¸…ç†ç­–ç•¥3: æ™ºèƒ½æ¸…ç†å…·ä½“èˆŒè±¡è„‰è±¡æè¿°ï¼Œä¿ç•™æ­£å¸¸æœ¯è¯­è®¨è®º
        # å…ˆæ£€æŸ¥ä¸Šä¸‹æ–‡ï¼Œå¦‚æœæ˜¯æ•™å­¦/è¯´æ˜å†…å®¹åˆ™ä¸æ¸…ç†
        def should_preserve_term(text, term_pos):
            """åˆ¤æ–­æ˜¯å¦åº”è¯¥ä¿ç•™æœ¯è¯­ï¼ˆåŸºäºä¸Šä¸‹æ–‡ï¼‰"""
            context_before = text[max(0, term_pos-10):term_pos]
            return any(indicator in context_before for indicator in ['å¦‚', 'è‹¥', 'è§', 'æˆ–', 'å¸¸', 'å¤š', 'åŒ…æ‹¬'])
        
        # åªæ¸…ç†æ˜ç¡®çš„ç¼–é€ æè¿°ï¼Œä¿ç•™æ•™å­¦è®¨è®º
        cleaned_response = ai_response
        
        # å¤„ç†æ˜ç¡®çš„ç¼–é€ æ¨¡å¼ - æ‰©å±•ç‰ˆæœ¬
        fabrication_patterns = [
            r'èˆŒè±¡[ï¼š:].*?[ï¼Œã€‚\n]',  # "èˆŒè±¡ï¼šæ·¡çº¢è‹”ç™½"
            r'æ‚£è€…èˆŒè¾¹å°–çº¢[ï¼Œã€‚]?',   # "æ‚£è€…èˆŒè¾¹å°–çº¢"  
            r'æ‚£è€…è‹”è–„[ç™½é»„][ï¼Œã€‚]?', # "æ‚£è€…è‹”è–„ç™½"
            r'è„‰è±¡[ï¼š:].*?[ï¼Œã€‚\n]',  # "è„‰è±¡ï¼šæµ®æ•°æœ‰åŠ›"
            r'æ‚£è€…è„‰[æµ®æ²‰ç¼“æ•°å¼¦æ»‘][ï¼Œã€‚]?', # "æ‚£è€…è„‰æµ®æ•°"
            r'^è„‰[æµ®æ²‰ç¼“æ•°å¼¦æ»‘][ï¼Œã€‚]',     # å¥é¦–çš„"è„‰æµ®æ•°ï¼Œ"
            r'è„‰[æµ®æ²‰ç¼“æ•°å¼¦æ»‘]+ï¼Œæœ‰åŠ›[ï¼Œã€‚]?', # "è„‰æµ®æ•°ï¼Œæœ‰åŠ›"
            r'^èˆŒè´¨[æ·¡çº¢][ï¼Œã€‚]',          # å¥é¦–çš„"èˆŒè´¨æ·¡çº¢ï¼Œ"
            r'èˆŒè´¨æ·¡çº¢ï¼Œè‹”è–„[ç™½é»„è…»][ï¼Œã€‚]?', # "èˆŒè´¨æ·¡çº¢ï¼Œè‹”è–„è…»"
        ]
        
        for pattern in fabrication_patterns:
            matches = list(re.finditer(pattern, cleaned_response))
            for match in reversed(matches):  # ä»åå‘å‰æ›¿æ¢ï¼Œé¿å…ä½ç½®åç§»
                start, end = match.span()
                # ç®€å•çš„ä¸Šä¸‹æ–‡æ£€æŸ¥
                context = cleaned_response[max(0, start-15):start]
                if not any(indicator in context for indicator in ['å¦‚', 'è‹¥', 'è§', 'æˆ–', 'å¸¸è§', 'å¤šä¸º']):
                    if 'èˆŒè±¡' in match.group():
                        cleaned_response = cleaned_response[:start] + 'èˆŒè±¡éœ€è¦é¢è¯Šè§‚å¯Ÿã€‚' + cleaned_response[end:]
                    elif 'è„‰è±¡' in match.group():
                        cleaned_response = cleaned_response[:start] + 'è„‰è±¡éœ€è¦é¢è¯Šåˆ‡è¯Šã€‚' + cleaned_response[end:]
                    else:
                        cleaned_response = cleaned_response[:start] + cleaned_response[end:]
                    logger.info(f"æ¸…ç†äº†ç¼–é€ æè¿°: {match.group()}")
        
        ai_response = cleaned_response
        
        
        # æ¸…ç†ç­–ç•¥5: ä¸¥æ ¼æ¸…ç†æœ›è¯Šåˆ‡è¯Šéƒ¨åˆ†çš„ç¼–é€ å†…å®¹
        if "1. æœ›è¯Š" in ai_response or "### æœ›è¯Š" in ai_response:
            # æ›¿æ¢æ•´ä¸ªæœ›è¯Šéƒ¨åˆ†
            ai_response = re.sub(
                r'(?:1\.|###)?\s*æœ›è¯Š[ï¼š:]?.*?(?=(?:2\.|###|$))', 
                '1. æœ›è¯Š\n\n- æœªè¿›è¡Œå®é™…æœ›è¯Šï¼Œå»ºè®®æ‚£è€…æä¾›èˆŒè±¡ç…§ç‰‡æˆ–å¯»æ±‚é¢è¯Šã€‚\n\n',
                ai_response, 
                flags=re.DOTALL
            )
            logger.info("å·²æ¸…ç†æœ›è¯Šéƒ¨åˆ†çš„ç¼–é€ å†…å®¹")
        
        if "4. åˆ‡è¯Š" in ai_response or "### åˆ‡è¯Š" in ai_response:
            # æ›¿æ¢æ•´ä¸ªåˆ‡è¯Šéƒ¨åˆ†
            ai_response = re.sub(
                r'(?:4\.|###)?\s*åˆ‡è¯Š[ï¼š:]?.*?(?=(?:5\.|###|$))', 
                '4. åˆ‡è¯Š\n\n- æœªè¿›è¡Œå®é™…åˆ‡è¯Šï¼Œè„‰è±¡è¯Šæ–­éœ€è¦ä¸“ä¸šä¸­åŒ»å¸ˆé¢è¯Šç¡®å®šã€‚\n\n',
                ai_response, 
                flags=re.DOTALL
            )
            logger.info("å·²æ¸…ç†åˆ‡è¯Šéƒ¨åˆ†çš„ç¼–é€ å†…å®¹")
        
        # æ¸…ç†ç­–ç•¥6: æ¸…ç†è¯Šç–—æ–¹æ¡ˆä¸­çš„ç¼–é€ ä½“å¾
        if "<æœ›è¯Šæ‰€è§>" in ai_response:
            # æ›´ä¸¥æ ¼çš„æœ›è¯Šæ¸…ç†
            ai_response = re.sub(
                r'<æœ›è¯Šæ‰€è§>.*?</æœ›è¯Šæ‰€è§>',
                '<æœ›è¯Šæ‰€è§>æœªè¿›è¡Œå®é™…æœ›è¯Šï¼Œå»ºè®®æ‚£è€…ä¸Šä¼ èˆŒè±¡ç…§ç‰‡æˆ–é¢è¯Š</æœ›è¯Šæ‰€è§>',
                ai_response,
                flags=re.DOTALL
            )
            logger.info("å·²æ¸…ç†XMLæ ¼å¼çš„æœ›è¯Šç¼–é€ å†…å®¹")

        # æ¸…ç†ç­–ç•¥7: æ£€æµ‹å¹¶é˜»æ­¢AIç¼–é€ å…·ä½“å¤„æ–¹å»ºè®® - ä¿®å¤è¿‡åº¦æ¸…ç†é—®é¢˜
        prescription_fabrication_patterns = [
            r'ğŸ’Š å¤„æ–¹å»ºè®®.*?(?=ğŸ”¥|âš¡|ğŸ“œ|ğŸ”„|ğŸ¯|---|\n\n\*|$)',              # æ•´ä¸ªå¤„æ–¹å»ºè®®éƒ¨åˆ† (ç®€åŒ–)
            r'ğŸ’Š è¯ç‰©ç»„æˆ.*?(?=ğŸ”¥|âš¡|ğŸ“œ|ğŸ”„|ğŸ¯|---|\n\n\*|$)',              # è¯ç‰©ç»„æˆéƒ¨åˆ† (ç®€åŒ–)
            r'å¤„æ–¹ç»„æˆ[ï¼š:].*?(?=ğŸ”¥|âš¡|ğŸ“œ|ğŸ”„|ğŸ¯|---|\n\n\*|$)',             # å¤„æ–¹ç»„æˆéƒ¨åˆ† (ç®€åŒ–)
            # åˆ é™¤è¿‡åº¦æ¸…ç†çš„æ¨¡å¼ï¼š
            # r'-\s*[^\n]+\s+\d+g',                                              # "- è¿ç¿˜ 15g" æ ¼å¼ - ä¼šè¯¯åˆ¤OCRåˆ†æ
            # r'[ä¸€-é¾¯\u4e00-\u9fff]{2,4}\s+\d+g',                              # "è¿ç¿˜ 15g" æ ¼å¼ - ä¼šè¯¯åˆ¤OCRåˆ†æ
            r'ç…åˆ¶æ–¹æ³•[ï¼š:].*?(?=æœç”¨æ–¹æ³•|ğŸ”¥|âš¡|ğŸ“œ|ğŸ”„|ğŸ¯|---|\n\n\*|$)',       # ç…åˆ¶æ–¹æ³• (ç®€åŒ–)
            r'æœç”¨æ–¹æ³•[ï¼š:].*?(?=ğŸ”¥|âš¡|ğŸ“œ|ğŸ”„|ğŸ¯|---|\n\n\*|$)',               # æœç”¨æ–¹æ³• (ç®€åŒ–)
        ]
        
        for pattern in prescription_fabrication_patterns:
            if re.search(pattern, ai_response, flags=re.DOTALL):
                logger.warning("æ£€æµ‹åˆ°AIç¼–é€ å¤„æ–¹å†…å®¹ï¼Œè¿›è¡Œæ¸…ç†")
                
                # æ›¿æ¢å¤„æ–¹å»ºè®®éƒ¨åˆ† (ä½¿ç”¨ç®€åŒ–æ¨¡å¼)
                ai_response = re.sub(
                    r'ğŸ’Š å¤„æ–¹å»ºè®®.*?(?=ğŸ”¥|âš¡|ğŸ“œ|ğŸ”„|ğŸ¯|---|\n\n\*|$)',
                    'ğŸ’Š å¤„æ–¹å»ºè®®\n\nâš ï¸ ä¸ºç¡®ä¿ç”¨è¯å®‰å…¨ï¼Œå…·ä½“çš„å¤„æ–¹å»ºè®®éœ€è¦ç”±æ‰§ä¸šä¸­åŒ»å¸ˆæ ¹æ®æ‚£è€…çš„å…·ä½“æƒ…å†µï¼Œé€šè¿‡é¢è¯Šåæ‰èƒ½å¼€å…·ã€‚\n\nå»ºè®®æ‚£è€…ï¼š\n1. åŠæ—¶åˆ°æ­£è§„ä¸­åŒ»é™¢å°±è¯Š\n2. ç”±ä¸“ä¸šä¸­åŒ»å¸ˆè¿›è¡Œå››è¯Šåˆå‚\n3. æ ¹æ®å…·ä½“è¯å‹å¼€å…·ä¸ªæ€§åŒ–å¤„æ–¹\n\n',
                    ai_response,
                    flags=re.DOTALL
                )
                
                # æ›¿æ¢è¯ç‰©ç»„æˆéƒ¨åˆ†ï¼ˆé˜²æ­¢AIç¼–é€ å…·ä½“å¤„æ–¹ï¼‰- ä½¿ç”¨ç®€åŒ–æ¨¡å¼
                ai_response = re.sub(
                    r'ğŸ’Š è¯ç‰©ç»„æˆ.*?(?=ğŸ”¥|âš¡|ğŸ“œ|ğŸ”„|ğŸ¯|---|\n\n\*|$)',
                    'ğŸ’Š è¯ç‰©ç»„æˆ\n\nâš ï¸ å¤„æ–¹çš„å…·ä½“è¯ç‰©ç»„æˆéœ€è¦ç”±æ‰§ä¸šä¸­åŒ»å¸ˆæ ¹æ®æ‚£è€…çš„å…·ä½“ç—…æƒ…ï¼Œé€šè¿‡è¯¦ç»†è¯Šå¯Ÿåæ‰èƒ½ç¡®å®šã€‚\n\nè¯·åˆ°æ­£è§„ä¸­åŒ»åŒ»é™¢è¿›è¡Œä¸“ä¸šè¯Šç–—ã€‚\n\n',
                    ai_response,
                    flags=re.DOTALL
                )
                
                # æ¸…ç†ç…æœæŒ‡å¯¼
                ai_response = re.sub(
                    r'âš¡ ç…æœæŒ‡å¯¼\s*.*?(?=---|\n\n[ğŸ”¥âš¡ğŸ“œğŸ”„]|\n\n[ã€\[]|$)',
                    'âš¡ ç”¨è¯æŒ‡å¯¼\n\nå…·ä½“çš„ç…åˆ¶å’Œæœç”¨æ–¹æ³•åº”å½“éµå¾ªæ‰§ä¸šä¸­åŒ»å¸ˆçš„ä¸“ä¸šæŒ‡å¯¼ã€‚\n\n',
                    ai_response,
                    flags=re.DOTALL
                )
                
                # æ¸…ç†è¾¨è¯åŠ å‡éƒ¨åˆ†ï¼ˆè¿™ä¹Ÿæ˜¯ç¼–é€ çš„ï¼‰
                ai_response = re.sub(
                    r'ğŸ”„ è¾¨è¯åŠ å‡\s*.*?(?=---|\n\n[ğŸ”¥âš¡ğŸ“œğŸ”„]|\n\n[ã€\[]|$)',
                    'ğŸ”„ åç»­è°ƒæ•´\n\nå…·ä½“çš„è¯ç‰©åŠ å‡åº”å½“ç”±æ‰§ä¸šä¸­åŒ»å¸ˆæ ¹æ®æ‚£è€…ç—…æƒ…å˜åŒ–è¿›è¡Œä¸“ä¸šè°ƒæ•´ã€‚\n\n',
                    ai_response,
                    flags=re.DOTALL
                )
                
                logger.info("å·²æ¸…ç†AIç¼–é€ çš„å¤„æ–¹å»ºè®®å†…å®¹")
                break

        # æ¸…ç†ç­–ç•¥8: æ£€æµ‹å¹¶æ¸…ç†ç¼–é€ çš„æœ›è¯Šä¿¡æ¯
        appearance_fabrication_patterns = [
            (r'é¢è‰²[ç•¥æ˜¾]?[è‹ç™½çº¢æ¶¦é»¯æ·¡][ï¼Œã€‚]?', 'é¢è‰²éœ€è¦é¢è¯Šè§‚å¯Ÿ'),
            (r'ç²¾ç¥[ç–²å€¦èé¡ä¸æŒ¯å€¦æ€ ][ï¼Œã€‚]?', 'ç²¾ç¥çŠ¶æ€éœ€è¦é¢è¯Šè¯„ä¼°'), 
            (r'èˆŒä½“[èƒ–å¤§ç˜¦è–„][ï¼Œã€‚]?', 'èˆŒä½“ç‰¹å¾éœ€è¦é¢è¯Šæ£€æŸ¥'),
            (r'èˆŒè¾¹[æœ‰é½¿ç—•æ— å¼‚å¸¸][ï¼Œã€‚]?', 'èˆŒè¾¹æƒ…å†µéœ€è¦é¢è¯Šç¡®è®¤'),
        ]
        
        for pattern, replacement in appearance_fabrication_patterns:
            if re.search(pattern, ai_response):
                logger.warning(f"æ£€æµ‹åˆ°ç¼–é€ çš„æœ›è¯Šä¿¡æ¯: {pattern}")
                # æ¸…ç†ç¼–é€ çš„æœ›è¯Šæè¿°
                ai_response = re.sub(pattern, replacement, ai_response)
                logger.info(f"å·²æ¸…ç†ç¼–é€ çš„æœ›è¯Šä¿¡æ¯: {pattern}")

        # æ¸…ç†ç­–ç•¥4: æ·»åŠ ç®€æ´çš„åŒ»ç–—å®‰å…¨æé†’ï¼ˆä»…åœ¨å¿…è¦æ—¶ï¼‰
        if "é‡è¦å£°æ˜" not in ai_response and "ä»…ä¾›å‚è€ƒ" not in ai_response:
            safety_notice = "\n\n**æé†’**ï¼šä»¥ä¸Šå»ºè®®ä»…ä¾›å‚è€ƒï¼Œå¦‚ç—‡çŠ¶ä¸¥é‡è¯·åŠæ—¶å°±åŒ»ã€‚"
            ai_response += safety_notice
            logger.info("å·²æ·»åŠ ç®€æ´åŒ»ç–—å®‰å…¨æé†’")
    
    # ğŸš¨ å…³é”®ä¿®å¤ï¼šå¤„æ–¹ç¼–é€ æ¸…ç†é€»è¾‘ - æ€»æ˜¯è¿è¡Œï¼Œä¸ç®¡èˆŒè±¡è„‰è±¡æ£€æŸ¥ç»“æœ
    # è¿™ä¸ªæ¸…ç†é€»è¾‘ç‹¬ç«‹äºèˆŒè±¡è„‰è±¡æ£€æŸ¥ï¼Œå› ä¸ºå¤„æ–¹ç¼–é€ æ˜¯æ›´ä¸¥é‡çš„å®‰å…¨é—®é¢˜
    # ä¿®å¤ï¼šç§»é™¤ä¼šè¯¯åˆ¤OCRåˆ†æçš„è¿‡åº¦æ¸…ç†æ¨¡å¼
    prescription_fabrication_patterns = [
        r'ğŸ’Š å¤„æ–¹å»ºè®®.*?(?=ğŸ”¥|âš¡|ğŸ“œ|ğŸ”„|ğŸ¯|---|\n\n\*|$)',              # æ•´ä¸ªå¤„æ–¹å»ºè®®éƒ¨åˆ† (ç®€åŒ–)
        r'ğŸ’Š è¯ç‰©ç»„æˆ.*?(?=ğŸ”¥|âš¡|ğŸ“œ|ğŸ”„|ğŸ¯|---|\n\n\*|$)',              # è¯ç‰©ç»„æˆéƒ¨åˆ† (ç®€åŒ–)
        r'å¤„æ–¹ç»„æˆ[ï¼š:].*?(?=ğŸ”¥|âš¡|ğŸ“œ|ğŸ”„|ğŸ¯|---|\n\n\*|$)',             # å¤„æ–¹ç»„æˆéƒ¨åˆ† (ç®€åŒ–)
        # æ³¨é‡Šæ‰ä¼šè¯¯åˆ¤OCRåˆ†æçš„æ¨¡å¼ï¼š
        # r'-\s*[^\n]+\s+\d+g',                                              # "- è¿ç¿˜ 15g" æ ¼å¼ - è¯¯åˆ¤OCR
        # r'[ä¸€-é¾¯\u4e00-\u9fff]{2,4}\s+\d+g',                              # "è¿ç¿˜ 15g" æ ¼å¼ - è¯¯åˆ¤OCR
        r'ç…åˆ¶æ–¹æ³•[ï¼š:].*?(?=æœç”¨æ–¹æ³•|ğŸ”¥|âš¡|ğŸ“œ|ğŸ”„|ğŸ¯|---|\n\n\*|$)',       # ç…åˆ¶æ–¹æ³• (ç®€åŒ–)
        r'æœç”¨æ–¹æ³•[ï¼š:].*?(?=ğŸ”¥|âš¡|ğŸ“œ|ğŸ”„|ğŸ¯|---|\n\n\*|$)',               # æœç”¨æ–¹æ³• (ç®€åŒ–)
    ]
    
    for pattern in prescription_fabrication_patterns:
        if re.search(pattern, ai_response, flags=re.DOTALL):
            logger.warning("æ£€æµ‹åˆ°AIç¼–é€ å¤„æ–¹å†…å®¹ï¼Œè¿›è¡Œæ¸…ç†")
            
            # æ›¿æ¢å¤„æ–¹å»ºè®®éƒ¨åˆ† (ä½¿ç”¨ç®€åŒ–æ¨¡å¼)
            ai_response = re.sub(
                r'ğŸ’Š å¤„æ–¹å»ºè®®.*?(?=ğŸ”¥|âš¡|ğŸ“œ|ğŸ”„|ğŸ¯|---|\n\n\*|$)',
                'ğŸ’Š å¤„æ–¹å»ºè®®\n\nâš ï¸ ä¸ºç¡®ä¿ç”¨è¯å®‰å…¨ï¼Œå…·ä½“çš„å¤„æ–¹å»ºè®®éœ€è¦ç”±æ‰§ä¸šä¸­åŒ»å¸ˆæ ¹æ®æ‚£è€…çš„å…·ä½“æƒ…å†µï¼Œé€šè¿‡é¢è¯Šåæ‰èƒ½å¼€å…·ã€‚\n\nå»ºè®®æ‚£è€…ï¼š\n1. åŠæ—¶åˆ°æ­£è§„ä¸­åŒ»é™¢å°±è¯Š\n2. ç”±ä¸“ä¸šä¸­åŒ»å¸ˆè¿›è¡Œå››è¯Šåˆå‚\n3. æ ¹æ®å…·ä½“è¯å‹å¼€å…·ä¸ªæ€§åŒ–å¤„æ–¹\n\n',
                ai_response,
                flags=re.DOTALL
            )
            
            # æ›¿æ¢è¯ç‰©ç»„æˆéƒ¨åˆ†ï¼ˆé˜²æ­¢AIç¼–é€ å…·ä½“å¤„æ–¹ï¼‰- ä½¿ç”¨ç®€åŒ–æ¨¡å¼
            ai_response = re.sub(
                r'ğŸ’Š è¯ç‰©ç»„æˆ.*?(?=ğŸ”¥|âš¡|ğŸ“œ|ğŸ”„|ğŸ¯|---|\n\n\*|$)',
                'ğŸ’Š è¯ç‰©ç»„æˆ\n\nâš ï¸ å¤„æ–¹çš„å…·ä½“è¯ç‰©ç»„æˆéœ€è¦ç”±æ‰§ä¸šä¸­åŒ»å¸ˆæ ¹æ®æ‚£è€…çš„å…·ä½“ç—…æƒ…ï¼Œé€šè¿‡è¯¦ç»†è¯Šå¯Ÿåæ‰èƒ½ç¡®å®šã€‚\n\nè¯·åˆ°æ­£è§„ä¸­åŒ»åŒ»é™¢è¿›è¡Œä¸“ä¸šè¯Šç–—ã€‚\n\n',
                ai_response,
                flags=re.DOTALL
            )
            
            # æ¸…ç†ç…æœæŒ‡å¯¼
            ai_response = re.sub(
                r'âš¡ ç…æœæŒ‡å¯¼.*?(?=ğŸ”¥|âš¡|ğŸ“œ|ğŸ”„|ğŸ¯|---|\n\n\*|$)',
                'âš¡ ç”¨è¯æŒ‡å¯¼\n\nå…·ä½“çš„ç…åˆ¶å’Œæœç”¨æ–¹æ³•åº”å½“éµå¾ªæ‰§ä¸šä¸­åŒ»å¸ˆçš„ä¸“ä¸šæŒ‡å¯¼ã€‚\n\n',
                ai_response,
                flags=re.DOTALL
            )
            
            # æ¸…ç†è¾¨è¯åŠ å‡éƒ¨åˆ†ï¼ˆè¿™ä¹Ÿæ˜¯ç¼–é€ çš„ï¼‰
            ai_response = re.sub(
                r'ğŸ”„ è¾¨è¯åŠ å‡.*?(?=ğŸ”¥|âš¡|ğŸ“œ|ğŸ”„|ğŸ¯|---|\n\n\*|$)',
                'ğŸ”„ åç»­è°ƒæ•´\n\nå…·ä½“çš„è¯ç‰©åŠ å‡åº”å½“ç”±æ‰§ä¸šä¸­åŒ»å¸ˆæ ¹æ®æ‚£è€…ç—…æƒ…å˜åŒ–è¿›è¡Œä¸“ä¸šè°ƒæ•´ã€‚\n\n',
                ai_response,
                flags=re.DOTALL
            )
            
            logger.info("å·²æ¸…ç†AIç¼–é€ çš„å¤„æ–¹å»ºè®®å†…å®¹")
            break
    
    return ai_response

def check_image_analysis_success(chat_history: list) -> bool:
    """æ£€æŸ¥æœ€è¿‘çš„å›¾ç‰‡åˆ†ææ˜¯å¦æˆåŠŸ
    
    é€šè¿‡æ£€æŸ¥ä¼šè¯å†å²ä¸­çš„å›¾ç‰‡ä¸Šä¼ ç»“æœæ¥åˆ¤æ–­ï¼š
    1. åŒ…å«"âœ… èˆŒè±¡å›¾ç‰‡å·²æˆåŠŸä¸Šä¼ " â†’ åˆ†ææˆåŠŸ
    2. åŒ…å«"âš ï¸ å›¾ç‰‡å·²ä¸Šä¼ ï¼Œä½†å›¾åƒè´¨é‡" â†’ åˆ†æå¤±è´¥ï¼ˆè´¨é‡é—®é¢˜ï¼‰
    3. æ²¡æœ‰å›¾ç‰‡ä¸Šä¼ è®°å½• â†’ åˆ†æå¤±è´¥
    """
    try:
        logger.info(f"æ£€æŸ¥å›¾ç‰‡åˆ†æçŠ¶æ€ï¼Œå†å²æ¶ˆæ¯æ•°é‡: {len(chat_history)}")
        
        # ä»æœ€è¿‘çš„æ¶ˆæ¯å¼€å§‹æ£€æŸ¥ï¼Œé‡ç‚¹æŸ¥æ‰¾å›¾ç‰‡ä¸Šä¼ çš„æˆåŠŸæ ‡è¯†
        for message in reversed(chat_history):
            content = message.get("content", "")
            role = message.get("role", "")
            
            # æ£€æŸ¥AIå›å¤ä¸­çš„å›¾ç‰‡ä¸Šä¼ ç¡®è®¤ä¿¡æ¯
            if role == "assistant":
                # æˆåŠŸä¸Šä¼ çš„æ ‡è¯†
                if "âœ… èˆŒè±¡å›¾ç‰‡å·²æˆåŠŸä¸Šä¼ " in content:
                    logger.info("æ£€æµ‹åˆ°æˆåŠŸçš„èˆŒè±¡å›¾ç‰‡ä¸Šä¼ æ ‡è¯†")
                    return True
                # è´¨é‡é—®é¢˜çš„æ ‡è¯†
                if "âš ï¸ å›¾ç‰‡å·²ä¸Šä¼ ï¼Œä½†å›¾åƒè´¨é‡" in content:
                    logger.info("æ£€æµ‹åˆ°å›¾ç‰‡è´¨é‡é—®é¢˜æ ‡è¯†")
                    return False
                # å…¶ä»–å›¾ç‰‡ç›¸å…³çš„æˆåŠŸæ ‡è¯†
                if "å›¾ç‰‡å·²æˆåŠŸä¸Šä¼ " in content or "èˆŒè±¡å›¾ç‰‡" in content and "æˆåŠŸ" in content:
                    logger.info("æ£€æµ‹åˆ°å…¶ä»–å›¾ç‰‡ä¸Šä¼ æˆåŠŸæ ‡è¯†")
                    return True
            
            # æ£€æŸ¥ç³»ç»Ÿæ¶ˆæ¯ä¸­æ˜¯å¦æœ‰å›¾ç‰‡åˆ†ææˆåŠŸçš„æ ‡è¯†
            if role == "system" and "èˆŒè±¡" in content:
                if "æˆåŠŸ" in content or "å·²ä¿å­˜" in content:
                    logger.info("æ£€æµ‹åˆ°ç³»ç»Ÿçº§å›¾ç‰‡å¤„ç†æˆåŠŸæ ‡è¯†")
                    return True
        
        logger.info("æœªæ£€æµ‹åˆ°ä»»ä½•å›¾ç‰‡ä¸Šä¼ æˆåŠŸæ ‡è¯†")
        return False
    except Exception as e:
        logger.error(f"æ£€æŸ¥å›¾ç‰‡åˆ†æçŠ¶æ€å¤±è´¥: {e}")
        return False

async def detect_tongue_image_upload(conversation_id: str, chat_history: list) -> bool:
    """æ£€æµ‹æ˜¯å¦æœ‰èˆŒè±¡å›¾ç‰‡ä¸Šä¼ 
    
    æ”¹è¿›çš„æ£€æµ‹é€»è¾‘ï¼š
    1. ä¼˜å…ˆæ£€æŸ¥æ˜ç¡®çš„ä¸Šä¼ æˆåŠŸæ ‡è¯†
    2. æ£€æŸ¥ä¼šè¯å†å²ä¸­çš„å›¾åƒæ¶ˆæ¯
    3. æ£€æŸ¥æ˜¯å¦å­˜åœ¨èˆŒè±¡ç›¸å…³çš„å›¾åƒæ–‡ä»¶
    """
    
    logger.info(f"æ£€æµ‹èˆŒè±¡å›¾ç‰‡ä¸Šä¼ çŠ¶æ€ï¼Œä¼šè¯ID: {conversation_id}ï¼Œå†å²æ¶ˆæ¯æ•°é‡: {len(chat_history)}")
    
    # æ–¹æ³•1: æ£€æŸ¥æ˜ç¡®çš„å›¾ç‰‡ä¸Šä¼ æˆåŠŸæ ‡è¯†
    for msg in reversed(chat_history):  # ä»æœ€æ–°æ¶ˆæ¯å¼€å§‹æ£€æŸ¥
        content = msg.get("content", "")
        role = msg.get("role", "")
        
        # æ£€æŸ¥AIå›å¤ä¸­çš„å›¾ç‰‡ä¸Šä¼ ç¡®è®¤
        if role == "assistant":
            if "âœ… èˆŒè±¡å›¾ç‰‡å·²æˆåŠŸä¸Šä¼ " in content:
                logger.info("é€šè¿‡AIå›å¤ç¡®è®¤æ£€æµ‹åˆ°èˆŒè±¡å›¾ç‰‡ä¸Šä¼ ")
                return True
            if "âš ï¸ å›¾ç‰‡å·²ä¸Šä¼ ï¼Œä½†å›¾åƒè´¨é‡" in content:
                logger.info("æ£€æµ‹åˆ°å›¾ç‰‡ä¸Šä¼ ä½†è´¨é‡æœ‰é—®é¢˜")
                return True  # è™½ç„¶è´¨é‡æœ‰é—®é¢˜ï¼Œä½†ç¡®å®ä¸Šä¼ äº†
        
        # æ£€æŸ¥ç”¨æˆ·æ¶ˆæ¯ä¸­çš„å›¾ç‰‡ä¸Šä¼ æ ‡è¯†
        if role == "user":
            if any(keyword in content for keyword in ["èˆŒè±¡å›¾ç‰‡", "èˆŒè¯Šç…§ç‰‡", "ä¸Šä¼ èˆŒè±¡", "èˆŒå¤´ç…§ç‰‡"]):
                logger.info(f"åœ¨ç”¨æˆ·æ¶ˆæ¯ä¸­æ£€æµ‹åˆ°èˆŒè±¡å›¾ç‰‡ä¸Šä¼ æ ‡è¯†: {content[:50]}...")
                return True
    
    # æ–¹æ³•2: æ£€æŸ¥æ˜¯å¦å­˜åœ¨ä¼šè¯ç›¸å…³çš„å›¾åƒæ–‡ä»¶
    # å‡è®¾å›¾åƒæ–‡ä»¶å­˜å‚¨åœ¨ ./uploaded_images/{conversation_id}/ ç›®å½•
    image_dir = f"./uploaded_images/{conversation_id}"
    if os.path.exists(image_dir):
        image_files = [f for f in os.listdir(image_dir) 
                      if f.lower().endswith(('.jpg', '.jpeg', '.png', '.gif', '.bmp'))]
        if image_files:
            logger.info(f"æ£€æµ‹åˆ°ä¼šè¯ {conversation_id} æœ‰ {len(image_files)} ä¸ªå›¾åƒæ–‡ä»¶")
            return True
    
    # æ–¹æ³•3: æ£€æŸ¥ç”¨æˆ·æ¶ˆæ¯ä¸­æ˜¯å¦æœ‰base64ç¼–ç çš„å›¾åƒæ•°æ®ï¼ˆç”¨äºæœªæ¥æ‰©å±•ï¼‰
    for msg in chat_history:
        if msg.get("role") == "user":
            content = msg.get("content", "")
            # æ£€æŸ¥æ˜¯å¦åŒ…å«base64å›¾åƒæ•°æ®
            if "data:image/" in content and "base64," in content:
                logger.info("æ£€æµ‹åˆ°base64ç¼–ç çš„å›¾åƒæ•°æ®")
                return True
    
    return False

def validate_image_analysis_safety(analysis_result: str, image_type: str) -> str:
    """éªŒè¯å›¾åƒåˆ†æç»“æœçš„åŒ»ç–—å®‰å…¨æ€§"""
    
    # å±é™©çš„æ–­è¨€æ€§è¯æ±‡
    dangerous_assertions = [
        "ç¡®è¯Š", "è¯Šæ–­ä¸º", "å¯ä»¥ç¡®å®š", "æ˜ç¡®æ˜¾ç¤º", "ä¸€å®šæ˜¯", "è‚¯å®šæ˜¯", 
        "æ‚£æœ‰", "ç—…å˜", "å¼‚å¸¸", "ç–¾ç—…", "ç—‡å€™", "è¯å‹ä¸º"
    ]
    
    # è¿‡äºå…·ä½“çš„èˆŒè±¡æè¿°ï¼ˆå¯èƒ½ä¸å‡†ç¡®ï¼‰
    over_specific_tongue = [
        "èˆŒè‹”åšè…»", "èˆŒè¾¹é½¿ç—•æ˜æ˜¾", "èˆŒè´¨ç´«æš—", "åœ°å›¾èˆŒ", 
        "é•œé¢èˆŒ", "èˆŒä½“èƒ–å¤§", "èˆŒå°–çº¢åˆº"
    ]
    
    # æ£€æŸ¥æ˜¯å¦åŒ…å«å±é™©æ–­è¨€
    has_dangerous_assertion = any(danger in analysis_result for danger in dangerous_assertions)
    
    # æ£€æŸ¥èˆŒè±¡æè¿°æ˜¯å¦è¿‡äºå…·ä½“
    has_over_specific = any(specific in analysis_result for specific in over_specific_tongue)
    
    # å®‰å…¨æ€§è¯„ä¼°
    safety_warnings = []
    
    if has_dangerous_assertion:
        safety_warnings.append("âš ï¸ æ£€æµ‹åˆ°è¿‡äºè‚¯å®šçš„åŒ»ç–—åˆ¤æ–­è¡¨è¿°")
        logger.warning("å›¾åƒåˆ†æåŒ…å«å±é™©çš„åŒ»ç–—æ–­è¨€")
    
    if has_over_specific and image_type in ["èˆŒéƒ¨", "åŒ»å­¦å›¾åƒ"]:
        safety_warnings.append("âš ï¸ èˆŒè±¡æè¿°å¯èƒ½è¿‡äºå…·ä½“ï¼Œå»ºè®®è°¨æ…å‚è€ƒ")
        logger.warning("èˆŒè±¡åˆ†æå¯èƒ½è¿‡äºå…·ä½“")
    
    # å¦‚æœå‘ç°å®‰å…¨é—®é¢˜ï¼Œæ·»åŠ è­¦å‘Šæˆ–æ›¿æ¢ä¸ºå®‰å…¨ç‰ˆæœ¬
    if safety_warnings:
        safe_result = f"""
ã€å›¾åƒåˆ†æå®‰å…¨æç¤ºã€‘
{chr(10).join(safety_warnings)}

ã€ä¿å®ˆåˆ†æç»“æœã€‘
å›¾åƒè´¨é‡å’Œè§’åº¦é™åˆ¶äº†å‡†ç¡®åˆ†æã€‚åŸºäºå¯è§éƒ¨åˆ†è¿›è¡Œéå¸¸ä¿å®ˆçš„è§‚å¯Ÿï¼š

"""
        if image_type in ["èˆŒéƒ¨", "åŒ»å­¦å›¾åƒ"]:
            safe_result += """- å›¾åƒæ˜¾ç¤ºèˆŒéƒ¨åŒºåŸŸï¼Œä½†å—å…‰çº¿ã€è§’åº¦ç­‰å› ç´ å½±å“ï¼Œæ— æ³•è¿›è¡Œç²¾ç¡®çš„èˆŒè±¡åˆ†æ
- å»ºè®®æ‚£è€…åœ¨è‡ªç„¶å…‰ä¸‹ã€èˆŒä½“å¹³ä¼¸çŠ¶æ€ä¸‹é‡æ–°æ‹æ‘„ï¼Œæˆ–ç›´æ¥å¯»æ±‚ä¸­åŒ»å¸ˆé¢è¯Š
- èˆŒè±¡åˆ†æéœ€è¦ç»“åˆæ‚£è€…ç—‡çŠ¶ã€è„‰è±¡ç­‰ç»¼åˆåˆ¤æ–­ï¼Œå•çº¯å›¾åƒåˆ†ææœ‰å±€é™æ€§

ã€é‡è¦æé†’ã€‘
- æ­¤åˆ†æç»“æœä»…ä¾›å‚è€ƒï¼Œä¸èƒ½æ›¿ä»£ä¸“ä¸šåŒ»å¸ˆè¯Šæ–­
- ä»»ä½•æ²»ç–—æ–¹æ¡ˆéƒ½éœ€è¦æ‰§ä¸šä¸­åŒ»å¸ˆæ ¹æ®å››è¯Šåˆå‚åˆ¶å®š
- å»ºè®®æ‚£è€…åŠæ—¶å°±åŒ»ï¼Œå¯»æ±‚ä¸“ä¸šä¸­åŒ»å¸ˆçš„é¢è¯Šå’ŒæŒ‡å¯¼"""
        else:
            safe_result += """- å›¾åƒæ˜¾ç¤ºé¢éƒ¨åŒºåŸŸï¼Œä½†å—å…‰çº¿ã€è§’åº¦ç­‰å› ç´ å½±å“ï¼Œä»…èƒ½è§‚å¯Ÿåˆ°åŸºæœ¬é¢è‰²
- é¢è¯Šéœ€è¦åœ¨è‡ªç„¶å…‰ä¸‹ã€è¿‘è·ç¦»è§‚å¯Ÿï¼Œå›¾åƒåˆ†æå­˜åœ¨å±€é™æ€§
- å»ºè®®ç»“åˆæ‚£è€…è‡ªè¿°ç—‡çŠ¶å’Œä¸“ä¸šåŒ»å¸ˆé¢è¯Šè¿›è¡Œç»¼åˆåˆ¤æ–­

ã€é‡è¦æé†’ã€‘  
- æ­¤åˆ†æç»“æœä»…ä¾›å‚è€ƒï¼Œä¸èƒ½æ›¿ä»£ä¸“ä¸šåŒ»å¸ˆè¯Šæ–­
- ä»»ä½•è¯Šç–—å»ºè®®éƒ½éœ€è¦æ‰§ä¸šä¸­åŒ»å¸ˆäº²è‡ªè¯ŠæŸ¥ç¡®å®š"""
        
        return safe_result
    
    # å¦‚æœå®‰å…¨ï¼Œä½†ä»éœ€è¦æ·»åŠ æ ‡å‡†å®‰å…¨å£°æ˜
    else:
        # ç¡®ä¿åŒ…å«å¿…è¦çš„å®‰å…¨å£°æ˜
        if "ä»…ä¾›å‚è€ƒ" not in analysis_result:
            analysis_result += "\n\nã€é‡è¦å£°æ˜ã€‘æ­¤å›¾åƒåˆ†æä»…ä¾›å‚è€ƒï¼Œä¸èƒ½ä½œä¸ºè¯Šæ–­ä¾æ®ã€‚å»ºè®®ç»“åˆç—‡çŠ¶æè¿°å’Œä¸“ä¸šä¸­åŒ»å¸ˆé¢è¯Šè¿›è¡Œç»¼åˆåˆ¤æ–­ã€‚"
        
        return analysis_result

def extract_patient_tongue_description(chat_history: list) -> str:
    """æå–æ‚£è€…æè¿°çš„èˆŒè±¡ä¿¡æ¯
    
    ä»ä¼šè¯å†å²ä¸­æå–æ‚£è€…è‡ªå·±æè¿°çš„èˆŒè±¡ç‰¹å¾ï¼Œ
    è¿™äº›ä¿¡æ¯æ˜¯åˆæ³•çš„ï¼Œå¯ä»¥åœ¨AIå›å¤ä¸­ä½¿ç”¨
    """
    patient_descriptions = []
    
    # èˆŒè±¡ç›¸å…³å…³é”®è¯
    tongue_keywords = [
        "èˆŒè‹”", "èˆŒè´¨", "èˆŒè¾¹", "èˆŒå°–", "èˆŒæ ¹", "èˆŒä½“", 
        "èˆŒçº¢", "èˆŒæ·¡", "èˆŒç´«", "èˆŒæš—", "èˆŒèƒ–", "èˆŒç˜¦",
        "è‹”è–„", "è‹”åš", "è‹”ç™½", "è‹”é»„", "è‹”è…»", "è‹”å¹²",
        "é½¿ç—•", "è£‚çº¹", "åœ°å›¾èˆŒ", "é•œé¢èˆŒ"
    ]
    
    for msg in chat_history:
        if msg.get("role") == "user":
            content = msg.get("content", "")
            
            # æ£€æŸ¥ç”¨æˆ·æ¶ˆæ¯ä¸­æ˜¯å¦åŒ…å«èˆŒè±¡æè¿°
            for keyword in tongue_keywords:
                if keyword in content:
                    # æå–åŒ…å«èˆŒè±¡å…³é”®è¯çš„å¥å­
                    sentences = re.split(r'[ã€‚ï¼ï¼Ÿ.!?]', content)
                    for sentence in sentences:
                        if keyword in sentence:
                            patient_descriptions.append(sentence.strip())
                            logger.info(f"æå–åˆ°æ‚£è€…èˆŒè±¡æè¿°: {sentence.strip()}")
    
    return " ".join(set(patient_descriptions))  # å»é‡å¹¶åˆå¹¶

import asyncio
import logging
import re
import json
import tempfile
import platform
import base64
from datetime import datetime
from typing import Dict, List, Optional, Any
from contextlib import asynccontextmanager
from fastapi import FastAPI, HTTPException, UploadFile, File, Form, Request, Response

# å…ˆå®šä¹‰loggerï¼Œå†å¯¼å…¥å®‰å…¨ç³»ç»Ÿ
import logging
logger = logging.getLogger(__name__)

# å¯¼å…¥å®‰å…¨ç³»ç»Ÿ
try:
    from api.security_integration import setup_security_system, protect_api_routes
    SECURITY_AVAILABLE = True
    logger.info("Security system imported successfully")
except ImportError as e:
    logger.warning(f"Security system not available: {e}")
    SECURITY_AVAILABLE = False
from fastapi.responses import PlainTextResponse
from fastapi.responses import FileResponse, HTMLResponse
from fastapi.staticfiles import StaticFiles
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import numpy as np
import requests

# å¯¼å…¥åŒ»ç”Ÿè·¯ç”±
from api.routes.doctor_routes import router as doctor_router
from api.routes.prescription_routes import router as prescription_router
from api.routes.payment_routes import router as payment_router
from api.routes.decoction_routes import router as decoction_router
from api.routes.auth_routes import router as auth_router
from api.routes.unified_auth_routes import router as unified_auth_router
from api.routes.doctor_decision_tree_routes import router as decision_tree_router
from api.routes.symptom_analysis_routes import router as symptom_analysis_router
from api.routes.doctor_matching_routes import router as doctor_matching_router
from api.routes.review_routes import router as review_router
from api.routes.unified_consultation_routes import router as unified_consultation_router
from api.routes.database_management_routes import router as database_management_router
from api.routes.conversation_sync_routes import router as conversation_sync_router
from api.routes.user_data_sync_routes import router as user_data_sync_router
from api.routes.data_migration_routes import router as data_migration_router
import faiss

# å¯¼å…¥æ™ºèƒ½ç¼“å­˜ç³»ç»Ÿ
from core.cache_system.intelligent_cache_system import IntelligentCacheSystem, get_cache_system, init_cache_system
from core.prescription.integrated_prescription_parser import parse_prescription_text
from core.prescription.prescription_checker import PrescriptionChecker
from services.prescription_ocr_system import get_ocr_system, PrescriptionOCRSystem
from core.knowledge_retrieval.tcm_knowledge_graph import TCMKnowledgeGraph
from services.famous_doctor_learning_system import FamousDoctorLearningSystem
from services.prescription_learning_integrator import get_prescription_learning_integrator
import pickle
from dotenv import load_dotenv

# å¯¼å…¥å¢å¼ºæ£€ç´¢å’Œäººæ ¼åŒ–ç³»ç»Ÿ
# é‡æ–°å¯ç”¨å¢å¼ºç³»ç»Ÿï¼Œæ‰€æœ‰ä¾èµ–å·²ä¿®å¤
try:
    from core.knowledge_retrieval.enhanced_retrieval import EnhancedKnowledgeRetrieval
    from core.doctor_system.tcm_doctor_personas import PersonalizedTreatmentGenerator
    from services.personalized_learning import PersonalizedLearningSystem, UserFeedback
    from core.doctor_system.doctor_mind_integration import EnhancedPersonalizedTreatmentGenerator, DoctorMindAPI
    from database.postgresql_knowledge_interface import get_hybrid_knowledge_system
    from services.medical_diagnosis_controller import medical_diagnosis_controller
    ENHANCED_SYSTEM_AVAILABLE = True  # ä¾èµ–å·²ä¿®å¤ï¼Œé‡æ–°å¯ç”¨
    DOCTOR_MIND_SYSTEM_AVAILABLE = True
    POSTGRESQL_HYBRID_AVAILABLE = True
    # print("Enhanced systems loaded successfully including PostgreSQL hybrid knowledge")  # å‡å°‘å¯åŠ¨æ—¥å¿—
except ImportError as e:
    print(f"Enhanced systems not available: {e}, using basic search")
    ENHANCED_SYSTEM_AVAILABLE = False
    DOCTOR_MIND_SYSTEM_AVAILABLE = False
    POSTGRESQL_HYBRID_AVAILABLE = False

# å¯¼å…¥å¼ ä»²æ™¯ä¸“ç”¨å†³ç­–ç³»ç»Ÿ
try:
    from zhang_zhongjing_decision_system import ZhangZhongjingDecisionSystem
    ZHANG_ZHONGJING_SYSTEM_AVAILABLE = True
    # print("Zhang Zhongjing decision system loaded successfully")  # å‡å°‘å¯åŠ¨æ—¥å¿—
except ImportError as e:
    print(f"Zhang Zhongjing decision system not available: {e}")
    ZHANG_ZHONGJING_SYSTEM_AVAILABLE = False

# åˆå§‹åŒ–æ™ºèƒ½ç¼“å­˜ç³»ç»Ÿ
try:
    cache_system = init_cache_system(
        cache_db_path=str(PATHS['cache_db']),
        similarity_threshold=0.45
    )
    CACHE_SYSTEM_AVAILABLE = True
    # print("Intelligent cache system initialized successfully")  # å‡å°‘å¯åŠ¨æ—¥å¿—
except Exception as e:
    print(f"Cache system initialization failed: {e}, continuing without cache")
    CACHE_SYSTEM_AVAILABLE = False

# åˆå§‹åŒ–ç”¨æˆ·å†å²ç³»ç»Ÿ
try:
    from services.user_history_system import UserHistorySystem, user_history
    USER_HISTORY_AVAILABLE = True
    # print("User history system initialized successfully")  # å‡å°‘å¯åŠ¨æ—¥å¿—
except ImportError as e:
    print(f"User history system not available: {e}")
    USER_HISTORY_AVAILABLE = False

# åŸºç¡€å¯¼å…¥å’Œé…ç½®
if platform.system() == "Linux":
    os.environ['SQLITE_TMPDIR'] = '/tmp'
    os.environ['TMPDIR'] = '/tmp'

# ä¼˜åŒ–jiebaåˆ†è¯å¯åŠ¨æ€§èƒ½ - ç¦ç”¨DEBUGæ—¥å¿—å’Œè¯¦ç»†è¾“å‡º
import logging
import jieba
jieba_logger = logging.getLogger('jieba')
jieba_logger.setLevel(logging.ERROR)  # åªæ˜¾ç¤ºERRORçº§åˆ«ï¼Œè¿›ä¸€æ­¥å‡å°‘æ—¥å¿—
jieba.setLogLevel(logging.ERROR)  # è®¾ç½®jiebaå†…éƒ¨æ—¥å¿—çº§åˆ«

try:
    import dashscope
    from dashscope import Generation, MultiModalConversation
    from http import HTTPStatus
except ImportError as e:
    print(f"Required libraries missing: {e}. Please run 'pip install dashscope'")
    sys.exit(1)

# æ—¥å¿—é…ç½®
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('/var/log/tcm_api.log'),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()
logger.info("Attempted to load environment variables from .env file.")

# APIé…ç½®
DASHSCOPE_API_KEY = os.getenv("DASHSCOPE_API_KEY")
if not DASHSCOPE_API_KEY:
    logger.error("CRITICAL: DASHSCOPE_API_KEY not set.")
else:
    dashscope.api_key = DASHSCOPE_API_KEY
    logger.info("DashScope API Key is set.")

MAIN_LLM_MODEL = "qwen-turbo"
RAG_EMBEDDING_MODEL = "text-embedding-v4"
RAG_EMBEDDING_DIM = 1024
CONVERSATION_LOG_DIR = "./conversation_logs"
os.makedirs(CONVERSATION_LOG_DIR, exist_ok=True)

# FAISSçŸ¥è¯†åº“è·¯å¾„é…ç½®
KNOWLEDGE_DB_PATH = os.getenv("KNOWLEDGE_DB_PATH", str(PATHS['knowledge_db']))
FAISS_INDEX_FILE = os.path.join(KNOWLEDGE_DB_PATH, "knowledge.index")
DOCUMENTS_FILE = os.path.join(KNOWLEDGE_DB_PATH, "documents.pkl")
METADATA_FILE = os.path.join(KNOWLEDGE_DB_PATH, "metadata.pkl")

conversation_history_store: Dict[str, List[Dict[str, str]]] = {}
conversation_session_store: Dict[str, Dict] = {}

# åˆå§‹åŒ–å¢å¼ºæ£€ç´¢å’Œäººæ ¼åŒ–ç³»ç»Ÿ
enhanced_retrieval = None
persona_generator = None
learning_system = None
enhanced_treatment_generator = None
doctor_mind_api = None
hybrid_knowledge_system = None

if ENHANCED_SYSTEM_AVAILABLE:
    try:
        enhanced_retrieval = EnhancedKnowledgeRetrieval(KNOWLEDGE_DB_PATH)
        persona_generator = PersonalizedTreatmentGenerator()
        learning_system = PersonalizedLearningSystem(db_path=str(PATHS['data_dir'] / 'learning_db.sqlite'))
        logger.info("Enhanced retrieval, persona and learning systems initialized successfully")
    except Exception as e:
        logger.error(f"Failed to initialize enhanced systems: {e}")
        ENHANCED_SYSTEM_AVAILABLE = False

# åˆå§‹åŒ–PostgreSQLæ··åˆçŸ¥è¯†åº“ç³»ç»Ÿ
if POSTGRESQL_HYBRID_AVAILABLE:
    try:
        hybrid_knowledge_system = get_hybrid_knowledge_system(enhanced_retrieval)
        logger.info("PostgreSQL hybrid knowledge system initialized successfully")
    except Exception as e:
        logger.error(f"Failed to initialize PostgreSQL hybrid system: {e}")
        POSTGRESQL_HYBRID_AVAILABLE = False

# åˆå§‹åŒ–åŒ»ç”Ÿæ€ç»´å†³ç­–æ ‘ç³»ç»Ÿ
if DOCTOR_MIND_SYSTEM_AVAILABLE:
    try:
        enhanced_treatment_generator = EnhancedPersonalizedTreatmentGenerator()
        doctor_mind_api = DoctorMindAPI(enhanced_treatment_generator)
        logger.info("Doctor mind decision tree system initialized successfully")
    except Exception as e:
        logger.error(f"Failed to initialize doctor mind system: {e}")
        DOCTOR_MIND_SYSTEM_AVAILABLE = False

# åˆå§‹åŒ–å¼ ä»²æ™¯ä¸“ç”¨å†³ç­–ç³»ç»Ÿ
if ZHANG_ZHONGJING_SYSTEM_AVAILABLE:
    try:
        zhang_zhongjing_system = ZhangZhongjingDecisionSystem()
        logger.info("Zhang Zhongjing specialized decision system initialized successfully")
    except Exception as e:
        logger.error(f"Failed to initialize Zhang Zhongjing system: {e}")
        ZHANG_ZHONGJING_SYSTEM_AVAILABLE = False
        zhang_zhongjing_system = None
else:
    zhang_zhongjing_system = None

# æ··åˆçŸ¥è¯†åº“æœç´¢å‡½æ•° (æ•´åˆPostgreSQLå’ŒFAISS)
async def search_knowledge_base(query: str, query_embedding: list[float], k: int = 5, selected_doctor: str = "zhang_zhongjing") -> list[str]:
    """å¢å¼ºçš„æ··åˆçŸ¥è¯†åº“æœç´¢å‡½æ•° (ä¼˜å…ˆä½¿ç”¨PostgreSQLåŒ»ç”Ÿä¸“ç”¨çŸ¥è¯†åº“ï¼Œæ”¯æŒå‘é‡æœç´¢)"""
    try:
        # å¦‚æœPostgreSQLæ··åˆç³»ç»Ÿå¯ç”¨ï¼Œä¼˜å…ˆä½¿ç”¨
        if POSTGRESQL_HYBRID_AVAILABLE and hybrid_knowledge_system:
            logger.info(f"Using PostgreSQL hybrid knowledge search (with vectors) for doctor: {selected_doctor}")
            results = await hybrid_knowledge_system.search_knowledge(
                query, selected_doctor, query_embedding=query_embedding, top_k=k
            )
            
            # è½¬æ¢æ ¼å¼ä¸ºåŸæœ‰æ ¼å¼
            formatted_results = []
            for result in results:
                content = result.get('content', '')
                title = result.get('title', 'Unknown')
                source = result.get('source', '')
                search_method = result.get('search_method', 'unknown')
                score = result.get('relevance_score', 0)
                
                formatted_content = f"ã€{title}ã€‘\n{content}"
                if source and source != 'ç»¼åˆçŸ¥è¯†åº“':
                    formatted_content += f"\n\næ¥æºï¼š{source}"
                formatted_content += f"\n\næœç´¢æ–¹å¼ï¼š{search_method}ï¼Œç›¸å…³æ€§ï¼š{score:.3f}"
                formatted_results.append(formatted_content)
            
            logger.info(f"PostgreSQL hybrid vector search found {len(formatted_results)} results")
            return formatted_results
        
        # å¦‚æœå¢å¼ºæ£€ç´¢ç³»ç»Ÿå¯ç”¨ï¼Œä½¿ç”¨æ··åˆæ£€ç´¢
        elif ENHANCED_SYSTEM_AVAILABLE and enhanced_retrieval:
            logger.info("Using enhanced hybrid search")
            results = enhanced_retrieval.hybrid_search(
                query=query,
                query_embedding=query_embedding,
                semantic_weight=0.6,
                keyword_weight=0.4,
                total_results=k
            )
            return [result['document'] for result in results]
        
        # å¦åˆ™ä½¿ç”¨åŸºç¡€FAISSæ£€ç´¢
        else:
            logger.info("Using basic FAISS search")
            if not os.path.exists(FAISS_INDEX_FILE):
                logger.warning("FAISS index file not found")
                return []
                
            # åŠ è½½ç´¢å¼•
            index = faiss.read_index(FAISS_INDEX_FILE)
            if index.ntotal == 0:
                logger.warning("FAISS index is empty")
                return []
                
            # åŠ è½½æ–‡æ¡£
            with open(DOCUMENTS_FILE, 'rb') as f:
                documents = pickle.load(f)
                
            # æ ‡å‡†åŒ–æŸ¥è¯¢å‘é‡
            query_vector = np.array([query_embedding], dtype=np.float32)
            faiss.normalize_L2(query_vector)
            
            # æœç´¢
            scores, indices = index.search(query_vector, k)
            
            # è¿”å›ç»“æœ
            results = []
            for idx in indices[0]:
                if idx != -1 and idx < len(documents):
                    results.append(documents[idx])
            
            logger.info(f"FAISS search found {len(results)} results")
            return results
        
    except Exception as e:
        logger.error(f"Knowledge base search failed: {e}")
        return []

def extract_diagnosis_improved(ai_response: str) -> str:
    """
    æ”¹è¿›çš„è¯Šæ–­ä¿¡æ¯æå–å‡½æ•°
    æ”¯æŒå¤šç§ä¸­åŒ»è¯Šæ–­æ ¼å¼
    """
    import re
    
    diagnosis_patterns = [
        # XMLæ ¼å¼
        r'<è¯Šæ–­>(.*?)</è¯Šæ–­>',
        r'<ä¸­åŒ»è¯Šæ–­>(.*?)</ä¸­åŒ»è¯Šæ–­>',
        r'<è¯å€™>(.*?)</è¯å€™>',
        
        # æ ‡å‡†æ ¼å¼
        r'ã€è¯Šæ–­ã€‘[:ï¼š]?\s*(.+?)(?:\n|$)',
        r'ã€ä¸­åŒ»è¯Šæ–­ã€‘[:ï¼š]?\s*(.+?)(?:\n|$)', 
        r'ã€è¯å€™ã€‘[:ï¼š]?\s*(.+?)(?:\n|$)',
        r'ã€è¯å‹ã€‘[:ï¼š]?\s*(.+?)(?:\n|$)',
        
        # è‡ªç„¶è¯­è¨€æ ¼å¼
        r'è¯Šæ–­ä¸º[:ï¼š]?\s*(.+?)(?:\n|ã€‚|$)',
        r'è¾¨è¯ä¸º[:ï¼š]?\s*(.+?)(?:\n|ã€‚|$)',
        r'è¯å€™ä¸º[:ï¼š]?\s*(.+?)(?:\n|ã€‚|$)',
        r'å±äº[:ï¼š]?\s*(.+?è¯)(?:\n|ã€‚|$)',
        
        # ç»“æ„åŒ–æ ¼å¼
        r'## è¯Šæ–­\s*\n(.+?)(?:\n##|\n\n|$)',
        r'\*\*è¯Šæ–­[:ï¼š]?\*\*\s*(.+?)(?:\n|$)',
        
        # å…¶ä»–å¸¸è§æ ¼å¼
        r'ä¸­åŒ»è¯Šæ–­[:ï¼š]?\s*(.+?)(?:\n|ã€‚|$)',
        r'ä¸´åºŠè¯Šæ–­[:ï¼š]?\s*(.+?)(?:\n|ã€‚|$)',
    ]
    
    for pattern in diagnosis_patterns:
        matches = re.findall(pattern, ai_response, re.MULTILINE | re.DOTALL)
        if matches:
            diagnosis = matches[0].strip()
            # æ¸…ç†å¤šä½™çš„æ ‡ç‚¹å’Œç©ºç™½
            diagnosis = re.sub(r'[\n\r\t]+', ' ', diagnosis)
            diagnosis = re.sub(r'[ã€‚ï¼Œï¼›ï¼š]+$', '', diagnosis)
            if len(diagnosis) > 5 and len(diagnosis) < 200:  # åˆç†é•¿åº¦
                return diagnosis
    
    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ï¼Œå°è¯•ä»æ®µè½ä¸­æå–
    lines = ai_response.split('\n')
    for line in lines:
        line = line.strip()
        if any(keyword in line for keyword in ['è¯', 'è¯Šæ–­', 'è¾¨è¯', 'ç—…æœº']):
            if len(line) > 10 and len(line) < 150:
                # å»æ‰å¯èƒ½çš„å‰ç¼€
                for prefix in ['æ ¹æ®ç—‡çŠ¶,', 'ç»¼åˆåˆ†æ,', 'æ‚£è€…çš„æƒ…å†µå±äº']:
                    line = line.replace(prefix, '')
                cleaned_line = line.strip()
                if len(cleaned_line) > 5:
                    return cleaned_line
    
    return "å¾…å®Œå–„"

def extract_prescription_improved(ai_response: str) -> tuple[bool, str]:
    """
    æ”¹è¿›çš„å¤„æ–¹æå–å‡½æ•°
    è¿”å›: (æ˜¯å¦æ£€æµ‹åˆ°å¤„æ–¹, å¤„æ–¹å†…å®¹)
    """
    import re
    
    # 1. XMLæ ¼å¼å¤„æ–¹æ£€æµ‹ï¼ˆæœ€ä¼˜å…ˆï¼‰
    xml_patterns = [
        r'<å¤„æ–¹å»ºè®®>(.*?)</å¤„æ–¹å»ºè®®>',
        r'<å¤„æ–¹>(.*?)</å¤„æ–¹>',
        r'<æ–¹å‰‚>(.*?)</æ–¹å‰‚>',
        r'<è¯æ–¹>(.*?)</è¯æ–¹>'
    ]
    
    for pattern in xml_patterns:
        matches = re.findall(pattern, ai_response, re.MULTILINE | re.DOTALL)
        if matches:
            prescription = matches[0].strip()
            if len(prescription) > 20:  # å¤„æ–¹åº”è¯¥æœ‰ä¸€å®šé•¿åº¦
                return True, prescription[:1500]
    
    # 2. æ ‡å‡†æ ‡è®°æ ¼å¼
    marker_patterns = [
        r'ã€å¤„æ–¹ã€‘[:ï¼š]?(.*?)(?:ã€|##|\n\n|$)',
        r'ã€æ–¹å‰‚ã€‘[:ï¼š]?(.*?)(?:ã€|##|\n\n|$)',
        r'ã€è¯æ–¹ã€‘[:ï¼š]?(.*?)(?:ã€|##|\n\n|$)',
        r'å¤„æ–¹[:ï¼š]\n(.*?)(?:ã€|##|\n\n|$)',
        r'æ–¹å‰‚[:ï¼š]\n(.*?)(?:ã€|##|\n\n|$)',
        r'## å¤„æ–¹å»ºè®®\s*\n(.*?)(?:##|\n\n|$)',
        r'\*\*å¤„æ–¹[:ï¼š]?\*\*\s*\n(.*?)(?:\n\n|$)'
    ]
    
    for pattern in marker_patterns:
        matches = re.findall(pattern, ai_response, re.MULTILINE | re.DOTALL)
        if matches:
            prescription = matches[0].strip()
            # éªŒè¯æ˜¯å¦åŒ…å«è¯ç‰©ä¿¡æ¯
            if has_herbal_content(prescription):
                return True, prescription[:400]
    
    # 3. æ–¹å‰‚åç§°æ£€æµ‹
    formula_patterns = [
        r'(é“¶ç¿˜æ•£|éº»æçŸ³ç”˜æ±¤|å°æŸ´èƒ¡æ±¤|å››å›å­æ±¤|å››ç‰©æ±¤|å…­å‘³åœ°é»„æ±¤|è¡¥ä¸­ç›Šæ°”æ±¤|é€é¥æ•£|ç”˜éœ²é¥®|æ¸…èƒƒæ•£).*?(?:ç»„æˆ|è¯ç‰©)[:ï¼š]?(.*?)(?:ã€|##|\n\n|$)',
        r'æ¨èä½¿ç”¨\s*(.*?æ±¤|.*?æ•£|.*?ä¸¸|.*?ç‰‡)\s*[:,ï¼š]?(.*?)(?:ã€|##|\n\n|$)'
    ]
    
    for pattern in formula_patterns:
        matches = re.findall(pattern, ai_response, re.MULTILINE | re.DOTALL)
        if matches:
            formula_name = matches[0][0] if isinstance(matches[0], tuple) else matches[0]
            formula_content = matches[0][1] if isinstance(matches[0], tuple) and len(matches[0]) > 1 else ""
            if formula_content and has_herbal_content(formula_content):
                return True, f"{formula_name}ï¼š{formula_content}"[:1500]
            elif formula_name:
                return True, f"æ¨èæ–¹å‰‚ï¼š{formula_name}"
    
    # 4. è¯ç‰©ç»„åˆæ£€æµ‹
    lines = ai_response.split('\n')
    herb_lines = []
    
    common_herbs = [
        'å…šå‚', 'é»„èŠª', 'å½“å½’', 'å·èŠ', 'ç™½èŠ', 'ç†Ÿåœ°', 'ç™½æœ¯', 'èŒ¯è‹“', 'ç”˜è‰',
        'é“¶èŠ±', 'è¿ç¿˜', 'æ¿è“æ ¹', 'è’²å…¬è‹±', 'æ¡”æ¢—', 'è–„è·', 'èŠèŠ±', 'é‡‘é“¶èŠ±',
        'é™ˆçš®', 'åŠå¤', 'ç”Ÿå§œ', 'å¤§æ£', 'æ¸æ', 'èŠèŠ±', 'å†³æ˜å­', 'å±±æ¥‚',
        'æŸ´èƒ¡', 'é»„èŠ©', 'äººå‚', 'é¹¿èŒ¸', 'å†¬è™«å¤è‰', 'çµèŠ', 'å¤©éº»'
    ]
    
    for line in lines:
        line = line.strip()
        # æ£€æŸ¥æ˜¯å¦åŒ…å«è¯ç‰©å’Œç”¨é‡
        herb_count = sum(1 for herb in common_herbs if herb in line)
        has_dosage = bool(re.search(r'\d+[gGå…‹é’±]', line))
        
        if herb_count >= 2 or (herb_count >= 1 and has_dosage):
            herb_lines.append(line)
    
    if len(herb_lines) >= 3:  # è‡³å°‘3è¡Œè¯ç‰©
        prescription_content = '\n'.join(herb_lines[:8])  # æœ€å¤š8è¡Œ
        return True, prescription_content[:1500]
    
    # 5. æ£€æµ‹"- è¯å ç”¨é‡"æ ¼å¼çš„è¯ç‰©åˆ—è¡¨ï¼ˆæ–°å¢ï¼‰
    dash_herb_lines = []
    for line in lines:
        line = line.strip()
        # åŒ¹é… "- è¯å æ•°é‡g" æˆ– "- è¯å æ•°é‡å…‹" æ ¼å¼
        if re.match(r'-\s*[\u4e00-\u9fa5]+\s+\d+[gGå…‹é’±]', line):
            dash_herb_lines.append(line)
        # ä¹ŸåŒ¹é…å¸¦è¯´æ˜çš„æ ¼å¼ "- è¯å æ•°é‡g (åŠŸæ•ˆè¯´æ˜)"
        elif re.match(r'-\s*[\u4e00-\u9fa5]+\s+\d+[gGå…‹é’±]\s*\([^)]+\)', line):
            dash_herb_lines.append(line)
    
    if len(dash_herb_lines) >= 3:  # è‡³å°‘3ä¸ªè¯ç‰©é¡¹ç›®
        prescription_content = '\n'.join(dash_herb_lines[:10])  # æœ€å¤š10è¡Œ
        return True, prescription_content[:1500]
    
    return False, "æœªå¼€æ–¹"

def has_herbal_content(text: str) -> bool:
    """æ£€æŸ¥æ–‡æœ¬æ˜¯å¦åŒ…å«ä¸­è¯å†…å®¹"""
    import re
    
    # æ£€æŸ¥æ˜¯å¦åŒ…å«ç”¨é‡å•ä½
    dosage_pattern = r'\d+[gGå…‹é’±]'
    if re.search(dosage_pattern, text):
        return True
    
    # æ£€æŸ¥æ˜¯å¦åŒ…å«å¸¸è§ä¸­è¯å
    common_herbs = ['å…šå‚', 'é»„èŠª', 'å½“å½’', 'å·èŠ', 'ç™½èŠ', 'ç†Ÿåœ°', 'ç™½æœ¯', 'èŒ¯è‹“', 'ç”˜è‰', 'é“¶èŠ±', 'è¿ç¿˜']
    herb_count = sum(1 for herb in common_herbs if herb in text)
    
    return herb_count >= 2

def llm_based_knowledge_search(query: str, k: int = 5) -> list[str]:
    """åŸºäºLLMçš„çŸ¥è¯†æœç´¢ (æ›¿ä»£æœ¬åœ°çŸ¥è¯†åº“)"""
    try:
        search_prompt = f"""ä½œä¸ºä¸­åŒ»çŸ¥è¯†ä¸“å®¶ï¼Œè¯·é’ˆå¯¹ç”¨æˆ·æŸ¥è¯¢"{query}"æä¾›ç›¸å…³çš„ä¸­åŒ»çŸ¥è¯†ã€‚

è¯·ä»ä»¥ä¸‹å‡ ä¸ªæ–¹é¢æä¾›ä¿¡æ¯ï¼š
1. ç›¸å…³çš„ä¸­åŒ»ç†è®ºå’Œç—…æœºåˆ†æ
2. å¸¸ç”¨çš„æ²»ç–—æ–¹å‰‚å’Œè¯ç‰©
3. ä¸´åºŠç—‡çŠ¶å’Œè¾¨è¯è¦ç‚¹
4. è°ƒç†å»ºè®®å’Œæ³¨æ„äº‹é¡¹

è¯·ç¡®ä¿ä¿¡æ¯å‡†ç¡®ã€ä¸“ä¸šï¼Œé€‚åˆä¸­åŒ»ä¸´åºŠåº”ç”¨ã€‚"""

        messages = [{"role": "user", "content": search_prompt}]
        
        # ä½¿ç”¨å¼‚æ­¥è°ƒç”¨çš„åŒæ­¥ç‰ˆæœ¬
        import asyncio
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        try:
            response = loop.run_until_complete(bailian_llm_complete(MAIN_LLM_MODEL, messages))
            # å°†å›å¤åˆ†å‰²æˆå¤šä¸ªçŸ¥è¯†å—
            knowledge_blocks = response.split('\n\n')
            return knowledge_blocks[:k]
        finally:
            loop.close()
            
    except Exception as e:
        logger.error(f"LLM-based knowledge search error: {e}")
        return [f"åŸºäºæŸ¥è¯¢'{query}'çš„ä¸­åŒ»çŸ¥è¯†æœç´¢æš‚æ—¶ä¸å¯ç”¨ã€‚"]

# æ ¸å¿ƒåŠŸèƒ½å‡½æ•°
async def embed_query(texts: list[str]) -> list[list[float]]:
    if not texts: return []
    logger.info(f"EMBEDDING [QUERY]: Starting for {len(texts)} texts...")
    try:
        resp = await asyncio.to_thread(dashscope.TextEmbedding.call, model=RAG_EMBEDDING_MODEL, input=texts, text_type="query")
        if resp.status_code != HTTPStatus.OK:
            raise RuntimeError(f"DashScope Embedding API Error: {getattr(resp, 'message', 'Unknown')}")
        logger.info(f"EMBEDDING [QUERY]: Successfully completed.")
        return [r['embedding'] for r in resp.output['embeddings']]
    except Exception as e:
        logger.error(f"EMBEDDING [QUERY]: Exception: {e}", exc_info=True)
        return [[]]

async def bailian_llm_complete(model: str, messages: List[Dict[str, str]], timeout: float = 40.0) -> str:
    try:
        # ä¸ºAIè°ƒç”¨æ·»åŠ è¶…æ—¶ä¿æŠ¤
        response = await asyncio.wait_for(
            asyncio.to_thread(Generation.call, model=model, messages=messages, result_format='message'),
            timeout=timeout
        )
        if response.status_code == HTTPStatus.OK and response.output and response.output.choices:
            return response.output.choices[0]['message']['content']
        else:
            error_msg = f"LLM Error: {getattr(response, 'message', 'Unknown')}"
            logger.error(error_msg)
            return f"ã€ç³»ç»Ÿé”™è¯¯ã€‘{error_msg}"
    except asyncio.TimeoutError:
        logger.error(f"LLM call timed out after {timeout} seconds")
        return "ã€ç³»ç»Ÿæç¤ºã€‘AIåŒ»ç”Ÿæ­£åœ¨åˆ†æä¸­ï¼Œå“åº”æ—¶é—´è¾ƒé•¿ï¼Œè¯·ç¨åé‡è¯•æˆ–æä¾›æ›´ç®€æ´çš„ç—‡çŠ¶æè¿°ã€‚"
    except Exception as e:
        logger.error(f"LLM Exception: {e}", exc_info=True)
        return "ã€ç³»ç»Ÿé”™è¯¯ã€‘è°ƒç”¨AIæ—¶å‘ç”ŸæœªçŸ¥å¼‚å¸¸ã€‚"

# def call_qwen_vl_api(messages: List[Dict], model: str = "qwen-vl-plus") -> str:
#     """[DEPRECATED] æ—§ç‰ˆAPIè°ƒç”¨æ–¹æ³• - å·²ç”±extract_features_from_imageç›´æ¥å¤„ç†"""
#     pass

async def extract_keywords_from_query(query: str) -> List[str]:
    logger.info("LLM - Extracting keywords from query...")
    prompt = f'''ä½ æ˜¯ä¸€ä¸ªä¿¡æ¯æ£€ç´¢ä¸“å®¶ã€‚è¯·ä»ä»¥ä¸‹ç”¨æˆ·é—®é¢˜ä¸­ï¼Œæå–å‡ºæ‰€æœ‰å¯¹æ£€ç´¢ç»“æœè‡³å…³é‡è¦çš„ã€æ ¸å¿ƒå…³é”®è¯ã€‘ã€‚
è¿™äº›å…³é”®è¯åº”è¯¥åŒ…æ‹¬ï¼š
1.  **ç—…åæˆ–è¯å‹** (ä¾‹å¦‚ï¼šä¸­æš‘, æ°”é˜´ä¸¤è™š)
2.  **æ–¹å‰‚æˆ–è¯æå** (ä¾‹å¦‚ï¼šæ¸…ç»œé¥®, è¥¿æ´‹å‚)
3.  **æ ¸å¿ƒç—‡çŠ¶** (ä¾‹å¦‚ï¼šå¤´æ™•, ä¹åŠ›, å£å¹²)

è¿”å›ä¸€ä¸ªJSONæ ¼å¼çš„å­—ç¬¦ä¸²åˆ—è¡¨ã€‚

ã€ç¤ºä¾‹1ã€‘
ç”¨æˆ·é—®é¢˜ï¼š"å…ˆå…†ä¸­æš‘å¤´æ™•ä¹åŠ›æ€ä¹ˆåŠï¼Ÿ"
è¿”å›ï¼š["å…ˆå…†ä¸­æš‘", "å¤´æ™•", "ä¹åŠ›"]

ã€ç”¨æˆ·é—®é¢˜ã€‘
"{query}"
'''
    try:
        response_str = await bailian_llm_complete(model=MAIN_LLM_MODEL, messages=[{"role": "user", "content": prompt}])
        logger.info(f"LLM - Raw keyword extraction response: {response_str}")
        match = re.search(r'```json\s*([\s\S]*?)\s*```', response_str)
        if match:
            response_str = match.group(1)
        keywords = json.loads(response_str)
        if isinstance(keywords, list):
            logger.info(f"LLM - Extracted keywords: {keywords}")
            return keywords
    except Exception as e:
        logger.error(f"Failed to extract or parse keywords: {e}")
    return []

# ä½¿ç”¨åœ¨çº¿è¯­éŸ³è¯†åˆ«æœåŠ¡ (é›†æˆé˜¿é‡Œäº‘è¯­éŸ³è¯†åˆ«)
async def speech_to_text_online(audio_bytes: bytes) -> str:
    """ä½¿ç”¨é˜¿é‡Œäº‘è¯­éŸ³è¯†åˆ«æœåŠ¡"""
    try:
        import tempfile
        import requests
        import json
        
        logger.info(f"å¼€å§‹è¯­éŸ³è¯†åˆ«ï¼ŒéŸ³é¢‘å¤§å°: {len(audio_bytes)} bytes")
        
        # æ£€æŸ¥éŸ³é¢‘å¤§å°
        if len(audio_bytes) < 100:
            logger.warning("éŸ³é¢‘æ•°æ®è¿‡å°ï¼Œå¯èƒ½æ˜¯ç©ºéŸ³é¢‘")
            return "éŸ³é¢‘æ•°æ®è¿‡å°ï¼Œè¯·é‡æ–°å½•åˆ¶"
            
        # ä¿å­˜éŸ³é¢‘åˆ°ä¸´æ—¶æ–‡ä»¶
        with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as tmp_file:
            tmp_file.write(audio_bytes)
            tmp_file_path = tmp_file.name
        
        logger.info(f"éŸ³é¢‘æ–‡ä»¶ä¿å­˜åˆ°: {tmp_file_path}")
        
        try:
            # ä½¿ç”¨DashScopeçš„è¯­éŸ³è¯†åˆ«API
            from dashscope.audio.asr import Recognition
            
            recognition = Recognition(model='paraformer-realtime-v1',
                                    format='wav',
                                    sample_rate=16000,
                                    callback=None)
            
            # è°ƒç”¨è¯­éŸ³è¯†åˆ«
            result = recognition.call(tmp_file_path)
            
            if result.status_code == 200:
                # è§£æè¯†åˆ«ç»“æœ
                if hasattr(result, 'output') and result.output and 'text' in result.output:
                    recognized_text = result.output['text'].strip()
                    logger.info(f"è¯­éŸ³è¯†åˆ«æˆåŠŸ: {recognized_text}")
                    return recognized_text if recognized_text else "æœªè¯†åˆ«åˆ°è¯­éŸ³å†…å®¹"
                else:
                    logger.warning("è¯­éŸ³è¯†åˆ«è¿”å›ç©ºç»“æœ")
                    return "æœªè¯†åˆ«åˆ°è¯­éŸ³å†…å®¹ï¼Œè¯·é‡æ–°å½•åˆ¶"
            else:
                logger.error(f"è¯­éŸ³è¯†åˆ«APIé”™è¯¯: {result.status_code}")
                return "è¯­éŸ³è¯†åˆ«æœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ä½¿ç”¨æ–‡å­—è¾“å…¥"
                
        except ImportError:
            logger.warning("DashScopeè¯­éŸ³è¯†åˆ«æ¨¡å—æœªå®‰è£…ï¼Œå°è¯•å¤‡ç”¨æ–¹æ¡ˆ")
            # å¤‡ç”¨æ–¹æ¡ˆï¼šä½¿ç”¨ç®€å•çš„éŸ³é¢‘æ£€æµ‹
            if len(audio_bytes) > 1000:  # åŸºæœ¬çš„éŸ³é¢‘å¤§å°æ£€æµ‹
                return "è¯­éŸ³è¯†åˆ«åŠŸèƒ½æ­£åœ¨å‡çº§ä¸­ï¼Œè¯·æš‚æ—¶ä½¿ç”¨æ–‡å­—è¾“å…¥"
            else:
                return "éŸ³é¢‘è¿‡çŸ­ï¼Œè¯·é‡æ–°å½•åˆ¶"
                
        except Exception as api_error:
            logger.error(f"è¯­éŸ³è¯†åˆ«APIè°ƒç”¨å¤±è´¥: {api_error}")
            return "è¯­éŸ³è¯†åˆ«æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ä½¿ç”¨æ–‡å­—è¾“å…¥"
            
        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            try:
                import os
                os.unlink(tmp_file_path)
            except:
                pass
                
    except Exception as e:
        logger.error(f"è¯­éŸ³è¯†åˆ«ç³»ç»Ÿé”™è¯¯: {e}")
        return "è¯­éŸ³è¯†åˆ«æœåŠ¡æš‚æ—¶ä¸å¯ç”¨"

# å›¾åƒåˆ†æå‡½æ•° (ä½¿ç”¨å¤šæ¨¡æ€API)
def extract_features_from_image(image_bytes: bytes, image_type: str) -> str:
    """ä½¿ç”¨å¤šæ¨¡æ€APIè¿›è¡Œå›¾åƒåˆ†æ"""
    try:
        logger.info(f"Starting image analysis for {image_type}, image size: {len(image_bytes)} bytes")
        
        # æ£€æŸ¥å›¾åƒæ•°æ®æ˜¯å¦æœ‰æ•ˆ
        if not image_bytes or len(image_bytes) < 100:
            logger.error(f"Invalid image data: size={len(image_bytes) if image_bytes else 0}")
            return f"{image_type}å›¾åƒæ•°æ®æ— æ•ˆæˆ–è¿‡å°"
        
        # ä¿å­˜ä¸´æ—¶æ–‡ä»¶ä¾›APIä½¿ç”¨ (å› ä¸ºDashScope VL APIéœ€è¦æ–‡ä»¶è·¯å¾„)
        with tempfile.NamedTemporaryFile(suffix='.jpg', delete=False) as tmp_file:
            tmp_file.write(image_bytes)
            tmp_file_path = tmp_file.name
        
        logger.info(f"Temporary image file created: {tmp_file_path}")
        
        try:
            # ä½¿ç”¨æ­£ç¡®çš„DashScopeå¤šæ¨¡æ€APIæ ¼å¼ (file://æœ¬åœ°è·¯å¾„)
            messages = [
                {
                    "role": "user", 
                    "content": [
                        {
                            "image": f"file://{tmp_file_path}"
                        },
                        {
                            "text": f"""ã€ä¸¥æ ¼åŒ»ç–—å®‰å…¨è¦æ±‚ã€‘è¯·ä½œä¸ºä¸“ä¸šçš„ä¸­åŒ»å¸ˆè¿›è¡Œ{image_type}å›¾åƒåˆ†æï¼Œä¸¥æ ¼éµå¾ªä»¥ä¸‹å®‰å…¨åŸåˆ™ï¼š

**ã€å…³é”®å®‰å…¨è§„åˆ™ã€‘**
1. å¦‚æœå›¾åƒæ¨¡ç³Šã€å…‰çº¿ä¸ä½³ã€è§’åº¦ä¸æ­£ç¡®ï¼Œå¿…é¡»æ˜ç¡®è¯´æ˜"å›¾åƒè´¨é‡ä¸ä½³ï¼Œæ— æ³•è¿›è¡Œå‡†ç¡®åˆ†æ"
2. å¯¹äºä»»ä½•ä¸ç¡®å®šçš„ç‰¹å¾ï¼Œå¿…é¡»ä½¿ç”¨"ç–‘ä¼¼"ã€"å¯èƒ½"ç­‰ä¸ç¡®å®šæ€§è¯æ±‡
3. ç»å¯¹ç¦æ­¢è¿›è¡Œè¯Šæ–­æˆ–æš—ç¤ºç–¾ç—…
4. å¿…é¡»å¼ºè°ƒéœ€è¦ç»“åˆç—‡çŠ¶å’Œä¸“ä¸šåŒ»ç”Ÿé¢è¯Š

**ã€åˆ†æè¦æ±‚ã€‘**
1. **å›¾åƒè´¨é‡è¯„ä¼°**ï¼šé¦–å…ˆè¯„ä¼°å›¾åƒæ˜¯å¦é€‚åˆåˆ†æï¼ˆæ¸…æ™°åº¦ã€å…‰çº¿ã€è§’åº¦ï¼‰
2. **åŸºç¡€è§‚å¯Ÿ**ï¼ˆä»…åœ¨å›¾åƒè´¨é‡è‰¯å¥½æ—¶è¿›è¡Œï¼‰ï¼š
   - èˆŒè¯Šå›¾åƒï¼šä»…æè¿°æ˜æ˜¾å¯è§çš„èˆŒè´¨åŸºæœ¬é¢œè‰²å’Œè‹”è‰²ï¼ˆå¦‚"èˆŒè´¨åçº¢è‰²è°ƒ"ã€"è‹”è‰²åç™½"ï¼‰
   - é¢è¯Šå›¾åƒï¼šä»…æè¿°æ˜æ˜¾çš„é¢è‰²ç‰¹ç‚¹ï¼ˆå¦‚"é¢è‰²åçº¢æ¶¦"ã€"é¢è‰²åè‹ç™½"ï¼‰
3. **ä¸ç¡®å®šæ€§å£°æ˜**ï¼šå¯¹ä»»ä½•ç»†èŠ‚ç‰¹å¾ä½¿ç”¨"ç–‘ä¼¼"ã€"ä¼¼æœ‰"ç­‰è¯æ±‡
4. **åŒ»ç–—å®‰å…¨å£°æ˜**ï¼š
   - "æ­¤å›¾åƒåˆ†æä»…ä¾›å‚è€ƒï¼Œä¸èƒ½ä½œä¸ºè¯Šæ–­ä¾æ®"
   - "å»ºè®®ç»“åˆæ‚£è€…è¯¦ç»†ç—‡çŠ¶æè¿°å’Œä¸“ä¸šä¸­åŒ»å¸ˆé¢è¯Š"
   - "ä»»ä½•æ²»ç–—æ–¹æ¡ˆéœ€ç”±æ‰§ä¸šä¸­åŒ»å¸ˆæ ¹æ®å››è¯Šåˆå‚ç¡®å®š"

**ã€ä¸¥æ ¼ç¦æ­¢ã€‘**
- ç¦æ­¢ç»™å‡ºå…·ä½“çš„ç—…ç†åˆ¤æ–­
- ç¦æ­¢æš—ç¤ºç‰¹å®šç–¾ç—…æˆ–è¯å‹  
- ç¦æ­¢åœ¨å›¾åƒä¸æ¸…æ™°æ—¶å¼ºè¡Œæè¿°ç»†èŠ‚
- ç¦æ­¢ç»™å‡ºæ²»ç–—å»ºè®®

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸Šè¦æ±‚è¿›è¡Œåˆ†æï¼Œç¡®ä¿åŒ»ç–—å®‰å…¨ã€‚"""
                        }
                    ]
                }
            ]
            
            logger.info("Calling Qwen VL API with temporary file...")
            
            # ä½¿ç”¨MultiModalConversation.callè€Œä¸æ˜¯Generation.call
            # ä½¿ç”¨ç»Ÿä¸€çš„å¤šæ¨¡æ€æ¨¡å‹é…ç½®
            model_name = AI_CONFIG.get("multimodal_model", "qwen-vl-max")
            model_timeout = AI_CONFIG.get("multimodal_timeout", 80)
            
            response = dashscope.MultiModalConversation.call(
                model=model_name,
                messages=messages,
                timeout=model_timeout
            )
            
            logger.info(f"API Response status: {response.status_code}")
            
            if response.status_code == HTTPStatus.OK:
                # æ­£ç¡®è§£æå“åº”æ ¼å¼
                content_list = response.output.choices[0].message.content
                result_text = ""
                
                for item in content_list:
                    if 'text' in item:
                        result_text += item['text']
                
                logger.info(f"API Response content (first 100 chars): {result_text[:100]}...")
                
                if not result_text or result_text.strip() == "":
                    logger.warning("API returned empty content")
                    return "å›¾åƒåˆ†ææœªèƒ½è¯†åˆ«åˆ°æœ‰æ•ˆå†…å®¹ï¼Œè¯·ç¡®ä¿å›¾åƒæ¸…æ™°ä¸”åŒ…å«é¢éƒ¨æˆ–èˆŒéƒ¨ç‰¹å¾ã€‚"
                
                # åŒ»ç–—å®‰å…¨éªŒè¯
                validated_result = validate_image_analysis_safety(result_text, image_type)
                return validated_result
            else:
                error_msg = getattr(response, 'message', 'Unknown error')
                logger.error(f"Qwen VL API error - Status: {response.status_code}, Message: {error_msg}")
                return f"å›¾åƒåˆ†æAPIè°ƒç”¨å¤±è´¥: {error_msg}"
                
        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            try:
                os.unlink(tmp_file_path)
                logger.info(f"Temporary file cleaned up: {tmp_file_path}")
            except:
                pass
        
    except Exception as e: 
        logger.error(f"Error processing {image_type} image: {e}", exc_info=True)
        return f"{image_type}å›¾åƒå¤„ç†æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"

# FastAPIåº”ç”¨è®¾ç½®
@asynccontextmanager
async def lifespan(app_instance: FastAPI):
    logger.info("Application startup: Initializing online-only resources...")
    # ä¸éœ€è¦åŠ è½½æœ¬åœ°æ¨¡å‹
    yield
    logger.info("Application shutdown.")

app = FastAPI(
    title="AIä¸­åŒ»æ™ºèƒ½é—®è¯Šç³»ç»Ÿ - æœ€å°åŒ–ç‰ˆæœ¬",
    description="åŸºäºåœ¨çº¿APIçš„ä¸­åŒ»é—®è¯Šç³»ç»Ÿ",
    version="2.2.0",
    lifespan=lifespan
)

# è®¾ç½®å®‰å…¨ç³»ç»Ÿ
if SECURITY_AVAILABLE:
    setup_security_system(app)
    logger.info("Security system activated")

# å…ˆæ³¨å†Œå…·ä½“è·¯ç”±ï¼Œå†æ³¨å†Œé€šç”¨è·¯ç”±ï¼ˆé¿å…è·¯ç”±å†²çªï¼‰
@app.get("/api/prescription/learning_stats")
async def get_prescription_learning_stats():
    """è·å–å¤„æ–¹å­¦ä¹ ç³»ç»Ÿç»Ÿè®¡ä¿¡æ¯"""
    try:
        learning_integrator = get_prescription_learning_integrator()
        stats = await learning_integrator.get_learning_statistics()
        return {
            "success": True,
            "data": stats
        }
    except Exception as e:
        logger.error(f"è·å–å¤„æ–¹å­¦ä¹ ç»Ÿè®¡å¤±è´¥: {e}")
        return {
            "success": False,
            "error": str(e)
        }

@app.get("/api/prescription/learning_details")
async def get_prescription_learning_details():
    """è·å–å¤„æ–¹å­¦ä¹ è¯¦ç»†å†…å®¹"""
    try:
        learning_integrator = get_prescription_learning_integrator()
        
        # è·å–è¯¦ç»†çš„å­¦ä¹ æ¡ˆä¾‹
        details = []
        
        # å°è¯•ä»æ•°æ®åº“è·å–å­¦ä¹ æ¡ˆä¾‹
        import sqlite3
        import os
        
        # æ£€æŸ¥å­¦ä¹ æ•°æ®åº“æ˜¯å¦å­˜åœ¨
        learning_db_path = '/opt/tcm-ai/data/learning_db.sqlite'
        if os.path.exists(learning_db_path):
            conn = sqlite3.connect(learning_db_path)
            cursor = conn.cursor()
            
            try:
                # è·å–æœ€è¿‘çš„å­¦ä¹ æ¡ˆä¾‹
                cursor.execute("""
                    SELECT * FROM learning_cases 
                    ORDER BY learned_at DESC 
                    LIMIT 20
                """)
                rows = cursor.fetchall()
                
                for row in rows:
                    details.append({
                        'diagnosis': row[2] if len(row) > 2 else 'æœªçŸ¥',
                        'syndrome': row[3] if len(row) > 3 else 'æœªçŸ¥',
                        'prescription': row[4] if len(row) > 4 else '',
                        'confidence': row[5] if len(row) > 5 else 0.0,
                        'learned_at': row[6] if len(row) > 6 else 'æœªçŸ¥'
                    })
                
                conn.close()
            except Exception as db_error:
                logger.error(f"è¯»å–å­¦ä¹ æ•°æ®åº“å¤±è´¥: {db_error}")
                conn.close()
        
        return {
            "success": True,
            "data": details
        }
    except Exception as e:
        logger.error(f"è·å–å­¦ä¹ è¯¦æƒ…å¤±è´¥: {e}")
        return {
            "success": False,
            "error": str(e),
            "data": []
        }

@app.get("/api/prescription/recent_learning")
async def get_recent_learning_activities():
    """è·å–æœ€è¿‘çš„å­¦ä¹ æ´»åŠ¨"""
    try:
        import sqlite3
        
        # æ¨¡æ‹Ÿæœ€è¿‘å­¦ä¹ æ´»åŠ¨æ•°æ®
        activities = []
        
        # å°è¯•ä»æ•°æ®åº“è¯»å–çœŸå®æ•°æ®
        learning_db_path = '/opt/tcm-ai/data/learning_db.sqlite'
        if os.path.exists(learning_db_path):
            conn = sqlite3.connect(learning_db_path)
            cursor = conn.cursor()
            
            try:
                cursor.execute("""
                    SELECT * FROM learning_cases 
                    ORDER BY learned_at DESC 
                    LIMIT 10
                """)
                rows = cursor.fetchall()
                
                for row in rows:
                    activities.append({
                        'type': 'å¤„æ–¹å­¦ä¹ ',
                        'diagnosis': row[2] if len(row) > 2 else 'æœªçŸ¥è¯Šæ–­',
                        'syndrome': row[3] if len(row) > 3 else 'æœªè¯†åˆ«',
                        'confidence': row[5] if len(row) > 5 else 0.0,
                        'time_ago': calculate_time_ago(row[6]) if len(row) > 6 else 'æœªçŸ¥æ—¶é—´'
                    })
                
                conn.close()
            except Exception as db_error:
                logger.error(f"è¯»å–å­¦ä¹ æ´»åŠ¨å¤±è´¥: {db_error}")
                conn.close()
        
        return {
            "success": True,
            "data": activities
        }
    except Exception as e:
        logger.error(f"è·å–å­¦ä¹ æ´»åŠ¨å¤±è´¥: {e}")
        return {
            "success": False,
            "data": []
        }

# å…ˆæ³¨å†Œé™æ€é¡µé¢è·¯ç”±ï¼ˆåœ¨APIè·¯ç”±ä¹‹å‰ï¼‰
# åŒ»ç”Ÿç«¯å‹å¥½URLè·¯ç”± (å»é™¤.htmlæ‰©å±•å)
@app.get("/doctor")
async def doctor_main():
    """åŒ»ç”Ÿå·¥ä½œå°ä¸»é¡µ - ä¼˜åŒ–ç‰ˆæœ¬"""
    from fastapi.responses import FileResponse
    return FileResponse('/opt/tcm-ai/static/doctor/index_optimized.html')

@app.get("/decision_tree_visual_builder.html")
async def decision_tree_builder():
    """å†³ç­–æ ‘å¯è§†åŒ–æ„å»ºå™¨ - å‘åå…¼å®¹è·¯ç”±"""
    from fastapi.responses import FileResponse
    return FileResponse('/opt/tcm-ai/static/decision_tree_visual_builder.html')

@app.get("/debug-doctor")
async def get_debug_doctor_page():
    """åŒ»ç”Ÿå·¥ä½œå°è°ƒè¯•é¡µé¢"""
    from fastapi.responses import FileResponse
    return FileResponse('/opt/tcm-ai/debug_doctor.html')

# é›†æˆæ‰€æœ‰è·¯ç”±
app.include_router(auth_router)
app.include_router(unified_auth_router)  # æ–°çš„ç»Ÿä¸€è®¤è¯ç³»ç»Ÿ
app.include_router(doctor_router)
app.include_router(prescription_router)

# AIå¢å¼ºå¤„æ–¹ç®¡ç†è·¯ç”±
from api.routes.prescription_ai_routes import router as prescription_ai_router
app.include_router(prescription_ai_router)

app.include_router(payment_router)
app.include_router(decoction_router)
app.include_router(decision_tree_router)
app.include_router(symptom_analysis_router)
app.include_router(doctor_matching_router)
app.include_router(review_router)
app.include_router(unified_consultation_router)
app.include_router(database_management_router)
app.include_router(conversation_sync_router)
app.include_router(user_data_sync_router)
app.include_router(data_migration_router)

# è®¾ç½®å…¨å±€å¼‚å¸¸å¤„ç†å™¨
from api.middleware.exception_handler import setup_exception_handlers
setup_exception_handlers(app)

# ä¿æŠ¤ç°æœ‰APIè·¯ç”±
if SECURITY_AVAILABLE:
    protect_api_routes(app)

# åˆå§‹åŒ–å¤„æ–¹æ£€æŸ¥ç³»ç»Ÿ - å»¶è¿Ÿåˆå§‹åŒ–ï¼Œé¿å…å¯åŠ¨æ—¶é”™è¯¯
prescription_checker = None
tcm_knowledge_graph = None
famous_doctor_system = None

def get_prescription_checker():
    global prescription_checker
    if prescription_checker is None:
        try:
            from core.prescription.prescription_checker import PrescriptionChecker
            prescription_checker = PrescriptionChecker()
        except Exception as e:
            logger.error(f"å¤„æ–¹æ£€æŸ¥å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
    return prescription_checker

def get_knowledge_graph():
    global tcm_knowledge_graph
    if tcm_knowledge_graph is None:
        try:
            from core.knowledge_retrieval.tcm_knowledge_graph import TCMKnowledgeGraph
            tcm_knowledge_graph = TCMKnowledgeGraph()
        except Exception as e:
            logger.error(f"çŸ¥è¯†å›¾è°±åˆå§‹åŒ–å¤±è´¥: {e}")
    return tcm_knowledge_graph

def get_famous_doctor_system():
    global famous_doctor_system  
    if famous_doctor_system is None:
        try:
            from services.famous_doctor_learning_system import FamousDoctorLearningSystem
            famous_doctor_system = FamousDoctorLearningSystem()
        except Exception as e:
            logger.error(f"ååŒ»ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {e}")
    return famous_doctor_system

# CORSä¸­é—´ä»¶é…ç½®
app.add_middleware(
    CORSMiddleware,
    allow_origins=[
        "https://mxh0510.cn", 
        "https://www.mxh0510.cn",
        "http://localhost:8000",
        "http://127.0.0.1:8000",
        "http://localhost",
        "http://127.0.0.1"
    ],
    allow_credentials=True,
    allow_methods=["GET", "POST", "PUT", "DELETE", "OPTIONS"],
    allow_headers=["*"],
)

# é™æ€æ–‡ä»¶æŒ‚è½½
try:
    app.mount("/static", StaticFiles(directory="/opt/tcm-ai/static"), name="static")
    
    # ç§»åŠ¨ç«¯å¼¹çª—æµ‹è¯•é¡µé¢
    @app.get("/mobile-modal-test")
    async def mobile_modal_test():
        """ç§»åŠ¨ç«¯å›¾ç‰‡é€‰æ‹©å¼¹çª—æµ‹è¯•é¡µé¢"""
        with open(str(PATHS['static_dir'] / 'mobile_modal_test.html'), "r", encoding="utf-8") as f:
            content = f.read()
        return HTMLResponse(content=content)
    
    # å¾®ä¿¡éªŒè¯æ–‡ä»¶æ”¯æŒ - é€šç”¨è·¯ç”±
    @app.get("/MP_verify_{filename}.txt")
    async def wechat_verification_dynamic(filename: str):
        """å¾®ä¿¡å…¬ä¼—å¹³å°åŸŸåéªŒè¯ - æ”¯æŒä»»æ„MP_verify_*.txtæ–‡ä»¶"""
        try:
            file_path = f"/opt/tcm-ai/static/MP_verify_{filename}.txt"
            if os.path.exists(file_path):
                with open(file_path, "r") as f:
                    content = f.read().strip()
                logger.info(f"æˆåŠŸè¯»å–å¾®ä¿¡éªŒè¯æ–‡ä»¶: MP_verify_{filename}.txt")
                return PlainTextResponse(content)
            else:
                logger.warning(f"å¾®ä¿¡éªŒè¯æ–‡ä»¶ä¸å­˜åœ¨: MP_verify_{filename}.txt")
                return PlainTextResponse("File not found", status_code=404)
        except Exception as e:
            logger.error(f"è¯»å–å¾®ä¿¡éªŒè¯æ–‡ä»¶å¤±è´¥: {e}")
            return PlainTextResponse("Error reading verification file", status_code=500)
    
    # ä¿ç•™åŸæœ‰çš„é€šç”¨éªŒè¯æ–‡ä»¶è·¯ç”±ï¼ˆå‘åå…¼å®¹ï¼‰
    @app.get("/MP_verify_wechat_verification.txt")
    async def wechat_verification():
        """å¾®ä¿¡å…¬ä¼—å¹³å°åŸŸåéªŒè¯ - å‘åå…¼å®¹"""
        try:
            with open("/opt/tcm-ai/static/MP_verify_wechat_verification.txt", "r") as f:
                content = f.read()
            return PlainTextResponse(content)
        except:
            return PlainTextResponse("wechat_verification_tcm_ai_medical_system")
    
    @app.get("/robots.txt") 
    async def robots_txt():
        """æœç´¢å¼•æ“robots.txt"""
        try:
            with open("/opt/tcm-ai/static/robots.txt", "r") as f:
                content = f.read()
            return PlainTextResponse(content)
        except:
            return PlainTextResponse("User-agent: *\nAllow: /")
    
    @app.get("/sitemap.xml")
    async def sitemap_xml():
        """æœç´¢å¼•æ“ç«™ç‚¹åœ°å›¾"""
        sitemap_content = '''<?xml version="1.0" encoding="UTF-8"?>
<urlset xmlns="http://www.sitemaps.org/schemas/sitemap/0.9">
  <url>
    <loc>https://mxh0510.cn/</loc>
    <lastmod>2025-08-06</lastmod>
    <changefreq>weekly</changefreq>
    <priority>1.0</priority>
  </url>
  <url>
    <loc>https://mxh0510.cn/register</loc>
    <lastmod>2025-08-06</lastmod>
    <changefreq>monthly</changefreq>
    <priority>0.8</priority>
  </url>
</urlset>'''
        return Response(content=sitemap_content, media_type="application/xml")
    
    @app.post("/api/log_wechat_visit")
    async def log_wechat_visit(request: Request):
        """è®°å½•å¾®ä¿¡å…¬ä¼—å·è®¿é—®ç»Ÿè®¡"""
        try:
            data = await request.json()
            logger.info(f"å¾®ä¿¡å…¬ä¼—å·è®¿é—®ç»Ÿè®¡: {data}")
            
            # è¿™é‡Œå¯ä»¥å°†æ•°æ®ä¿å­˜åˆ°æ•°æ®åº“æˆ–æ—¥å¿—æ–‡ä»¶
            # æš‚æ—¶å…ˆè®°å½•åˆ°æ—¥å¿—ä¸­
            log_entry = {
                'timestamp': data.get('timestamp'),
                'source': data.get('source', 'unknown'),
                'from_wechat': data.get('from_wechat', False),
                'is_wechat_browser': data.get('is_wechat_browser', False),
                'page': data.get('page', 'unknown'),
                'ip': request.client.host if hasattr(request, 'client') else 'unknown'
            }
            
            # å¯ä»¥æ‰©å±•ä¸ºä¿å­˜åˆ°æ•°æ®åº“
            # await save_wechat_visit_to_db(log_entry)
            
            return {"status": "success", "message": "å¾®ä¿¡è®¿é—®è®°å½•æˆåŠŸ"}
        except Exception as e:
            logger.error(f"è®°å½•å¾®ä¿¡è®¿é—®å¤±è´¥: {e}")
            return {"status": "error", "message": str(e)}
    
except Exception as e:
    logger.warning(f"Static files not mounted: {e}")

@app.get("/doctor/portal")
async def doctor_portal():
    """åŒ»ç”Ÿé—¨æˆ· - å‹å¥½URL"""
    from fastapi.responses import FileResponse
    return FileResponse('/opt/tcm-ai/static/doctor_portal.html')

@app.get("/doctor/review")
async def doctor_review_portal():
    """åŒ»ç”Ÿå¤„æ–¹å®¡æŸ¥é—¨æˆ·"""
    from fastapi.responses import FileResponse
    return FileResponse('/opt/tcm-ai/static/doctor_review_portal.html')

@app.get("/prescription/confirm")
async def patient_prescription_confirm():
    """æ‚£è€…å¤„æ–¹ç¡®è®¤é¡µé¢"""
    from fastapi.responses import FileResponse
    return FileResponse('/opt/tcm-ai/static/patient_prescription_confirm.html')

@app.get("/doctor/thinking")  
async def doctor_thinking():
    """åŒ»ç”Ÿæ€ç»´å½•å…¥ - å‹å¥½URL"""
    from fastapi.responses import FileResponse
    return FileResponse('/opt/tcm-ai/static/doctor_thinking_input.html')

@app.get("/doctor/thinking-v2")
async def doctor_thinking_v2():
    """åŒ»ç”Ÿæ€ç»´å½•å…¥V2 - å‹å¥½URL (æ¨è)"""
    from fastapi.responses import FileResponse
    return FileResponse('/opt/tcm-ai/static/doctor_thinking_input_v2.html')

@app.get("/doctor/management")
async def doctor_management():
    """åŒ»ç”Ÿç®¡ç† - å‹å¥½URL"""
    from fastapi.responses import FileResponse
    return FileResponse('/opt/tcm-ai/static/doctor_management.html')

@app.get("/doctor-test")
async def doctor_selection_test():
    """åŒ»ç”Ÿé€‰æ‹©æµ‹è¯•é¡µé¢"""
    from fastapi.responses import FileResponse
    return FileResponse('/opt/tcm-ai/static/doctor_test.html')

@app.get("/test-doctor-selection")
async def test_doctor_selection_simple():
    """ç®€å•åŒ»ç”Ÿé€‰æ‹©åŠŸèƒ½æµ‹è¯•"""
    from fastapi.responses import FileResponse
    return FileResponse('test_doctor_selection.html')


# æ·»åŠ ç¼ºå¤±çš„ç›´æ¥è·¯ç”±
@app.get("/doctor_portal")
async def doctor_portal_direct():
    """åŒ»ç”Ÿé—¨æˆ· - ç›´æ¥URL (å…¼å®¹æ€§)"""
    from fastapi.responses import FileResponse
    return FileResponse('/opt/tcm-ai/static/doctor_portal.html')

# æ—§çš„ç‹¬ç«‹æ³¨å†Œé¡µé¢è·¯ç”±å·²ç§»é™¤ - ç»Ÿä¸€ä½¿ç”¨ auth_portal.html
# æ‰€æœ‰æ³¨å†ŒåŠŸèƒ½ç°åœ¨é€šè¿‡ /register è‡ªåŠ¨é‡å®šå‘åˆ°æ³¨å†Œæ ‡ç­¾é¡µ

@app.get("/user_history")  
async def user_history_page():
    """ç”¨æˆ·å†å²è®°å½•é¡µé¢"""
    from fastapi.responses import FileResponse
    return FileResponse('/opt/tcm-ai/static/user_history.html')

@app.get("/qr_gallery")
async def qr_gallery_page():
    """äºŒç»´ç ç®¡ç†é¡µé¢"""
    from fastapi.responses import FileResponse
    return FileResponse('/opt/tcm-ai/static/qr_code_gallery.html')

# Pydantic æ¨¡å‹
class ChatMessageInput(BaseModel): 
    message: str
    conversation_id: str
    selected_doctor: Optional[str] = "zhang_zhongjing"

class ChatMessageOutput(BaseModel): 
    reply: str
    conversation_id: str

class ConversationHistoryMessage(BaseModel): 
    role: str
    content: str

class ConversationHistoryOutput(BaseModel): 
    conversation_id: str
    history: List[ConversationHistoryMessage]
    message: Optional[str] = None

class STTOutput(BaseModel): 
    text: str
    error: Optional[str] = None

class ImageAnalysisOutput(BaseModel): 
    analysis_result: Optional[str] = None
    error: Optional[str] = None

class FeedbackInput(BaseModel):
    conversation_id: str
    rating: int
    feedback_text: Optional[str] = None
    timestamp: str

class FeedbackOutput(BaseModel):
    success: bool
    message: str

# ç³»ç»Ÿæç¤ºè¯ - ä¸­åŒ»è¯Šç–—è¾…åŠ©ç³»ç»Ÿ
SYSTEM_PROMPT_TCM_DIALOGUE_ENHANCED = ENHANCED_MEDICAL_SAFETY_PROMPT + """
# èº«ä»½å’Œç›®æ ‡
æ‚¨æ˜¯ä¸€ä½ç»éªŒä¸°å¯Œçš„ä¸­åŒ»å¸ˆï¼Œè¿ç”¨ä¼ ç»Ÿä¸­åŒ»ç†è®ºè¿›è¡Œè¯Šç–—è¾…åŠ©ã€‚æ‚¨çš„ç›®æ ‡æ˜¯é€šè¿‡ä¸­åŒ»æœ›é—»é—®åˆ‡å››è¯Šåˆå‚ï¼Œè¿›è¡Œè¾¨è¯è®ºæ²»ï¼Œæä¾›ä¸“ä¸šçš„ä¸­åŒ»è¯Šç–—æ–¹æ¡ˆã€‚

# ğŸš¨ é‡è¦åŸåˆ™ï¼šåšæŒä¸­åŒ»ç‰¹è‰²
**è¯·ä¸¥æ ¼éµå¾ªä¸­åŒ»è¯Šç–—è§„èŒƒï¼š**
- âŒ é¿å…ï¼šè¥¿è¯åç§°ã€ç°ä»£åŒ»å­¦æ£€æŸ¥é¡¹ç›®ã€è¥¿åŒ»è¯Šæ–­æœ¯è¯­
- âŒ é¿å…ï¼šè¡€å¸¸è§„ã€èƒƒé•œã€Bè¶…ã€CTã€MRIç­‰ç°ä»£æ£€æŸ¥
- âŒ é¿å…ï¼šå¥¥ç¾æ‹‰å”‘ã€é˜¿å¸åŒ¹æ—ç­‰åŒ–å­¦è¯å“
- âŒ é¿å…ï¼šä½¿ç”¨ç°ä»£åŒ»å­¦ç—…åï¼Œåº”é‡‡ç”¨ä¸­åŒ»ç—…ç—‡å
- âŒ é¿å…ï¼šç»†èŒã€ç—…æ¯’ç­‰å¾®è§‚åŒ»å­¦æ¦‚å¿µ
- âœ… ä¸“æ³¨ï¼šä¸­åŒ»ç†è®ºã€ä¸­è¯æ–¹å‰‚ã€é’ˆç¸æ¨æ‹¿ç­‰ä¼ ç»Ÿç–—æ³•

# ä¸­åŒ»è¯Šç–—ç†å¿µ
1. **å››è¯Šåˆå‚**ï¼šæœ›é—»é—®åˆ‡ï¼Œä»¥ä¸­åŒ»ç†è®ºä¸ºå‡†ç»³
2. **è¾¨è¯è®ºæ²»**ï¼šç—…å› ç—…æœºåˆ†æï¼Œè¯å‹ç¡®å®šï¼Œæ–¹è¯å¯¹ç—‡
3. **æ•´ä½“è§‚å¿µ**ï¼šäººä½“è„è…‘ç»ç»œæ°”è¡€æ´¥æ¶²çš„æ•´ä½“è°ƒç†
4. **æ²»ç—…æ±‚æœ¬**ï¼šæ ‡æœ¬å…¼æ²»ï¼Œè°ƒç†æ ¹æœ¬

# è¯Šç–—æµç¨‹å’Œé—®è¯Šè¦ç‚¹

## é‡è¦æŒ‡å¯¼åŸåˆ™ï¼š
**âš ï¸ é¿å…é‡å¤æé—®**ï¼šåœ¨ç»§ç»­é—®è¯Šå‰ï¼Œè¯·ä»”ç»†å›é¡¾å¯¹è¯å†å²ä¸­æ‚£è€…å·²ç»æä¾›çš„ä¿¡æ¯ï¼Œä¸è¦é‡å¤è¯¢é—®ç›¸åŒçš„é—®é¢˜ã€‚å¦‚æœæ‚£è€…å·²ç»å›ç­”äº†æŸä¸ªé—®é¢˜ï¼Œè¯·åŸºäºè¯¥ä¿¡æ¯è¿›è¡Œåˆ†æï¼Œè€Œä¸æ˜¯å†æ¬¡è¯¢é—®ã€‚

## é—®è¯Šé‡ç‚¹ï¼ˆæŒ‰ä¼˜å…ˆçº§ï¼‰ï¼š
1. **ä¸»è¯‰ç—‡çŠ¶**ï¼šæœ€ä¸»è¦çš„ä¸é€‚åŠæŒç»­æ—¶é—´
2. **ç—‡çŠ¶ç‰¹ç‚¹**ï¼š
   - ç–¼ç—›æ€§è´¨ï¼šèƒ€ç—›ã€åˆºç—›ã€éšç—›ã€çªœç—›ç­‰
   - å‘ä½œè§„å¾‹ï¼šæŒç»­æ€§ã€é—´æ­‡æ€§ã€ä¸æ—¶é—´/é¥®é£Ÿ/æƒ…ç»ªçš„å…³ç³»
   - è¯±å‘ç¼“è§£å› ç´ ï¼šä»€ä¹ˆæƒ…å†µä¸‹åŠ é‡æˆ–å‡è½»
3. **ä¼´éšç—‡çŠ¶**ï¼š
   - å…¨èº«ç—‡çŠ¶ï¼šå¯’çƒ­ã€æ±—å‡ºã€ç²¾ç¥ã€é£Ÿæ¬²ã€ç¡çœ 
   - å¤´é¢äº”å®˜ï¼šå¤´ç—›ã€çœ©æ™•ã€è€³é¸£ã€å’½å¹²ç­‰
   - èƒ¸è…¹ï¼šèƒ¸é—·ã€è…¹èƒ€ã€èƒƒè„˜ç—›ç­‰
   - äºŒä¾¿ï¼šå¤§ä¾¿ï¼ˆæ¬¡æ•°ã€æ€§çŠ¶ã€é¢œè‰²ï¼‰ã€å°ä¾¿ï¼ˆæ¬¡æ•°ã€é¢œè‰²ã€é‡ï¼‰
4. **æ—¢å¾€å²å’Œç”Ÿæ´»å²**ï¼š
   - æ—¢å¾€ç–¾ç—…ã€æ‰‹æœ¯å²ã€ç”¨è¯å²
   - é¥®é£Ÿåå¥½ã€ä½œæ¯è§„å¾‹ã€å·¥ä½œæ€§è´¨
   - æƒ…å¿—çŠ¶æ€ï¼šæ˜¯å¦ç„¦è™‘ã€æŠ‘éƒã€æ˜“æ€’ç­‰

## æœ›è¯Šè¦ç‚¹ï¼ˆä»…é™æœ‰å›¾åƒä¸Šä¼ æ—¶ï¼‰ï¼š
1. **é¢è‰²è§‚å¯Ÿ**ï¼šçº¢æ¶¦ã€è‹ç™½ã€èé»„ã€é’é»‘ã€æ½®çº¢ç­‰
2. **ç²¾ç¥çŠ¶æ€**ï¼šç¥é‡‡å¥•å¥•ã€ç–²æƒ«æ— ç¥ã€ç„¦è™‘ä¸å®‰ç­‰
3. **èˆŒè±¡åˆ†æ**ï¼š**ä»…åœ¨æ‚£è€…ä¸Šä¼ èˆŒè±¡å›¾ç‰‡æ—¶è¿›è¡Œåˆ†æï¼Œç»ä¸å¯åœ¨æ²¡æœ‰å›¾åƒæ—¶æè¿°èˆŒè±¡ç‰¹å¾**
   - å¿…é¡»åŸºäºå®é™…å›¾åƒè§‚å¯Ÿè¿›è¡Œæè¿°
   - å¦‚æ— èˆŒè±¡å›¾ç‰‡ï¼Œåº”å»ºè®®æ‚£è€…æä¾›ä»¥ä¾¿å‡†ç¡®è¯Šæ–­
   - **å›¾åƒè´¨é‡å·®å¤„ç†**ï¼šå¦‚æœæ”¶åˆ°"ã€å›¾åƒè´¨é‡æç¤ºã€‘"ï¼Œè¯´æ˜æ‚£è€…å·²ä¸Šä¼ å›¾ç‰‡ä½†è´¨é‡ä¸ä½³ï¼Œåº”åœ¨åˆ†æä¸­æ˜ç¡®è¯´æ˜ï¼š"è™½ç„¶æ‚¨å·²ä¸Šä¼ èˆŒè±¡å›¾ç‰‡ï¼Œä½†ç”±äºå›¾åƒè´¨é‡é™åˆ¶ï¼Œæš‚æ—¶æ— æ³•è¿›è¡Œç²¾ç¡®èˆŒè±¡åˆ†æ"ï¼Œå¹¶å»ºè®®é‡æ–°æ‹æ‘„

# å¯¹è¯äº¤äº’è§„åˆ™
## ä¿¡æ¯æ”¶é›†é˜¶æ®µï¼ˆä¿¡æ¯ä¸è¶³æ—¶ï¼‰ï¼š
é‡‡ç”¨å¾ªåºæ¸è¿›çš„é—®è¯Šæ–¹å¼ï¼Œæ¯æ¬¡è¯¢é—®2-3ä¸ªæœ€å…³é”®çš„é—®é¢˜ï¼š

**é‡è¦é—®è¯Šè§„åˆ™**ï¼š
- **ç»ä¸é‡å¤è¯¢é—®**ï¼šä»”ç»†æŸ¥çœ‹å®Œæ•´å¯¹è¯å†å²ï¼Œç»å¯¹ä¸è¦é‡å¤è¯¢é—®å·²ç»é—®è¿‡çš„é—®é¢˜
- **åŸºäºå·²çŸ¥ä¿¡æ¯**ï¼šæ ¹æ®æ‚£è€…å·²ç»æä¾›çš„ä¿¡æ¯ï¼Œåªè¯¢é—®å°šæœªäº†è§£çš„å…³é”®ä¿¡æ¯
- **å¾ªåºæ¸è¿›**ï¼šæ¯æ¬¡è¯¢é—®2-3ä¸ªæœ€å…³é”®çš„é—®é¢˜ï¼Œé…åˆé€‚å½“çš„è§£é‡Šå’Œå…³æ€€
- **å®Œæ•´å›å¤**ï¼šæ¯æ¬¡å›å¤éƒ½è¦åŒ…å«å…·ä½“çš„é—®è¯Šå†…å®¹ï¼Œä¸èƒ½åªæœ‰æ ‡ç­¾

**é—®è¯Šè¯­è¨€ç‰¹ç‚¹**ï¼š
- "è¯·é—®æ‚¨çš„[ç—‡çŠ¶]æ˜¯ä»€ä¹ˆæ€§è´¨çš„ï¼Ÿæ¯”å¦‚æ˜¯èƒ€ç—›ã€åˆºç—›è¿˜æ˜¯éšéšä½œç—›ï¼Ÿ"
- "è¿™ä¸ªç—‡çŠ¶å¤§æ¦‚æŒç»­å¤šé•¿æ—¶é—´äº†ï¼Ÿæ˜¯ä»€ä¹ˆæ—¶å€™å¼€å§‹å‡ºç°çš„ï¼Ÿ"
- "å¹³æ—¶æ‚¨æ˜¯æ¯”è¾ƒæ€•å†·è¿˜æ˜¯æ€•çƒ­ï¼Ÿæ‰‹è„šæ¸©åº¦å¦‚ä½•ï¼Ÿ"
- "æ‚¨çš„ç¡çœ å¦‚ä½•ï¼Ÿæ˜¯éš¾ä»¥å…¥ç¡ï¼Œè¿˜æ˜¯å®¹æ˜“é†’æ¥ï¼Ÿ"
- "å¤§å°ä¾¿æƒ…å†µæ€æ ·ï¼Ÿå¤§ä¾¿æ˜¯å¦æˆå½¢ï¼Ÿå°ä¾¿é¢œè‰²æ·±æµ…ï¼Ÿ"

## é—®è¯Šå’Œå¼€æ–¹å†³ç­–è§„åˆ™ï¼š
1. **ç»§ç»­é—®è¯Šæ—¶**ï¼šä½¿ç”¨ `[ASK_MORE]` æ ‡ç­¾ç»“æŸï¼Œå¹¶è¯¢é—®ç¼ºå¤±çš„å…³é”®ä¿¡æ¯
2. **å‡†å¤‡å¼€æ–¹æ—¶**ï¼šå½“ä¿¡æ¯å……è¶³ä¸”è¯Šæ–­æ˜ç¡®æ—¶ï¼Œå¯è¿›å…¥è¾¨è¯è®ºæ²»é˜¶æ®µï¼Œæ— éœ€ä½¿ç”¨`[ASK_MORE]`æ ‡ç­¾

## è¾¨è¯è®ºæ²»é˜¶æ®µï¼ˆä¿¡æ¯å……è¶³æ—¶ï¼‰ï¼š
æŒ‰ç…§ä¼ ç»Ÿä¸­åŒ»è¾¨è¯æ€è·¯ç»™å‡ºå®Œæ•´æ–¹æ¡ˆï¼Œ**ä¸¥æ ¼ä½¿ç”¨ä»¥ä¸‹XMLæ ¼å¼**ï¼š

**æ³¨æ„**ï¼šåŸºäºæ‚£è€…æ˜ç¡®æè¿°çš„ç—‡çŠ¶è¿›è¡Œåˆ†æã€‚

# ğŸ¥ **å®Œæ•´ä¸­åŒ»è¯Šç–—æ–¹æ¡ˆ**

## ğŸ“‹ **åŸºæœ¬ä¿¡æ¯**
**ğŸ”¸ ä¸»è¯‰ï¼š** ç®€è¦æ¦‚æ‹¬ä¸»è¦ç—‡çŠ¶ï¼ˆä»…åŸºäºæ‚£è€…æ˜ç¡®è¡¨è¿°ï¼‰

**ğŸ”¸ ç°ç—…å²ï¼š** è¯¦ç»†æè¿°ç—‡çŠ¶å‘ç”Ÿå‘å±•è¿‡ç¨‹åŠä¼´éšç—‡çŠ¶ï¼ˆä»…åŸºäºæ‚£è€…æè¿°å†…å®¹ï¼‰

## ğŸ‘ï¸ **æœ›è¯Šæ‰€è§**
**ğŸ”¸ é¢è‰²èˆŒè±¡ï¼š** å¦‚æœ‰å›¾åƒåˆ†æç»“æœï¼Œæè¿°é¢è‰²ã€èˆŒè±¡ç­‰å®¢è§‚è¡¨ç°

## ğŸ§  **ä¸­åŒ»è¾¨è¯åˆ†æ**

### **ç—…æœºåˆ†æ**
ä»ä¸­åŒ»è§’åº¦åˆ†æå‘ç—…åŸå› å’Œç—…ç†æœºåˆ¶

### **ğŸ¯ è¯å‹è¯Šæ–­**  
**ç¡®å®šå…·ä½“çš„ä¸­åŒ»è¯å‹**

### **âš¡ æ²»ç–—æ–¹æ³•**
**æ²»æ³•ï¼š** ç¡®å®šæ²»ç–—å¤§æ³•

### **ğŸ“œ æ–¹å‰‚é€‰ç”¨**
**é€‰æ‹©çš„ä¸»è¦æ–¹å‰‚åŠç†ç”±**

---

## ğŸ’Š **å¤„æ–¹å»ºè®®**
å…·ä½“è¯ç‰©åŠå‰‚é‡ï¼ˆ**ä¸¥æ ¼è¦æ±‚**ï¼šè¯å ç¡®å®šå‰‚é‡gæ ¼å¼ï¼Œå¦‚"å…šå‚ 15g"ï¼Œç»ä¸ä½¿ç”¨èŒƒå›´ç”¨é‡å¦‚"12-15g"ï¼‰

---

## âš¡ **ç…æœæŒ‡å¯¼**

### **ç…åˆ¶æ–¹æ³•ï¼š**
- ğŸ”¸ è¯¦ç»†çš„ç…è¯æ–¹æ³•
- ğŸ”¸ ç…åˆ¶æ—¶é—´å’Œç«å€™

### **æœç”¨æ–¹æ³•ï¼š**  
- ğŸ”¸ å…·ä½“çš„æœç”¨æ–¹æ³•å’Œæ—¶é—´

---

## ğŸ”„ **è¾¨è¯åŠ å‡**
**éšè¯åŠ å‡ï¼š** æ ¹æ®å…¼ç—‡çš„åŠ å‡å˜åŒ–

---

## ğŸƒ **ç”Ÿæ´»è°ƒæŠ¤**
**ç”Ÿæ´»è°ƒæ‘„ï¼š** é¥®é£Ÿèµ·å±…ã€æƒ…å¿—è°ƒèŠ‚ç­‰å…·ä½“å»ºè®®

---

## ğŸ“… **å¤è¯Šå®‰æ’**

### **å¤è¯Šæ—¶é—´ï¼š**
- **é¦–æ¬¡å¤è¯Šï¼š** æœè¯3-5å¤©å
- **åç»­å¤è¯Šï¼š** æ ¹æ®ç—…æƒ…å˜åŒ–å®‰æ’

### **è§‚å¯Ÿè¦ç‚¹ï¼š**
- âœ… ä¸»è¦ç—‡çŠ¶å˜åŒ–æƒ…å†µ  
- âœ… è¯ç‰©ç–—æ•ˆåŠä¸è‰¯ååº”
- âœ… èˆŒè±¡è„‰è±¡å˜åŒ–
- âœ… é£Ÿæ¬²ç¡çœ äºŒä¾¿æƒ…å†µ

---

## âš ï¸ **é‡è¦æé†’**

> **æ³¨æ„äº‹é¡¹ï¼š**
> - æœ¬æ–¹æ¡ˆä¸ºAIè¾…åŠ©ä¸­åŒ»å»ºè®®ï¼Œä»…ä¾›å‚è€ƒ
> - å¿…é¡»åœ¨æ‰§ä¸šä¸­åŒ»å¸ˆæŒ‡å¯¼ä¸‹ä½¿ç”¨
> - ä¸èƒ½æ›¿ä»£æ­£è§„åŒ»é™¢è¯Šæ–­æ²»ç–—
> - å¦‚ç—‡çŠ¶åŠ é‡æˆ–å‡ºç°ä¸é€‚ï¼Œ**è¯·åŠæ—¶å°±åŒ»**

# è¯­è¨€é£æ ¼
- ä½¿ç”¨é€šä¿—æ˜“æ‡‚çš„ä¸­åŒ»æœ¯è¯­ï¼Œå¿…è¦æ—¶è¿›è¡Œè§£é‡Š
- è¯­æ°”äº²åˆ‡ä¸“ä¸šï¼Œä½“ç°åŒ»è€…ä»å¿ƒ
- å–„ç”¨æ¯”å–»è¯´æ˜ç—…æœºï¼ˆå¦‚"å¿ƒç«ä¸Šç‚"ã€"è‚æ°”éƒç»“"ç­‰ï¼‰
- åœ¨å…³é”®æœ¯è¯­ä¸Šä½¿ç”¨**åŠ ç²—**æ ‡è®°çªå‡ºé‡ç‚¹
"""

SYNTHESIS_PROMPT_TEMPLATE = """
# è§’è‰²è®¾å®š
ä½ æ˜¯ä¸€ä½è¡ŒåŒ»50å¤šå¹´çš„èµ„æ·±è€ä¸­åŒ»ï¼Œæœ‰ç€ä¸°å¯Œçš„ä¸´åºŠç»éªŒå’Œæ·±åšçš„ç†è®ºåŠŸåº•ã€‚ç°åœ¨éœ€è¦ä½ æ ¹æ®å¤ç±èµ„æ–™ï¼Œç»“åˆå¤šå¹´ä¸´åºŠå¿ƒå¾—ï¼Œä¸ºå¹´è½»åŒ»ç”Ÿæä¾›è¯Šç–—æŒ‡å¯¼ã€‚

# ä»»åŠ¡
æ ¹æ®ã€ç”¨æˆ·é—®é¢˜ã€‘å’Œã€å¤ç±å‚è€ƒèµ„æ–™ã€‘ï¼Œä»¥è€ä¸­åŒ»çš„è¯­æ°”å’Œç»éªŒï¼Œæ•´ç†å‡ºå®ç”¨çš„ä¸´åºŠæŒ‡å¯¼æ„è§ã€‚

# è¡¨è¾¾è¦æ±‚
1. **è€ä¸­åŒ»è¯­æ°”**: ä½¿ç”¨"æˆ‘ä»åŒ»è¿™ä¹ˆå¤šå¹´æ¥çœ‹..."ã€"æ®æˆ‘ä¸´åºŠæ‰€è§..."ã€"å¤äººæœ‰äº‘..."ã€"è¿™ç±»ç—…äººæˆ‘è§å¾—å¤šäº†..."ç­‰è¡¨è¾¾æ–¹å¼
2. **ç»éªŒåˆ†äº«**: ç»“åˆå‚è€ƒèµ„æ–™å†…å®¹ï¼Œä½†è¦ä»¥ä¸ªäººä¸´åºŠä½“ä¼šçš„æ–¹å¼è¡¨è¾¾
3. **ç†è®ºè”ç³»å®é™…**: æ—¢è¦å¼•ç”¨å¤ç±ç†è®ºï¼Œåˆè¦ç»“åˆç°ä»£ä¸´åºŠå®è·µ
4. **è¯­è¨€ç‰¹è‰²**: è¯­æ°”äº²åˆ‡ä½†æƒå¨ï¼Œå¶å°”ä½¿ç”¨ä¸­åŒ»è¡Œè¯ï¼Œä½“ç°è€ä¸­åŒ»çš„ç¿æ™ºå’Œæ…ˆç¥¥
5. **ä¸¥æ ¼ç—‡çŠ¶è®°å½•**: ã€ç»å¯¹ç¦æ­¢ã€‘æ·»åŠ ç”¨æˆ·æœªæåŠçš„ç—‡çŠ¶ï¼Œåªèƒ½åŸºäºç”¨æˆ·æ˜ç¡®æè¿°çš„ç—‡çŠ¶è¿›è¡Œåˆ†æ

# å†…å®¹è¦æ±‚
- æ•´åˆå‚è€ƒèµ„æ–™ä¸­çš„ç²¾åå†…å®¹
- æŒ‰ç…§ã€ç—…æœºåˆ†æ -> ä¸´åºŠç»éªŒ -> æ²»ç–—æ€è·¯ -> æ–¹è¯å¿ƒå¾— -> è°ƒæŠ¤å˜±å’ã€‘çš„é€»è¾‘ç»„ç»‡
- æ¯ä¸ªé‡ç‚¹å¿…é¡»æ ‡æ³¨ `[å¤ç±ä¾æ®: å‚è€ƒèµ„æ–™ N]`

---
ã€æ‚£è€…å’¨è¯¢ã€‘
{user_question}
---
ã€å¤ç±å‚è€ƒèµ„æ–™ã€‘
{context_str}
---

è¯·ä»¥ä¸€ä½ç»éªŒä¸°å¯Œçš„è€ä¸­åŒ»èº«ä»½ï¼Œç»“åˆå¤ç±æ™ºæ…§ï¼Œç»™å‡ºä¸“ä¸šè€Œäº²åˆ‡çš„ä¸´åºŠæŒ‡å¯¼ï¼š
"""

# è¾…åŠ©å‡½æ•°
def get_conversation_history_filepath(conversation_id: str) -> str: 
    return os.path.join(CONVERSATION_LOG_DIR, f"conversation_{conversation_id}.json")

def load_conversation_history(conversation_id: str) -> List[Dict[str, str]]:
    filepath = get_conversation_history_filepath(conversation_id)
    if os.path.exists(filepath):
        try:
            with open(filepath, 'r', encoding='utf-8') as f: 
                return json.load(f)
        except: 
            return []
    return []

def save_conversation_history(conversation_id: str, history: List[Dict[str, str]]):
    filepath = get_conversation_history_filepath(conversation_id)
    try:
        with open(filepath, 'w', encoding='utf-8') as f: 
            json.dump(history, f, ensure_ascii=False, indent=2)
    except: 
        pass

# API ç«¯ç‚¹
@app.get("/")
async def read_index_html(): 
    """é¦–é¡µ - è¿”å›æœ€æ–°çš„Webç•Œé¢ï¼ˆç¦ç”¨ç¼“å­˜ï¼‰"""
    from fastapi.responses import Response
    try:
        with open("/opt/tcm-ai/static/index_v2.html", "r", encoding="utf-8") as f:
            content = f.read()
            response = Response(content=content, media_type="text/html")
            # å¼ºåˆ¶ç¦ç”¨ç¼“å­˜
            response.headers["Cache-Control"] = "no-cache, no-store, must-revalidate"
            response.headers["Pragma"] = "no-cache"
            response.headers["Expires"] = "0"
            return response
    except FileNotFoundError:
        try:
            with open("/opt/tcm-ai/static/index.html", "r", encoding="utf-8") as f:
                content = f.read()
                response = Response(content=content, media_type="text/html")
                response.headers["Cache-Control"] = "no-cache, no-store, must-revalidate"
                response.headers["Pragma"] = "no-cache"
                response.headers["Expires"] = "0"
                return response
        except FileNotFoundError:
            # å¦‚æœé™æ€æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¿”å›åŸºç¡€çŠ¶æ€é¡µé¢
            return HTMLResponse("""
            <html>
                <head><title>AIä¸­åŒ»æ™ºèƒ½é—®è¯Šç³»ç»Ÿ</title></head>
                <body>
                    <h1>AIä¸­åŒ»æ™ºèƒ½é—®è¯Šç³»ç»Ÿ</h1>
                    <p>æœåŠ¡è¿è¡Œæ­£å¸¸</p>
                    <p>ç‰ˆæœ¬: 2.2.0 (è…¾è®¯äº‘å¤šæ¨¡æ€ç‰ˆ)</p>
                    <p>åŠŸèƒ½: å¯¹è¯AI + å¤šæ¨¡æ€å›¾åƒåˆ†æ</p>
                    <p><a href="/static/index.html">è¿›å…¥Webç•Œé¢</a></p>
                </body>
            </html>
            """)


@app.get("/get_conversation_history/{conversation_id}", response_model=ConversationHistoryOutput)
async def get_history_endpoint(conversation_id: str): 
    history = conversation_history_store.get(conversation_id) or load_conversation_history(conversation_id)
    return ConversationHistoryOutput(conversation_id=conversation_id, history=history) if history else ConversationHistoryOutput(conversation_id=conversation_id, history=[], message=f"No history found")

@app.post("/speech_to_text", response_model=STTOutput)
async def speech_to_text_endpoint(audio_file: UploadFile = File(...)):
    """è¯­éŸ³è½¬æ–‡å­—æ¥å£ - ä½¿ç”¨åœ¨çº¿è¯­éŸ³è¯†åˆ«"""
    logger.info(f"æ”¶åˆ°è¯­éŸ³è½¬æ–‡å­—è¯·æ±‚, æ–‡ä»¶: {audio_file.filename}")
    
    try:
        content = await audio_file.read()
        recognized_text = await speech_to_text_online(content)
        
        if not recognized_text or "ä¸å¯ç”¨" in recognized_text:
            return STTOutput(text="", error=recognized_text)
        
        return STTOutput(text=recognized_text)
        
    except Exception as e: 
        logger.error(f"STT Error: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"è¯­éŸ³è¯†åˆ«å¤±è´¥: {str(e)}")
    finally:
        await audio_file.close()

@app.post("/analyze_images", response_model=ImageAnalysisOutput)
async def analyze_images_endpoint(
    conversation_id: str = Form(...), 
    medical_image: Optional[UploadFile] = File(None),
    face_image: Optional[UploadFile] = File(None), 
    tongue_image: Optional[UploadFile] = File(None)
):
    """å›¾åƒåˆ†ææ¥å£ - ä½¿ç”¨å¤šæ¨¡æ€API"""
    analysis_texts = []
    
    # å¤„ç†é€šç”¨åŒ»å­¦å›¾åƒ (å‰ç«¯ä¸Šä¼ çš„ medical_image)
    if medical_image:
        try: 
            image_bytes = await medical_image.read()
            analysis_result = extract_features_from_image(image_bytes, "åŒ»å­¦å›¾åƒ")
            if analysis_result and analysis_result != "null":
                analysis_texts.append(analysis_result)
            else:
                logger.warning(f"Medical image analysis returned null or empty result")
                analysis_texts.append("ã€å›¾åƒè´¨é‡æç¤ºã€‘æ‚£è€…å·²ä¸Šä¼ èˆŒè±¡å›¾ç‰‡ï¼Œä½†ç”±äºå…‰çº¿ä¸è¶³ã€è§’åº¦ä¸ä½³æˆ–å›¾åƒæ¨¡ç³Šç­‰å› ç´ ï¼Œæ— æ³•è¿›è¡Œç²¾ç¡®çš„èˆŒè±¡åˆ†æã€‚å»ºè®®æ‚£è€…åœ¨è‡ªç„¶å…‰ä¸‹é‡æ–°æ‹æ‘„èˆŒè±¡ç…§ç‰‡ã€‚")
        except Exception as e:
            logger.error(f"Error processing medical image: {e}")
            analysis_texts.append(f"å›¾åƒå¤„ç†æ—¶å‘ç”Ÿé”™è¯¯ï¼š{str(e)}")
        finally: 
            await medical_image.close()
    
    # å¤„ç†é¢éƒ¨å›¾åƒ (æ”¯æŒæ—§ç‰ˆæ¥å£)
    if face_image:
        try: 
            image_bytes = await face_image.read()
            analysis_result = extract_features_from_image(image_bytes, "é¢éƒ¨")
            if analysis_result and analysis_result != "null":
                analysis_texts.append(analysis_result)
        except Exception as e:
            logger.error(f"Error processing face image: {e}")
            analysis_texts.append(f"é¢éƒ¨å›¾åƒå¤„ç†é”™è¯¯ï¼š{str(e)}")
        finally: 
            await face_image.close()
    
    # å¤„ç†èˆŒéƒ¨å›¾åƒ (æ”¯æŒæ—§ç‰ˆæ¥å£)
    if tongue_image:
        try: 
            image_bytes = await tongue_image.read()
            analysis_result = extract_features_from_image(image_bytes, "èˆŒéƒ¨")
            if analysis_result and analysis_result != "null":
                analysis_texts.append(analysis_result)
            else:
                logger.warning(f"Tongue image analysis returned null or empty result")
                analysis_texts.append("ã€å›¾åƒè´¨é‡æç¤ºã€‘æ‚£è€…å·²ä¸Šä¼ èˆŒè±¡å›¾ç‰‡ï¼Œä½†ç”±äºå…‰çº¿ä¸è¶³ã€è§’åº¦ä¸ä½³æˆ–å›¾åƒæ¨¡ç³Šç­‰å› ç´ ï¼Œæ— æ³•è¿›è¡Œç²¾ç¡®çš„èˆŒè±¡åˆ†æã€‚å»ºè®®æ‚£è€…åœ¨è‡ªç„¶å…‰ä¸‹é‡æ–°æ‹æ‘„èˆŒè±¡ç…§ç‰‡ã€‚")
        except Exception as e:
            logger.error(f"Error processing tongue image: {e}")
            analysis_texts.append(f"èˆŒéƒ¨å›¾åƒå¤„ç†é”™è¯¯ï¼š{str(e)}")
        finally: 
            await tongue_image.close()
    
    if not analysis_texts: 
        return ImageAnalysisOutput(error="æœªæä¾›æœ‰æ•ˆå›¾åƒæˆ–å›¾åƒåˆ†æå¤±è´¥")
    
    # ä¸ç«‹å³åˆ†æï¼Œåªä¿å­˜å›¾ç‰‡çš„åŸå§‹åˆ†æç»“æœåˆ°ç³»ç»Ÿæ¶ˆæ¯ä¸­
    combined_analysis = "\n".join(analysis_texts)
    
    # ä¿å­˜å›¾ç‰‡åˆ†æç»“æœåˆ°ä¼šè¯å†å²ï¼Œä½†æ ‡è®°ä¸ºå¾…å¤„ç†
    visual_features_message = {
        "role": "system", 
        "content": f"ã€å¾…åˆ†æå›¾åƒã€‘{combined_analysis}",
        "image_pending": True  # æ ‡è®°ä¸ºå¾…å¤„ç†çš„å›¾ç‰‡
    }
    
    history = conversation_history_store.get(conversation_id) or load_conversation_history(conversation_id)
    history.append(visual_features_message)
    conversation_history_store[conversation_id] = history
    save_conversation_history(conversation_id, history)
    
    # æ ¹æ®åˆ†æç»“æœè°ƒæ•´å‹å¥½æç¤ºä¿¡æ¯
    if "ã€å›¾åƒè´¨é‡æç¤ºã€‘" in combined_analysis:
        user_friendly_response = "âš ï¸ å›¾ç‰‡å·²ä¸Šä¼ ï¼Œä½†å›¾åƒè´¨é‡å¯èƒ½ä¸å¤Ÿæ¸…æ™°ã€‚\n\nğŸ’¡ ä¸ºäº†æ›´å¥½çš„è¯Šç–—æ•ˆæœï¼Œå»ºè®®æ‚¨ï¼š\nâ€¢ åœ¨å……è¶³çš„è‡ªç„¶å…‰ä¸‹é‡æ–°æ‹æ‘„\nâ€¢ ç¡®ä¿èˆŒå¤´å®Œå…¨ä¼¸å‡º\nâ€¢ é•œå¤´å‚ç›´å‘ä¸‹æ‹æ‘„\n\nğŸ“ è¯·å…ˆæè¿°ä¸€ä¸‹ç›®å‰çš„ç—‡çŠ¶ï¼š\nâ€¢ ä¸»è¦ä¸é€‚æ„Ÿè§‰\nâ€¢ æŒç»­æ—¶é—´\nâ€¢ ä¼´éšç—‡çŠ¶\nâ€¢ æ—¢å¾€ç—…å²ç­‰\n\næˆ‘å°†åŸºäºæ‚¨çš„ç—‡çŠ¶æè¿°è¿›è¡Œåˆæ­¥åˆ†æï¼Œå¦‚éœ€è¦æ›´ç²¾ç¡®çš„èˆŒè±¡è¯Šæ–­ï¼Œå†é‡æ–°æ‹æ‘„å›¾ç‰‡ã€‚"
    else:
        user_friendly_response = "âœ… èˆŒè±¡å›¾ç‰‡å·²æˆåŠŸä¸Šä¼ å¹¶ä¿å­˜ã€‚\n\nğŸ“ è¯·æ‚¨è¯¦ç»†æè¿°ä¸€ä¸‹ç›®å‰çš„ç—‡çŠ¶ï¼Œæ¯”å¦‚ï¼š\nâ€¢ ä¸»è¦ä¸é€‚æ„Ÿè§‰\nâ€¢ æŒç»­æ—¶é—´\nâ€¢ ä¼´éšç—‡çŠ¶\nâ€¢ æ—¢å¾€ç—…å²ç­‰\n\næˆ‘å°†ç»“åˆæ‚¨çš„èˆŒè±¡å›¾ç‰‡å’Œç—‡çŠ¶æè¿°ï¼Œä¸ºæ‚¨æä¾›æ›´å‡†ç¡®çš„ä¸­åŒ»è¯Šç–—å»ºè®®ã€‚"
    
    logger.info(f"Image uploaded and saved for {conversation_id}, waiting for symptom description")
    return ImageAnalysisOutput(analysis_result=user_friendly_response)

# é‡æ„ç‰ˆæœ¬ä¹Ÿå·²è¿ç§»è‡³ç»Ÿä¸€é—®è¯ŠæœåŠ¡ /api/consultation/chat
# DEPRECATED: åŸrefactoredå‡½æ•° (~150 lines) å·²ç§»è‡³ç»Ÿä¸€é—®è¯ŠæœåŠ¡
# ä¿ç•™æ­¤ä»£ç æ®µä½œä¸ºå¤‡ä»½ï¼Œå¯åœ¨éœ€è¦æ—¶æ¢å¤
# DEPRECATED: æ­¤ç«¯ç‚¹å°†åœ¨ä¸‹ä¸ªç‰ˆæœ¬ä¸­å®Œå…¨ç§»é™¤
@app.post("/chat_with_ai_deprecated", response_model=ChatMessageOutput)
async def chat_with_ai_endpoint_backup(chat_input: ChatMessageInput, request: Request):
    """åŸç‰ˆå¯¹è¯æ¥å£ - å·²åºŸå¼ƒï¼Œè¯·ä½¿ç”¨ /api/consultation/chat"""
    raise HTTPException(
        status_code=410, 
        detail="æ­¤æ¥å£å·²åºŸå¼ƒï¼Œè¯·ä½¿ç”¨ /api/consultation/chat"
    )

# åŸchat_with_aiå‡½æ•°ä½“ (550+ lines) å·²å®Œå…¨è¿ç§»è‡³ /api/consultation/chat
# åŠŸèƒ½ä¿ç•™ï¼Œæ€§èƒ½ä¼˜åŒ–ï¼Œæ¥å£ç»Ÿä¸€ - è¯·ä½¿ç”¨æ–°ç«¯ç‚¹

@app.get("/get_doctor_info/{doctor_name}")
async def get_doctor_info_endpoint(doctor_name: str):
    """è·å–åŒ»ç”Ÿä¸“ä¸šä¿¡æ¯å’Œç»Ÿè®¡"""
    try:
        if POSTGRESQL_HYBRID_AVAILABLE and hybrid_knowledge_system:
            doctor_info = hybrid_knowledge_system.get_doctor_info(doctor_name)
            if doctor_info:
                return {"success": True, "data": doctor_info}
        
        return {"success": False, "message": "åŒ»ç”Ÿä¿¡æ¯ä¸å¯ç”¨"}
    except Exception as e:
        logger.error(f"Error getting doctor info: {e}")
        return {"success": False, "error": str(e)}

@app.post("/recommend_formula")
async def recommend_formula_endpoint(symptoms_data: dict):
    """æ ¹æ®ç—‡çŠ¶æ¨èæ–¹å‰‚"""
    try:
        symptoms = symptoms_data.get("symptoms", "")
        selected_doctor = symptoms_data.get("selected_doctor", "zhang_zhongjing")
        
        if POSTGRESQL_HYBRID_AVAILABLE and hybrid_knowledge_system:
            recommendation = hybrid_knowledge_system.get_formula_recommendation(symptoms, selected_doctor)
            if recommendation:
                return {"success": True, "data": recommendation}
        
        return {"success": False, "message": "æ–¹å‰‚æ¨èä¸å¯ç”¨"}
    except Exception as e:
        logger.error(f"Error recommending formula: {e}")
        return {"success": False, "error": str(e)}

@app.get("/get_doctor_introductions")
async def get_doctor_introductions_endpoint():
    """è·å–åŒ»ç”Ÿç®€ä»‹ä¿¡æ¯"""
    try:
        if ENHANCED_SYSTEM_AVAILABLE and persona_generator:
            introductions = persona_generator.doctor_personas.get_doctor_introductions()
            return {"success": True, "data": introductions}
        else:
            # å¤‡ç”¨é™æ€æ•°æ®
            static_introductions = {
                "zhang_zhongjing": {
                    "name": "å¼ ä»²æ™¯åŒ»å¸ˆ",
                    "school": "ä¼¤å¯’æ´¾",
                    "introduction": "ä¼¤å¯’æ´¾ä»¥ã€Šä¼¤å¯’è®ºã€‹ä¸ºç†è®ºåŸºç¡€ï¼Œæ“…é•¿å…­ç»è¾¨è¯ï¼Œæ²»ç–—å¤–æ„Ÿç—…å’Œå†…ä¼¤æ‚ç—…ã€‚ç”¨è¯ç²¾å‡†ï¼Œæ–¹è¯å¯¹åº”ï¼Œè¯å°‘åŠ›ä¸“ï¼Œé€‚åˆæ€¥æ€§æ„Ÿå†’ã€å‘çƒ­ã€æ¶ˆåŒ–ç³»ç»Ÿç–¾ç—…ç­‰ã€‚æ³¨é‡è„‰è¯åˆå‚ï¼Œè¾¨è¯ä¸¥è°¨ã€‚",
                    "specialty": "å¤–æ„Ÿç—…, å†…ä¼¤æ‚ç—…, æ€¥ç—‡"
                },
                "ye_tianshi": {
                    "name": "å¶å¤©å£«åŒ»å¸ˆ",
                    "school": "æ¸©ç—…æ´¾", 
                    "introduction": "æ¸©ç—…æ´¾ä¸“æ²»å„ç§çƒ­æ€§ç–¾ç—…ï¼Œä»¥å«æ°”è¥è¡€è¾¨è¯ä¸ºç‰¹è‰²ï¼Œç”¨è¯è½»æ¸…çµåŠ¨ã€‚æ“…é•¿å„¿ç§‘å¦‡ç§‘ç–¾ç—…ï¼Œé‡è§†æ¸…çƒ­å…»é˜´ï¼Œä¿æŠ¤æ´¥æ¶²ã€‚é€‚åˆå‘çƒ­ã€å’½å–‰è‚¿ç—›ã€çš®è‚¤ç—…ã€å¦‡å¥³ç»æœŸçƒ­ç—‡ç­‰ã€‚",
                    "specialty": "æ¸©ç—…, çƒ­ç—…, å„¿ç§‘, å¦‡ç§‘"
                },
                "liu_duzhou": {
                    "name": "åˆ˜æ¸¡èˆŸåŒ»å¸ˆ",
                    "school": "ç»æ–¹æ´¾",
                    "introduction": "ç»æ–¹æ´¾ä¸¥æ ¼æŒ‰ç…§å¤ä»£ç»å…¸æ–¹å‰‚æ²»ç–—ï¼Œå¼ºè°ƒæ–¹è¯å¯¹åº”ã€‚ç‰¹åˆ«æ“…é•¿ç–‘éš¾æ‚ç—‡å’Œæ…¢æ€§ç–¾ç—…ï¼Œé‡è§†ä¸»ç—‡æŠ“å–å’Œä½“è´¨è¾¨è¯†ã€‚é€‚åˆå¤±çœ ã€å¿ƒæ‚¸ã€æ…¢æ€§èƒƒç—…ã€è‚èƒ†ç–¾ç—…ç­‰éœ€è¦ç²¾å‡†è°ƒç†çš„ç—…ç—‡ã€‚",
                    "specialty": "ç»æ–¹åº”ç”¨, ç–‘éš¾æ‚ç—‡, æ…¢æ€§ç—…"
                },
                "li_dongyuan": {
                    "name": "æä¸œå£åŒ»å¸ˆ",
                    "school": "è¡¥åœŸæ´¾",
                    "introduction": "è¡¥åœŸæ´¾ä»¥è°ƒç†è„¾èƒƒä¸ºæ ¸å¿ƒï¼Œè®¤ä¸ºè„¾èƒƒä¸ºåå¤©ä¹‹æœ¬ã€‚æ“…é•¿æ²»ç–—æ¶ˆåŒ–ç³»ç»Ÿç–¾ç—…å’Œå†…ä¼¤å‘çƒ­ï¼Œé‡è§†è¡¥ä¸­ç›Šæ°”ã€å‡é˜³ä¸¾é™·ã€‚é€‚åˆé£Ÿæ¬²ä¸æŒ¯ã€æ¶ˆåŒ–ä¸è‰¯ã€æ…¢æ€§è…¹æ³»ã€è„±è‚›ã€ä¹åŠ›ç­‰è„¾èƒƒè™šå¼±ç—‡çŠ¶ã€‚ç”¨è¯æ¸©å’Œï¼Œæ³¨é‡è°ƒå…»ã€‚",
                    "specialty": "è„¾èƒƒç—…, å†…ä¼¤å‘çƒ­, æ¶ˆåŒ–ç³»ç»Ÿç–¾ç—…"
                },
                "zheng_qin_an": {
                    "name": "éƒ‘é’¦å®‰åŒ»å¸ˆ",
                    "school": "æ‰¶é˜³æ´¾",
                    "introduction": "æ‰¶é˜³æ´¾é‡è§†é˜³æ°”ï¼Œè®¤ä¸ºä¸‡ç—…çš†ç”±é˜³æ°”ä¸è¶³æ‰€è‡´ã€‚æ“…é•¿æ²»ç–—å„ç§é˜³è™šç—‡çŠ¶å’Œæ€¥å±é‡ç—‡ï¼Œå–„ç”¨é™„å­ã€å¹²å§œç­‰æ¸©é˜³è¯ç‰©ã€‚é€‚åˆæ€•å†·ã€ä¹åŠ›ã€è…¹æ³»ã€æ°´è‚¿ã€å¿ƒè¡°ç­‰é˜³æ°”è™šå¼±çš„ç–¾ç—…ã€‚ç”¨è¯åŠ›é‡è¾ƒçŒ›ï¼Œè§æ•ˆå¿«ã€‚",
                    "specialty": "é˜³è™šè¯, æ€¥å±é‡ç—‡, ç–‘éš¾æ‚ç—‡"
                },
                "zhu_danxi": {
                    "name": "æœ±ä¸¹æºªåŒ»å¸ˆ", 
                    "school": "æ»‹é˜´æ´¾",
                    "introduction": "æ»‹é˜´æ´¾é‡è§†å…»é˜´æ¸…çƒ­ï¼Œæ“…é•¿æ²»ç–—é˜´è™šç«æ—ºå’Œå„ç§å†…ç§‘è°ƒå…»ï¼Œç”¨è¯å¹³å’Œæœ‰æ•ˆã€‚ä»¥æ»‹é˜´é™ç«ä¸ºä¸»è¦æ²»ç–—åŸåˆ™ï¼Œæ³¨é‡è°ƒç†é˜´è¡€ä¸è¶³ã€‚é€‚åˆæ½®çƒ­ç›—æ±—ã€å£å¹²å’½ç‡¥ã€å¤±çœ å¤šæ¢¦ã€æœˆç»ä¸è°ƒç­‰é˜´è™šå†…çƒ­ç—‡çŠ¶ã€‚",
                    "specialty": "é˜´è™šç«æ—º, å¦‡ç§‘æ‚ç—‡, å†…ç§‘è°ƒå…»"
                }
            }
            return {"success": True, "data": static_introductions}
    except Exception as e:
        logger.error(f"Error getting doctor introductions: {e}")
        return {"success": False, "error": str(e)}

@app.get("/debug_status")
async def debug_status_endpoint():
    """è°ƒè¯•çŠ¶æ€ç«¯ç‚¹"""
    try:
        status = {
            "server_status": "running",
            "enhanced_system_available": ENHANCED_SYSTEM_AVAILABLE,
            "doctor_mind_system_available": DOCTOR_MIND_SYSTEM_AVAILABLE,
            "zhang_zhongjing_system_available": ZHANG_ZHONGJING_SYSTEM_AVAILABLE,
            "cache_system_available": CACHE_SYSTEM_AVAILABLE,
            "conversation_store_size": len(conversation_history_store),
            "session_store_size": len(conversation_session_store),
            "knowledge_db_path": KNOWLEDGE_DB_PATH,
            "api_key_configured": bool(DASHSCOPE_API_KEY)
        }
        
        # æ·»åŠ ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯
        if CACHE_SYSTEM_AVAILABLE and cache_system:
            try:
                cache_stats = cache_system.get_cache_stats()
                status["cache_stats"] = {
                    "total_entries": cache_stats.total_entries,
                    "hit_rate": f"{cache_stats.hit_rate:.3f}",
                    "cache_size_mb": f"{cache_stats.cache_size_mb:.2f}",
                    "total_queries": cache_system.total_queries,
                    "cache_hits": cache_system.cache_hits,
                    "cache_misses": cache_system.cache_misses
                }
            except Exception as e:
                status["cache_stats"] = {"error": str(e)}
        
        if ENHANCED_SYSTEM_AVAILABLE:
            status["enhanced_retrieval_initialized"] = enhanced_retrieval is not None
            status["persona_generator_initialized"] = persona_generator is not None
            status["learning_system_initialized"] = learning_system is not None
        
        if DOCTOR_MIND_SYSTEM_AVAILABLE:
            status["enhanced_treatment_generator_initialized"] = enhanced_treatment_generator is not None
            status["doctor_mind_api_initialized"] = doctor_mind_api is not None
        
        if ZHANG_ZHONGJING_SYSTEM_AVAILABLE:
            status["zhang_zhongjing_system_initialized"] = zhang_zhongjing_system is not None
        
        return status
    except Exception as e:
        logger.error(f"Error in debug_status: {e}")
        return {"error": str(e)}

@app.get("/test_upload_page")
async def test_upload_page():
    """æä¾›å›¾ç‰‡ä¸Šä¼ æµ‹è¯•é¡µé¢"""
    with open(str(PATHS['static_dir'] / 'test_upload_simple.html'), "r", encoding="utf-8") as f:
        html_content = f.read()
    return HTMLResponse(content=html_content)

@app.get("/mobile_debug_test")
async def mobile_debug_test():
    """æä¾›ç§»åŠ¨ç«¯å¼¹çª—è°ƒè¯•æµ‹è¯•é¡µé¢"""
    with open("/opt/tcm/mobile_debug_test.html", "r", encoding="utf-8") as f:
        html_content = f.read()
    return HTMLResponse(content=html_content)

@app.get("/diagnosis_progress/{conversation_id}")
async def get_diagnosis_progress(conversation_id: str):
    """è·å–ç‰¹å®šå¯¹è¯çš„è¯Šæ–­è¿›åº¦"""
    try:
        progress_info = medical_diagnosis_controller.get_diagnosis_progress_info(conversation_id)
        return progress_info
    except Exception as e:
        logger.error(f"è·å–è¯Šæ–­è¿›åº¦å¤±è´¥: {e}")
        return {"error": str(e)}

# å¤„æ–¹æ£€æŸ¥ç³»ç»ŸAPIç«¯ç‚¹
@app.post("/api/prescription/check")
async def check_prescription_endpoint(
    prescription_text: str = Form(...),
    patient_info: str = Form(None)
):
    """å¤„æ–¹æ£€æŸ¥API - ä½¿ç”¨åŸºç¡€å¤„æ–¹è§£æå™¨"""
    try:
        logger.info(f"å¤„æ–¹æ£€æµ‹APIæ”¶åˆ°è¯·æ±‚: prescription_text='{prescription_text}', patient_info='{patient_info}'")
        
        # è§£ææ‚£è€…ä¿¡æ¯
        patient_data = {}
        if patient_info:
            try:
                import json
                patient_data = json.loads(patient_info)
            except:
                patient_data = {}
        
        # ä½¿ç”¨åŸºç¡€å¤„æ–¹è§£æå™¨
        from core.prescription.prescription_checker import PrescriptionParser
        
        parser = PrescriptionParser()
        logger.info(f"å¼€å§‹è§£æå¤„æ–¹æ–‡æœ¬: '{prescription_text[:100]}...'")
        prescription = parser.parse_prescription_text(prescription_text)
        logger.info(f"å¤„æ–¹è§£æç»“æœ: æˆåŠŸ={prescription is not None}, è¯ç‰©æ•°é‡={len(prescription.herbs) if prescription else 0}")
        
        if prescription and prescription.herbs:
            # æ„å»ºè¯ç‰©åˆ—è¡¨
            herbs_list = []
            total_dosage = 0
            
            for herb in prescription.herbs:
                herb_info = {
                    "name": herb.name,
                    "dosage": herb.dosage,
                    "unit": herb.unit,
                    "preparation": herb.preparation or ""
                }
                herbs_list.append(herb_info)
                
                # è®¡ç®—æ€»å‰‚é‡ï¼ˆç®€å•è§£ææ•°å­—ï¼‰
                try:
                    dosage_str = herb.dosage.replace('g', '').replace('å…‹', '').strip()
                    if '-' in dosage_str:
                        dosage_str = dosage_str.split('-')[0]
                    dosage_num = float(dosage_str)
                    total_dosage += dosage_num
                except:
                    pass
            
            result = {
                "success": True,
                "analysis_type": "ä¸­åŒ»å¤„æ–¹åŸºç¡€è§£æ",
                "prescription": {
                    "herbs": herbs_list,
                    "total_count": len(herbs_list),
                    "total_dosage": f"{total_dosage}g",
                    "preparation_method": prescription.preparation_method or "æ°´ç…æœ",
                    "usage_instructions": prescription.usage_instructions or "ä¸€æ—¥ä¸€å‰‚ï¼Œåˆ†2-3æ¬¡æœç”¨"
                },
                "tcm_analysis": {
                    "syndrome_analysis": {
                        "primary_syndrome": "è¯·å’¨è¯¢ä¸“ä¸šä¸­åŒ»å¸ˆè¿›è¡Œè¾¨è¯åˆ†æ",
                        "analysis_note": "åŸºç¡€è§£æå™¨ä¸æä¾›è¾¨è¯åˆ†æ"
                    },
                    "prescription_pattern": "åŸºç¡€æ¨¡å¼ï¼šè¯·ä¸“ä¸šåŒ»å¸ˆæä¾›è¾¨è¯åˆ†æ",
                    "clinical_assessment": {
                        "therapeutic_effects": ["éœ€è¦ä¸“ä¸šä¸­åŒ»å¸ˆè¯„ä¼°"],
                        "dosage_notes": [f"æ€»å‰‚é‡çº¦{total_dosage}gï¼Œç¬¦åˆå¸¸è§„ç”¨é‡"],
                        "usage_guidance": ["è¯·æŒ‰åŒ»å¸ˆæŒ‡å¯¼æœç”¨"]
                    },
                    "professional_comments": [
                        "æœ¬æ¬¡ä¸ºåŸºç¡€è§£æï¼Œè¯†åˆ«åˆ°æœ‰æ•ˆä¸­è¯æˆåˆ†",
                        "å…·ä½“è¾¨è¯åˆ†æéœ€è¦ä¸“ä¸šä¸­åŒ»å¸ˆè¿›è¡Œ",
                        "è¯·å¯»æ±‚æ­£è§„ä¸­åŒ»é™¢ä¸“ä¸šæŒ‡å¯¼"
                    ]
                },
                "safety_check": {
                    "is_safe": True,
                    "warnings": ["è¯·åœ¨ä¸“ä¸šåŒ»å¸ˆæŒ‡å¯¼ä¸‹ä½¿ç”¨"]
                },
                "detailed_analysis": {
                    "dosage_analysis": {
                        "total_dosage": f"{total_dosage}g",
                        "dosage_range_ratio": "å¸¸è§„å‰‚é‡èŒƒå›´",
                        "ratio_analysis": ["å‰‚é‡éœ€è¦ä¸“ä¸šåŒ»å¸ˆæ ¹æ®æ‚£è€…å…·ä½“æƒ…å†µè°ƒæ•´"]
                    },
                    "therapeutic_analysis": {
                        "treatment_methods": ["éœ€è¦ä¸“ä¸šä¸­åŒ»å¸ˆåˆ¶å®šæ²»ç–—æ–¹æ¡ˆ"],
                        "therapeutic_focus": ["åŸºç¡€è§£æå·²è¯†åˆ«è¯ç‰©æˆåˆ†"],
                        "expected_effects": ["å…·ä½“ç–—æ•ˆéœ€è¦ä¸“ä¸šåŒ»å¸ˆè¯„ä¼°"]
                    }
                }
            }
            
            # ğŸ“ è‡ªåŠ¨å­¦ä¹ å¤„ç†ï¼šå°†å¤„æ–¹æ•°æ®ç”¨äºç³»ç»Ÿå­¦ä¹ 
            try:
                learning_integrator = get_prescription_learning_integrator()
                learning_success = await learning_integrator.process_prescription_data(
                    prescription_data={'prescription': result['prescription']},
                    source_type="text_upload",
                    patient_info=patient_data if patient_data else None
                )
                if learning_success:
                    logger.info(f"âœ… å¤„æ–¹æ•°æ®å·²ç”¨äºç³»ç»Ÿå­¦ä¹ ")
                else:
                    logger.warning(f"âš ï¸ å¤„æ–¹å­¦ä¹ å¤„ç†æœªå®Œå…¨æˆåŠŸ")
            except Exception as learning_error:
                logger.warning(f"âš ï¸ å¤„æ–¹å­¦ä¹ å¤±è´¥ï¼ˆä¸å½±å“æ£€æµ‹ç»“æœï¼‰: {learning_error}")
            
            # ğŸ¯ æ·»åŠ å›è‡£ä½ä½¿åˆ†æ - ä¿®å¤PCç«¯bug
            try:
                from core.prescription.tcm_formula_analyzer import analyze_formula_with_ai
                
                # è½¬æ¢è¯ææ ¼å¼ä»¥åŒ¹é…åˆ†æå™¨è¦æ±‚
                analysis_herbs = []
                for herb in herbs_list:
                    analysis_herb = {
                        'name': herb['name'],
                        'dosage': float(herb['dosage'].replace('g', '').replace('å…‹', '').strip().split('-')[0]),
                        'unit': herb.get('unit', 'g')
                    }
                    analysis_herbs.append(analysis_herb)
                
                if len(analysis_herbs) >= 3:  # è‡³å°‘3å‘³è¯æ‰è¿›è¡Œåˆ†æ
                    logger.info(f"å¼€å§‹å›è‡£ä½ä½¿åˆ†æï¼Œå…±{len(analysis_herbs)}å‘³è¯æ")
                    formula_analysis = analyze_formula_with_ai(analysis_herbs)
                    result['formula_analysis'] = formula_analysis
                    logger.info(f"å›è‡£ä½ä½¿åˆ†æå®Œæˆ: {formula_analysis.get('confidence_level', 'unknown')}")
                else:
                    logger.info(f"è¯ææ•°é‡ä¸è¶³({len(analysis_herbs)}å‘³)ï¼Œè·³è¿‡å›è‡£ä½ä½¿åˆ†æ")
                    result['formula_analysis'] = {
                        'message': 'è¯ææ•°é‡ä¸è¶³ï¼Œå»ºè®®è‡³å°‘3å‘³è¯ææ‰èƒ½è¿›è¡Œå›è‡£ä½ä½¿åˆ†æ',
                        'roles': {'å›è¯': [], 'è‡£è¯': [], 'ä½è¯': [], 'ä½¿è¯': []},
                        'confidence_level': 'insufficient_data'
                    }
                    
            except Exception as analysis_error:
                logger.error(f"å›è‡£ä½ä½¿åˆ†æå¤±è´¥: {analysis_error}")
                result['formula_analysis'] = {
                    'error': f'åˆ†æå¤±è´¥: {str(analysis_error)}',
                    'roles': {'å›è¯': [], 'è‡£è¯': [], 'ä½è¯': [], 'ä½¿è¯': []},
                    'confidence_level': 'failed'
                }
            
            return {
                "success": True,
                "data": result
            }
        else:
            # å¤„æ–¹è§£æå¤±è´¥
            return {
                "success": False,
                "error": "æœªèƒ½è¯†åˆ«åˆ°æœ‰æ•ˆçš„ä¸­è¯å¤„æ–¹ä¿¡æ¯",
                "data": {
                    "suggestion": "è¯·ç¡®ä¿æ–‡æœ¬åŒ…å«è§„èŒƒçš„ä¸­è¯åç§°å’Œå‰‚é‡ä¿¡æ¯ï¼Œæ ¼å¼å¦‚ï¼šéº»é»„ 9g"
                }
            }
        
    except Exception as e:
        logger.error(f"å¤„æ–¹æ£€æŸ¥APIé”™è¯¯: {e}")
        return {
            "success": False,
            "error": str(e)
        }

@app.post("/api/prescription/add_famous_doctor")
async def add_famous_doctor_prescription_endpoint(
    prescription_text: str = Form(...),
    doctor_name: str = Form(...),
    source: str = Form("manual_input")
):
    """æ·»åŠ ååŒ»å¤„æ–¹åˆ°å­¦ä¹ ç³»ç»Ÿ"""
    try:
        checker = get_prescription_checker()
        if not checker:
            return {
                "success": False,
                "error": "å¤„æ–¹æ£€æŸ¥ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥"
            }
        
        success = checker.add_famous_doctor_prescription(
            prescription_text, doctor_name, source
        )
        
        return {
            "success": success,
            "message": "å¤„æ–¹æ·»åŠ æˆåŠŸ" if success else "å¤„æ–¹æ·»åŠ å¤±è´¥"
        }
        
    except Exception as e:
        return {
            "success": False,
            "error": str(e)
        }

@app.get("/api/prescription/doctor_patterns/{doctor_name}")
async def get_doctor_patterns_endpoint(doctor_name: str):
    """è·å–ç‰¹å®šåŒ»ç”Ÿçš„å¤„æ–¹è§„å¾‹"""
    try:
        system = get_famous_doctor_system()
        if not system:
            return {
                "success": False,
                "error": "ååŒ»å­¦ä¹ ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥"
            }
        
        patterns = system.learn_doctor_prescription_patterns(doctor_name)
        return {
            "success": True,
            "data": patterns
        }
        
    except Exception as e:
        return {
            "success": False,
            "error": str(e)
        }

# OCRå›¾ç‰‡è¯†åˆ«APIç«¯ç‚¹
@app.post("/api/prescription/ocr")
async def prescription_ocr_endpoint(file: UploadFile = File(...)):
    """å¤„æ–¹å›¾ç‰‡OCRè¯†åˆ«API"""
    try:
        # æ£€æŸ¥æ–‡ä»¶ç±»å‹
        if not file.content_type or not file.content_type.startswith(('image/', 'application/pdf')):
            return {
                "success": False,
                "error": "ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹ï¼Œè¯·ä¸Šä¼ å›¾ç‰‡(JPG/PNG)æˆ–PDFæ–‡ä»¶"
            }
        
        # è¯»å–æ–‡ä»¶æ•°æ®
        file_data = await file.read()
        if len(file_data) > 10 * 1024 * 1024:  # é™åˆ¶10MB
            return {
                "success": False,
                "error": "æ–‡ä»¶è¿‡å¤§ï¼Œè¯·ä¸Šä¼ 10MBä»¥å†…çš„æ–‡ä»¶"
            }
        
        # è·å–OCRç³»ç»Ÿ
        ocr = get_ocr_system()
        
        # æ ¹æ®æ–‡ä»¶ç±»å‹å¤„ç†
        if file.content_type == 'application/pdf':
            result = ocr.process_pdf(file_data, file.filename)
        else:
            result = ocr.process_image(file_data, file.filename)
        
        return result
        
    except Exception as e:
        logger.error(f"å¤„æ–¹OCRè¯†åˆ«å¤±è´¥: {e}")
        return {
            "success": False,
            "error": f"OCRè¯†åˆ«å¤±è´¥: {str(e)}"
        }

@app.post("/api/prescription/check_image_v2")  
async def prescription_check_image_multimodal(file: UploadFile = File(...)):
    """ä½¿ç”¨å¤šæ¨¡LLMçš„æ–°å¤„æ–¹å›¾ç‰‡æ£€æŸ¥API - ç°ä»£åŒ–æ–¹æ¡ˆ"""
    
    try:
        import tempfile
        from services.multimodal_processor import analyze_prescription_image_bytes
        
        # éªŒè¯æ–‡ä»¶ç±»å‹
        if not file.content_type or not file.content_type.startswith('image/'):
            return {
                "success": False,
                "error": "è¯·ä¸Šä¼ å›¾ç‰‡æ–‡ä»¶ (JPG, PNG, GIFç­‰æ ¼å¼)",
                "document_type": "æ–‡ä»¶æ ¼å¼é”™è¯¯"
            }
        
        # è¯»å–æ–‡ä»¶å†…å®¹
        content = await file.read()
        
        # éªŒè¯æ–‡ä»¶å¤§å° (10MBé™åˆ¶)
        if len(content) > 10 * 1024 * 1024:
            return {
                "success": False,
                "error": "å›¾ç‰‡æ–‡ä»¶è¿‡å¤§ï¼Œè¯·ä¸Šä¼ å°äº10MBçš„å›¾ç‰‡",
                "document_type": "æ–‡ä»¶è¿‡å¤§"
            }
        
        # ä½¿ç”¨å¤šæ¨¡LLMåˆ†æ
        logger.info(f"ä½¿ç”¨å¤šæ¨¡LLMåˆ†æå¤„æ–¹å›¾ç‰‡: {file.filename}")
        result = await analyze_prescription_image_bytes(content, file.filename or "prescription.jpg")
        
        logger.info(f"å¤šæ¨¡æ€å¤„ç†å™¨è¿”å›ç»“æœç±»å‹: {type(result)}")
        logger.info(f"å¤šæ¨¡æ€å¤„ç†å™¨è¿”å›ç»“æœæˆåŠŸçŠ¶æ€: {result.get('success')}")
        logger.debug(f"å¤šæ¨¡æ€å¤„ç†å™¨è¿”å›ç»“æœ: {str(result)[:500]}...")
        
        # æ£€æŸ¥å¤šæ¨¡æ€å¤„ç†å™¨è¿”å›çš„æ ¼å¼å¹¶ç¡®ä¿æ­£ç¡®æ€§
        if result.get('success'):
            logger.info(f"æ£€æŸ¥å¤šæ¨¡æ€ç»“æœæ ¼å¼ï¼ŒåŒ…å«å­—æ®µ: {list(result.keys())}")
            
            # æ£€æŸ¥æ˜¯å¦å·²ç»æ˜¯å¤šæ¨¡æ€æ ¼å¼
            if 'document_analysis' in result and 'prescription' in result:
                logger.info("å¤šæ¨¡æ€å¤„ç†å™¨è¿”å›æ ‡å‡†æ ¼å¼ï¼Œç›´æ¥è¿”å›")
                # ç¡®ä¿confidenceå­—æ®µå­˜åœ¨
                if 'confidence' not in result['document_analysis']:
                    result['document_analysis']['confidence'] = 0.95
                    logger.warning("è¡¥å……ç¼ºå¤±çš„confidenceå­—æ®µ")
                
                # ğŸ“ è‡ªåŠ¨å­¦ä¹ å¤„ç†ï¼šå°†å›¾ç‰‡å¤„æ–¹æ•°æ®ç”¨äºç³»ç»Ÿå­¦ä¹ 
                try:
                    learning_integrator = get_prescription_learning_integrator()
                    learning_success = await learning_integrator.process_prescription_data(
                        prescription_data=result,
                        source_type="image_upload",
                        patient_info=None  # å›¾ç‰‡ä¸Šä¼ é€šå¸¸ä¸åŒ…å«æ‚£è€…ä¿¡æ¯
                    )
                    if learning_success:
                        logger.info(f"âœ… å›¾ç‰‡å¤„æ–¹æ•°æ®å·²ç”¨äºç³»ç»Ÿå­¦ä¹ ")
                    else:
                        logger.warning(f"âš ï¸ å›¾ç‰‡å¤„æ–¹å­¦ä¹ å¤„ç†æœªå®Œå…¨æˆåŠŸ")
                except Exception as learning_error:
                    logger.warning(f"âš ï¸ å›¾ç‰‡å¤„æ–¹å­¦ä¹ å¤±è´¥ï¼ˆä¸å½±å“æ£€æµ‹ç»“æœï¼‰: {learning_error}")
                
                return result
            else:
                # å¦‚æœè¿”å›äº†éæ ‡å‡†æ ¼å¼ï¼Œéœ€è¦è½¬æ¢
                logger.warning("å¤šæ¨¡æ€å¤„ç†å™¨è¿”å›éæ ‡å‡†æ ¼å¼ï¼Œè¿›è¡Œè½¬æ¢")
                logger.info(f"è½¬æ¢å‰çš„ç»“æœç»“æ„: {list(result.keys())}")
                
                # ä»analysiså­—æ®µæå–herbs_details
                analysis = result.get('analysis', {})
                herbs_details = analysis.get('herbs_details', [])
                
                converted_result = {
                    "success": True,
                    "document_analysis": {
                        "type": result.get('document_type', 'ä¸­åŒ»å¤„æ–¹'),
                        "confidence": result.get('confidence', 0.95),
                        "quality": "æ¸…æ™°",
                        "notes": result.get('step', '')
                    },
                    "prescription": {
                        "herbs": herbs_details,
                        "total_herbs": analysis.get('total_herbs', len(herbs_details)),
                        "usage": analysis.get('usage_info', {}),
                        "estimated_cost": analysis.get('estimated_cost')
                    },
                    "patient_info": result.get('patient_info', {}),
                    "medical_info": result.get('medical_info', {}),
                    "diagnosis": result.get('diagnosis', {}),
                    "safety_analysis": result.get('safety_analysis', {}),
                    "clinical_analysis": result.get('clinical_analysis', {}),
                    "processing_info": result.get('processing_info', {})
                }
                
                logger.info(f"è½¬æ¢ååŒ…å« {len(herbs_details)} å‘³ä¸­è¯")
                logger.info(f"è½¬æ¢åçš„ç»“æœç»“æ„: {list(converted_result.keys())}")
                
                # ğŸ“ è‡ªåŠ¨å­¦ä¹ å¤„ç†ï¼šå°†è½¬æ¢åçš„å›¾ç‰‡å¤„æ–¹æ•°æ®ç”¨äºç³»ç»Ÿå­¦ä¹ 
                try:
                    learning_integrator = get_prescription_learning_integrator()
                    learning_success = await learning_integrator.process_prescription_data(
                        prescription_data=converted_result,
                        source_type="image_upload_converted",
                        patient_info=None  # å›¾ç‰‡ä¸Šä¼ é€šå¸¸ä¸åŒ…å«æ‚£è€…ä¿¡æ¯
                    )
                    if learning_success:
                        logger.info(f"âœ… è½¬æ¢åçš„å›¾ç‰‡å¤„æ–¹æ•°æ®å·²ç”¨äºç³»ç»Ÿå­¦ä¹ ")
                    else:
                        logger.warning(f"âš ï¸ è½¬æ¢åçš„å›¾ç‰‡å¤„æ–¹å­¦ä¹ å¤„ç†æœªå®Œå…¨æˆåŠŸ")
                except Exception as learning_error:
                    logger.warning(f"âš ï¸ è½¬æ¢åçš„å›¾ç‰‡å¤„æ–¹å­¦ä¹ å¤±è´¥ï¼ˆä¸å½±å“æ£€æµ‹ç»“æœï¼‰: {learning_error}")
                
                return converted_result
        else:
            return {
                "success": False,
                "error": result.get('error', 'å¤šæ¨¡LLMåˆ†æå¤±è´¥'),
                "document_type": "åˆ†æå¤±è´¥",
                "step": "å¤šæ¨¡LLMåˆ†æå¼‚å¸¸"
            }
            
    except Exception as e:
        logger.error(f"å¤šæ¨¡LLMå¤„æ–¹åˆ†æå¼‚å¸¸: {e}")
        logger.error(f"å¼‚å¸¸ç±»å‹: {type(e)}")
        logger.error(f"å¼‚å¸¸å †æ ˆ: {str(e)}", exc_info=True)
        return {
            "success": False,
            "error": f"ç³»ç»Ÿå¤„ç†å¼‚å¸¸: {str(e)}",
            "document_analysis": {
                "type": "ç³»ç»Ÿé”™è¯¯",
                "confidence": 0.0,
                "notes": f"å¤„ç†å¼‚å¸¸: {str(e)}"
            },
            "processing_info": {
                "error": True,
                "processed_at": "å¼‚å¸¸æ—¶é—´"
            }
        }

@app.post("/api/prescription/check_image")
async def prescription_check_image_endpoint(
    file: UploadFile = File(...),
    patient_info: str = Form(None)
):
    """å›¾ç‰‡å¤„æ–¹ä¸€ç«™å¼æ£€æŸ¥API (OCR + å¤„æ–¹æ£€æŸ¥) - ä¼ ç»Ÿæ–¹æ¡ˆ"""
    try:
        # 1. OCRè¯†åˆ«
        if not file.content_type or not file.content_type.startswith(('image/', 'application/pdf')):
            return {
                "success": False,
                "error": "ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹ï¼Œè¯·ä¸Šä¼ å›¾ç‰‡æˆ–PDFæ–‡ä»¶"
            }
        
        file_data = await file.read()
        if len(file_data) > 10 * 1024 * 1024:
            return {
                "success": False,
                "error": "æ–‡ä»¶è¿‡å¤§ï¼Œè¯·ä¸Šä¼ 10MBä»¥å†…çš„æ–‡ä»¶"
            }
        
        # ä½¿ç”¨ä¼˜åŒ–çš„è‡ªé€‚åº”OCRç­–ç•¥
        try:
            from adaptive_ocr_strategy import AdaptiveOCRStrategy
            adaptive_ocr = AdaptiveOCRStrategy()
            
            logger.info("ä½¿ç”¨è‡ªé€‚åº”OCRç­–ç•¥å¤„ç†å›¾ç‰‡")
            
            if file.content_type == 'application/pdf':
                # PDFæš‚æ—¶ä½¿ç”¨åŸæœ‰é€»è¾‘
                ocr = get_ocr_system()
                ocr_result = ocr.process_pdf(file_data, file.filename)
            else:
                # å›¾ç‰‡ä½¿ç”¨ä¼˜åŒ–çš„è‡ªé€‚åº”ç­–ç•¥
                adaptive_result = adaptive_ocr.auto_detect_and_process(file_data)
                
                # è½¬æ¢ä¸ºå…¼å®¹æ ¼å¼
                ocr_result = {
                    "success": adaptive_result.is_usable,
                    "original_text": adaptive_result.text,
                    "corrected_text": adaptive_result.text,
                    "combined_text": adaptive_result.text,
                    "confidence": adaptive_result.final_confidence,
                    "original_confidence": adaptive_result.original_confidence,
                    "quality_score": adaptive_result.quality_score,
                    "content_type": adaptive_result.content_type,
                    "strategy_used": adaptive_result.strategy_used,
                    "processing_time": adaptive_result.processing_time,
                    "adaptive_info": {
                        "quality_reasons": adaptive_result.quality_reasons,
                        "is_optimized": True
                    }
                }
                
                logger.info(f"è‡ªé€‚åº”OCRç»“æœ: ç±»å‹{adaptive_result.content_type}, ç­–ç•¥{adaptive_result.strategy_used}, ç½®ä¿¡åº¦{adaptive_result.original_confidence:.3f}->{adaptive_result.final_confidence:.3f}")
        
        except ImportError:
            logger.warning("è‡ªé€‚åº”OCRç­–ç•¥ä¸å¯ç”¨ï¼Œä½¿ç”¨åŸå§‹OCR")
            # é™çº§åˆ°åŸå§‹OCR
            ocr = get_ocr_system()
            if file.content_type == 'application/pdf':
                ocr_result = ocr.process_pdf(file_data, file.filename)
            else:
                ocr_result = ocr.process_image(file_data, file.filename)
        
        if not ocr_result["success"]:
            return {
                "success": False,
                "step": "OCRè¯†åˆ«",
                "error": ocr_result.get("error", "OCRè¯†åˆ«å¤±è´¥"),
                "ocr_result": ocr_result
            }
        
        # 2. å¤„æ–¹å®‰å…¨æ£€æŸ¥
        prescription_text = ocr_result.get("corrected_text", ocr_result.get("combined_text", ""))
        if not prescription_text.strip():
            return {
                "success": False,
                "step": "æ–‡æœ¬æå–",
                "error": "æ— æ³•ä»å›¾ç‰‡ä¸­æå–åˆ°å¤„æ–¹æ–‡æœ¬",
                "ocr_result": ocr_result
            }
        
        # è§£ææ‚£è€…ä¿¡æ¯
        patient_data = {}
        if patient_info:
            try:
                patient_data = json.loads(patient_info)
            except:
                patient_data = {}
        
        # ä½¿ç”¨é›†æˆç‰ˆå¤„æ–¹è§£æå™¨ï¼ˆä¿®å¤ç‰ˆï¼‰
        try:
            analysis_result = parse_prescription_text(prescription_text)
            
            # ä½¿ç”¨æ™ºèƒ½å¤„æ–¹å“åº”å™¨å¤„ç†è§£æå¤±è´¥æƒ…å†µ
            if not analysis_result["success"]:
                try:
                    from intelligent_prescription_responder import IntelligentPrescriptionResponder
                    intelligent_responder = IntelligentPrescriptionResponder()
                    
                    logger.info(f"åŸå§‹è§£æå¤±è´¥ï¼Œå¯ç”¨æ™ºèƒ½æ–‡æ¡£ç±»å‹è¯†åˆ«å’Œå“åº”...")
                    
                    # ä½¿ç”¨æ™ºèƒ½å“åº”å™¨ç”Ÿæˆåˆé€‚çš„å“åº”
                    intelligent_response = intelligent_responder.generate_appropriate_response(
                        prescription_text, 
                        analysis_result
                    )
                    
                    logger.info(f"æ™ºèƒ½åˆ†ç±»ç»“æœ: {intelligent_response.get('document_type', 'æœªçŸ¥')} (ç½®ä¿¡åº¦: {intelligent_response.get('classification_confidence', 0):.3f})")
                    
                    # å°†OCRç»“æœä¹Ÿæ·»åŠ åˆ°æ™ºèƒ½å“åº”ä¸­
                    intelligent_response["ocr_result"] = ocr_result
                    
                    return intelligent_response
                
                except ImportError:
                    logger.warning("æ™ºèƒ½å¤„æ–¹å“åº”å™¨ä¸å¯ç”¨ï¼Œä½¿ç”¨åŸå§‹é€»è¾‘")
                    # é™çº§åˆ°åŸå§‹çš„ä½ç½®ä¿¡åº¦å¤„ç†
                    if ocr_result.get("confidence", 0) < 0.1 and ocr_result.get("corrected_text"):
                        return {
                            "success": False,
                            "step": "åŸºç¡€OCRå¤„ç†", 
                            "error": f"OCRç½®ä¿¡åº¦è¾ƒä½({ocr_result.get('confidence', 0):.3f})ï¼Œä½†å·²è¯†åˆ«åˆ°å†…å®¹",
                            "suggestion": "åŸºäºä¼˜åŒ–åçš„ç³»ç»Ÿï¼Œä½ç½®ä¿¡åº¦å†…å®¹å¯èƒ½ä»æœ‰ä»·å€¼ï¼Œå»ºè®®æŸ¥çœ‹è¯†åˆ«ç»“æœ",
                            "partial_content": ocr_result.get("corrected_text", "")[:200] + "...",
                            "ocr_result": ocr_result
                        }
                
                # å¦‚æœæ™ºèƒ½å“åº”å™¨ä¹Ÿä¸å¯ç”¨ï¼Œè¿”å›åŸå§‹é”™è¯¯ä¿¡æ¯
                return {
                    "success": False,
                    "step": "å¤„æ–¹è§£æ",
                    "error": analysis_result.get("error", "æ— æ³•è¯†åˆ«è¶³å¤Ÿçš„ä¸­è¯ä¿¡æ¯è¿›è¡Œåˆ†æ"),
                    "ocr_result": ocr_result,
                    "analysis_details": analysis_result
                }
            
            # è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼
            check_result = {
                "success": True,
                "analysis_type": "ä¸­åŒ»æ™ºèƒ½å¤„æ–¹åˆ†æï¼ˆä¿®å¤ç‰ˆï¼‰",
                "prescription": {
                    "herbs": analysis_result["herbs"],
                    "total_count": analysis_result["total_herbs"],
                    "document_type": analysis_result.get("document_type", "unknown")
                },
                "validation": analysis_result.get("validation", {}),
                "parsing_notes": analysis_result.get("parsing_notes", []),
                "special_note": analysis_result.get("special_note", ""),
                "analysis_confidence": analysis_result.get("validation", {}).get("confidence_summary", {}).get("average", 0.8),
                "safety_check": {"is_safe": True, "warnings": []}
            }
            
        except (ImportError, Exception) as e:
            # å›é€€åˆ°åŸæœ‰ç³»ç»Ÿ
            logger.warning(f"é›†æˆå¤„æ–¹è§£æå™¨å¤±è´¥ï¼Œå›é€€åˆ°åŸæœ‰ç³»ç»Ÿ: {e}")
            checker = get_prescription_checker()
            if not checker:
                return {
                    "success": False,
                    "step": "å¤„æ–¹æ£€æŸ¥",
                    "error": "å¤„æ–¹æ£€æŸ¥ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥",
                    "ocr_result": ocr_result
                }
            check_result = checker.check_prescription(prescription_text, patient_data)
        
        return {
            "success": True,
            "ocr_result": ocr_result,
            "prescription_check": check_result,
            "processing_summary": {
                "ocr_confidence": ocr_result.get("confidence", 0.0),
                "prescription_found": check_result.get("success", False),
                "safety_passed": check_result.get("safety_check", {}).get("is_safe", False),
                "total_herbs": len(check_result.get("prescription", {}).get("herbs", [])) if check_result.get("prescription") else 0
            }
        }
        
    except Exception as e:
        logger.error(f"å›¾ç‰‡å¤„æ–¹æ£€æŸ¥å¤±è´¥: {e}")
        return {
            "success": False,
            "step": "ç³»ç»Ÿå¤„ç†",
            "error": f"å¤„ç†å¤±è´¥: {str(e)}"
        }

@app.get("/api/prescription/ocr_stats")
async def get_ocr_stats_endpoint():
    """è·å–OCRç³»ç»Ÿç»Ÿè®¡ä¿¡æ¯"""
    try:
        ocr = get_ocr_system()
        stats = ocr.get_system_stats()
        return {
            "success": True,
            "stats": stats,
            "system_info": {
                "version": "1.0.0",
                "supported_formats": ["JPG", "JPEG", "PNG", "BMP", "TIFF", "PDF"],
                "max_file_size": "10MB",
                "ocr_service": "ç™¾åº¦OCR"
            }
        }
    except Exception as e:
        logger.error(f"è·å–OCRç»Ÿè®¡å¤±è´¥: {e}")
        return {
            "success": False,
            "error": str(e)
        }

# å¤„æ–¹æ£€æŸ¥ç•Œé¢
@app.get("/prescription/checker")
async def prescription_checker_page():
    """å¤„æ–¹æ£€æŸ¥ç•Œé¢"""
    from fastapi.responses import HTMLResponse
    
    # ä½¿ç”¨å®Œæ•´åŠŸèƒ½ç‰ˆæœ¬
    try:
        from fastapi.responses import FileResponse
        return FileResponse("/opt/tcm-ai/static/prescription_checker_v2.html")
    except FileNotFoundError:
        return HTMLResponse("""
            <html><body>
                <h1>ğŸ¥ å¤„æ–¹æ£€æŸ¥ç³»ç»Ÿ</h1>
                <p>ç³»ç»Ÿæ­£åœ¨æ›´æ–°ä¸­...</p>
                <a href="/">è¿”å›ä¸»é¡µ</a>
            </body></html>
        """)

@app.get("/prescription/learning")
async def prescription_learning_dashboard():
    """å¤„æ–¹å­¦ä¹ ç»Ÿè®¡é¢æ¿"""
    try:
        return FileResponse("/opt/tcm-ai/static/prescription_learning_dashboard.html")
    except FileNotFoundError:
        from fastapi.responses import HTMLResponse
        return HTMLResponse("""
            <html><body>
                <h1>å¤„æ–¹å­¦ä¹ ç»Ÿè®¡é¢æ¿</h1>
                <p>é¡µé¢æ–‡ä»¶æœªæ‰¾åˆ°ï¼Œè¯·æ£€æŸ¥ç³»ç»Ÿé…ç½®ã€‚</p>
                <a href="/">è¿”å›ä¸»é¡µ</a>
            </body></html>
        """, status_code=404)

@app.get("/prescription/debug")
async def prescription_debug_page():
    """å¤„æ–¹æ£€æŸ¥ç§»åŠ¨ç«¯è°ƒè¯•é¡µé¢"""
    from fastapi.responses import HTMLResponse
    
    try:
        with open('/opt/tcm/mobile_prescription_debug.html', 'r', encoding='utf-8') as f:
            html_content = f.read()
        return HTMLResponse(html_content)
    except FileNotFoundError:
        return HTMLResponse("<h1>è°ƒè¯•é¡µé¢æœªæ‰¾åˆ°</h1>")

@app.get("/diagnosis_safety_status")
async def diagnosis_safety_status():
    """è·å–è¯Šæ–­å®‰å…¨ç³»ç»ŸçŠ¶æ€"""
    try:
        return {
            "diagnosis_controller_active": True,
            "total_tracked_conversations": len(medical_diagnosis_controller.diagnosis_progress),
            "stage_requirements": {
                stage.value: [req.value for req in requirements]
                for stage, requirements in medical_diagnosis_controller.stage_requirements.items()
            },
            "safety_features": [
                "å››è¯Šä¿¡æ¯å¼ºåˆ¶æ”¶é›†",
                "å¤šè½®é—®è¯Šè¦æ±‚", 
                "å¤„æ–¹å‰å®‰å…¨æ£€æŸ¥",
                "é˜²æ­¢è‰ç‡å¼€æ–¹"
            ]
        }
    except Exception as e:
        logger.error(f"è·å–è¯Šæ–­å®‰å…¨çŠ¶æ€å¤±è´¥: {e}")
        return {"error": str(e)}

@app.post("/submit_feedback", response_model=FeedbackOutput)
async def submit_feedback_endpoint(feedback_input: FeedbackInput):
    """æäº¤ç”¨æˆ·åé¦ˆ"""
    try:
        conversation_id = feedback_input.conversation_id
        
        # æŸ¥æ‰¾æœ€è¿‘çš„ä¼šè¯è®°å½•
        recent_session_id = None
        for session_id, session_data in conversation_session_store.items():
            if session_id.startswith(conversation_id):
                recent_session_id = session_id
        
        if not recent_session_id:
            return FeedbackOutput(success=False, message="æœªæ‰¾åˆ°å¯¹åº”çš„ä¼šè¯è®°å½•")
        
        session_data = conversation_session_store[recent_session_id]
        
        # å¦‚æœå­¦ä¹ ç³»ç»Ÿå¯ç”¨ï¼Œè®°å½•åé¦ˆ
        if ENHANCED_SYSTEM_AVAILABLE and learning_system:
            try:
                feedback = UserFeedback(
                    session_id=recent_session_id,
                    user_query=session_data["user_query"],
                    selected_doctor=session_data["selected_doctor"],
                    ai_response=session_data["ai_response"],
                    user_rating=feedback_input.rating,
                    feedback_text=feedback_input.feedback_text,
                    timestamp=datetime.fromisoformat(feedback_input.timestamp.replace('Z', '+00:00'))
                )
                
                learning_system.record_feedback(feedback)
                logger.info(f"Feedback recorded for session {recent_session_id}: rating={feedback_input.rating}")
                
                return FeedbackOutput(success=True, message="åé¦ˆå·²æˆåŠŸè®°å½•ï¼Œè°¢è°¢æ‚¨çš„è¯„ä»·ï¼")
                
            except Exception as e:
                logger.error(f"Failed to record feedback: {e}")
                return FeedbackOutput(success=False, message="åé¦ˆè®°å½•å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•")
        else:
            logger.info(f"Basic feedback logged: rating={feedback_input.rating}")
            return FeedbackOutput(success=True, message="æ„Ÿè°¢æ‚¨çš„åé¦ˆï¼")
            
    except Exception as e:
        logger.error(f"Error in submit_feedback_endpoint: {e}")
        return FeedbackOutput(success=False, message="æäº¤åé¦ˆæ—¶å‘ç”Ÿé”™è¯¯")

# åŒ»ç”Ÿæ€ç»´å†³ç­–æ ‘ç³»ç»ŸAPIç«¯ç‚¹ (ä¿æŒæ‰€æœ‰åŸæœ‰ç«¯ç‚¹)
class CaseInput(BaseModel):
    case_id: Optional[str] = None
    patient_symptoms: Dict[str, Any]
    doctor_reasoning: List[str]
    final_prescription: Dict[str, Any]
    treatment_outcome: str
    success_rating: float
    doctor_id: str
    disease_category: str

class DoctorLearningInput(BaseModel):
    doctor_id: str
    doctor_name: str

class DoctorRecommendationInput(BaseModel):
    user_query: str
    patient_data: Optional[Dict[str, Any]] = None

class DirectThinkingPatternInput(BaseModel):
    doctor_id: str
    doctor_name: str
    disease_category: str
    specialty_area: str
    pattern_accuracy: Optional[float] = 0.9
    case_count: Optional[int] = 0
    decision_logic: List[Dict[str, Any]]

# æ‰€æœ‰åŒ»ç”Ÿæ€ç»´ç³»ç»Ÿçš„APIç«¯ç‚¹ (ä¿æŒä¸å˜)
@app.post("/add_case_example")
async def add_case_example_endpoint(case_input: CaseInput):
    if not DOCTOR_MIND_SYSTEM_AVAILABLE or not doctor_mind_api:
        return {"success": False, "message": "åŒ»ç”Ÿæ€ç»´ç³»ç»Ÿä¸å¯ç”¨"}
    
    try:
        case_data = {
            "case_id": case_input.case_id,
            "patient_symptoms": case_input.patient_symptoms,
            "doctor_reasoning": case_input.doctor_reasoning,
            "final_prescription": case_input.final_prescription,
            "treatment_outcome": case_input.treatment_outcome,
            "success_rating": case_input.success_rating,
            "doctor_id": case_input.doctor_id,
            "disease_category": case_input.disease_category
        }
        
        result = doctor_mind_api.add_case_api(case_data)
        logger.info(f"Added case example: {case_input.case_id or 'auto-generated'}")
        return result
        
    except Exception as e:
        logger.error(f"Error adding case example: {e}")
        return {"success": False, "message": f"æ·»åŠ æ¡ˆä¾‹å¤±è´¥: {str(e)}"}

@app.post("/import_thinking_pattern")
async def import_thinking_pattern_endpoint(pattern_input: DirectThinkingPatternInput):
    """å¯¼å…¥åŒ»ç”Ÿæ€ç»´æ¨¡å¼"""
    if not DOCTOR_MIND_SYSTEM_AVAILABLE or not doctor_mind_api:
        return {"success": False, "message": "åŒ»ç”Ÿæ€ç»´ç³»ç»Ÿä¸å¯ç”¨"}
    
    try:
        pattern_data = {
            "doctor_id": pattern_input.doctor_id,
            "doctor_name": pattern_input.doctor_name,
            "disease_category": pattern_input.disease_category,
            "specialty_area": pattern_input.specialty_area,
            "pattern_accuracy": pattern_input.pattern_accuracy,
            "case_count": pattern_input.case_count,
            "decision_logic": pattern_input.decision_logic
        }
        
        result = doctor_mind_api.import_thinking_pattern_api(pattern_data)
        logger.info(f"Imported thinking pattern for {pattern_input.doctor_name}")
        return result
        
    except Exception as e:
        logger.error(f"Error importing thinking pattern: {e}")
        return {"success": False, "message": f"å¯¼å…¥æ€ç»´æ¨¡å¼å¤±è´¥: {str(e)}"}

@app.post("/learn_doctor_patterns/{doctor_id}")
async def learn_doctor_patterns_endpoint(doctor_id: str, doctor_name: str = ""):
    """å­¦ä¹ åŒ»ç”Ÿæ€ç»´æ¨¡å¼"""
    if not DOCTOR_MIND_SYSTEM_AVAILABLE or not doctor_mind_api:
        return {"success": False, "message": "åŒ»ç”Ÿæ€ç»´ç³»ç»Ÿä¸å¯ç”¨"}
    
    try:
        if not doctor_name:
            doctor_name = doctor_id
            
        result = doctor_mind_api.learn_patterns_api(doctor_id, doctor_name)
        logger.info(f"Learned patterns for doctor: {doctor_id}")
        return result
        
    except Exception as e:
        logger.error(f"Error learning doctor patterns: {e}")
        return {"success": False, "message": f"å­¦ä¹ åŒ»ç”Ÿæ¨¡å¼å¤±è´¥: {str(e)}"}

@app.post("/recommend_doctors")
async def recommend_doctors_endpoint(recommendation_input: DoctorRecommendationInput):
    """æ¨èæœ€é€‚åˆçš„åŒ»ç”Ÿ"""
    if not DOCTOR_MIND_SYSTEM_AVAILABLE or not doctor_mind_api:
        return {"success": False, "message": "åŒ»ç”Ÿæ€ç»´ç³»ç»Ÿä¸å¯ç”¨"}
    
    try:
        result = doctor_mind_api.recommend_doctors_api(
            recommendation_input.user_query, 
            recommendation_input.patient_data
        )
        logger.info(f"Generated doctor recommendations for query: {recommendation_input.user_query[:50]}...")
        return result
        
    except Exception as e:
        logger.error(f"Error recommending doctors: {e}")
        return {"success": False, "message": f"æ¨èåŒ»ç”Ÿå¤±è´¥: {str(e)}"}

@app.get("/doctor_statistics")
async def get_doctor_statistics_endpoint():
    """è·å–åŒ»ç”Ÿç»Ÿè®¡ä¿¡æ¯"""
    if not DOCTOR_MIND_SYSTEM_AVAILABLE or not doctor_mind_api:
        return {"success": False, "message": "åŒ»ç”Ÿæ€ç»´ç³»ç»Ÿä¸å¯ç”¨"}
    
    try:
        result = doctor_mind_api.get_statistics_api()
        return result
        
    except Exception as e:
        logger.error(f"Error getting doctor statistics: {e}")
        return {"success": False, "message": f"è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {str(e)}"}

@app.post("/doctor_authenticate")
async def doctor_authenticate_endpoint(auth_data: dict):
    """åŒ»ç”Ÿèº«ä»½è®¤è¯"""
    try:
        code = auth_data.get("code", "")
        name = auth_data.get("name", "")
        
        # é¢„è®¾çš„åŒ»ç”Ÿè®¿é—®ç ï¼ˆå®é™…éƒ¨ç½²æ—¶åº”ä½¿ç”¨æ•°æ®åº“ç®¡ç†ï¼‰
        valid_codes = {
            'tcm2024': 'ä¸­åŒ»AIç³»ç»Ÿ',
            'doctor123': 'æ¼”ç¤ºåŒ»ç”Ÿ', 
            'zhangzj': 'å¼ ä»²æ™¯ä¼ äºº',
            'lidongyw': 'æä¸œå£ä¼ äºº',
            'yetsh': 'å¶å¤©å£«ä¼ äºº',
            'admin001': 'ç³»ç»Ÿç®¡ç†å‘˜'
        }
        
        if code in valid_codes:
            logger.info(f"Doctor authentication successful: {name} ({code})")
            return {
                "success": True, 
                "message": f"æ¬¢è¿ {name} åŒ»ç”Ÿ",
                "doctor_name": name,
                "access_level": valid_codes[code]
            }
        else:
            logger.warning(f"Failed doctor authentication attempt: {name} ({code})")
            return {
                "success": False,
                "message": "è®¿é—®ç é”™è¯¯ï¼Œè¯·è”ç³»ç³»ç»Ÿç®¡ç†å‘˜"
            }
            
    except Exception as e:
        logger.error(f"Error in doctor authentication: {e}")
        return {"success": False, "message": f"è®¤è¯å¤±è´¥: {str(e)}"}

@app.get("/doctor_portal_info")
async def get_doctor_portal_info():
    """è·å–åŒ»ç”Ÿé—¨æˆ·ä¿¡æ¯"""
    try:
        # è·å–ç³»ç»Ÿç»Ÿè®¡
        stats_result = {"statistics": {"total_doctors": 0, "total_patterns": 0, "total_cases": 0}}
        if DOCTOR_MIND_SYSTEM_AVAILABLE and doctor_mind_api:
            stats_result = doctor_mind_api.get_statistics_api()
        
        # è·å–æœåŠ¡å™¨ä¿¡æ¯
        import socket
        hostname = socket.gethostname()
        
        return {
            "success": True,
            "server_info": {
                "hostname": hostname,
                "port": 8000,
                "doctor_mind_available": DOCTOR_MIND_SYSTEM_AVAILABLE
            },
            "statistics": stats_result.get("statistics", {}),
            "access_urls": {
                "portal": "/static/doctor_portal.html",
                "thinking_input": "/static/doctor_thinking_input.html",
                "management": "/static/doctor_management.html"
            }
        }
        
    except Exception as e:
        logger.error(f"Error getting doctor portal info: {e}")
        return {"success": False, "message": f"è·å–é—¨æˆ·ä¿¡æ¯å¤±è´¥: {str(e)}"}

# åˆ†äº«ç»Ÿè®¡API
@app.post("/api/share_visit")
async def share_visit_api(request: Request):
    """è®°å½•åˆ†äº«é¡µé¢è®¿é—®"""
    try:
        data = await request.json()
        logger.info(f"Share visit: {data}")
        return {"success": True}
    except:
        return {"success": False}

@app.post("/api/wechat_visit") 
async def wechat_visit_api(request: Request):
    """è®°å½•å¾®ä¿¡è®¿é—®"""
    try:
        data = await request.json()
        logger.info(f"Wechat visit: {data}")
        return {"success": True}
    except:
        return {"success": False}

# ============ ç”¨æˆ·å†å²è®°å½•ç³»ç»Ÿ API ============

@app.get("/api/user/info")
async def get_user_info_api(request: Request):
    """è·å–å½“å‰ç”¨æˆ·ä¿¡æ¯"""
    if not USER_HISTORY_AVAILABLE:
        return {"success": False, "error": "ç”¨æˆ·å†å²ç³»ç»Ÿä¸å¯ç”¨"}
    
    try:
        # ç”Ÿæˆè®¾å¤‡æŒ‡çº¹
        request_info = {
            'user_agent': request.headers.get('user-agent', ''),
            'client_ip': request.client.host,
            'accept_language': request.headers.get('accept-language', '')
        }
        device_fingerprint = user_history.generate_device_fingerprint(request_info)
        
        # è·å–ç”¨æˆ·ä¿¡æ¯
        user_id = user_history.register_or_get_user(device_fingerprint)
        user_info = user_history.get_user_info(user_id)
        
        if user_info:
            return {"success": True, **user_info}
        else:
            return {"success": False, "error": "ç”¨æˆ·ä¿¡æ¯ä¸å­˜åœ¨"}
            
    except Exception as e:
        logger.error(f"è·å–ç”¨æˆ·ä¿¡æ¯å¤±è´¥: {e}")
        return {"success": False, "error": str(e)}

@app.get("/api/user/sessions")
async def get_user_sessions_api(request: Request, limit: int = 20):
    """è·å–ç”¨æˆ·çš„é—®è¯Šä¼šè¯å†å²"""
    if not USER_HISTORY_AVAILABLE:
        return {"success": False, "error": "ç”¨æˆ·å†å²ç³»ç»Ÿä¸å¯ç”¨"}
    
    try:
        # è·å–ç”¨æˆ·ID
        request_info = {
            'user_agent': request.headers.get('user-agent', ''),
            'client_ip': request.client.host,
            'accept_language': request.headers.get('accept-language', '')
        }
        device_fingerprint = user_history.generate_device_fingerprint(request_info)
        user_id = user_history.register_or_get_user(device_fingerprint)
        
        # è·å–ä¼šè¯å†å²
        sessions = user_history.get_user_sessions(user_id, limit)
        
        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        doctor_names = set(session['doctor_name'] for session in sessions)
        earliest_session = min(sessions, key=lambda x: x['created_at'])['created_at'] if sessions else None
        usage_days = 0
        if earliest_session:
            from datetime import datetime
            earliest_date = datetime.fromisoformat(earliest_session)
            usage_days = (datetime.now() - earliest_date).days + 1
        
        stats = {
            'total_sessions': len(sessions),
            'doctor_count': len(doctor_names),
            'usage_days': usage_days
        }
        
        return {
            "success": True,
            "sessions": sessions,
            "stats": stats
        }
        
    except Exception as e:
        logger.error(f"è·å–ç”¨æˆ·ä¼šè¯å†å²å¤±è´¥: {e}")
        return {"success": False, "error": str(e)}

@app.get("/api/user/sessions/{doctor_name}")
async def get_user_doctor_sessions_api(doctor_name: str, request: Request):
    """è·å–ç”¨æˆ·ä¸ç‰¹å®šåŒ»ç”Ÿçš„ä¼šè¯å†å²"""
    if not USER_HISTORY_AVAILABLE:
        return {"success": False, "error": "ç”¨æˆ·å†å²ç³»ç»Ÿä¸å¯ç”¨"}
    
    try:
        # è·å–ç”¨æˆ·ID
        request_info = {
            'user_agent': request.headers.get('user-agent', ''),
            'client_ip': request.client.host,
            'accept_language': request.headers.get('accept-language', '')
        }
        device_fingerprint = user_history.generate_device_fingerprint(request_info)
        user_id = user_history.register_or_get_user(device_fingerprint)
        
        # è·å–ç‰¹å®šåŒ»ç”Ÿçš„ä¼šè¯å†å²
        sessions = user_history.get_sessions_by_doctor(user_id, doctor_name)
        
        return {
            "success": True,
            "doctor_name": doctor_name,
            "sessions": sessions
        }
        
    except Exception as e:
        logger.error(f"è·å–åŒ»ç”Ÿä¼šè¯å†å²å¤±è´¥: {e}")
        return {"success": False, "error": str(e)}

@app.get("/api/user/conversation/{conversation_id}")
async def get_conversation_detail_api(conversation_id: str, request: Request):
    """è·å–å¯¹è¯è¯¦æƒ…"""
    if not USER_HISTORY_AVAILABLE:
        return {"success": False, "error": "ç”¨æˆ·å†å²ç³»ç»Ÿä¸å¯ç”¨"}
    
    try:
        # éªŒè¯ç”¨æˆ·æƒé™
        user_agent = request.headers.get('user-agent', '')
        client_ip = request.client.host
        accept_language = request.headers.get('accept-language', '')
        request_info = {'user_agent': user_agent, 'client_ip': client_ip, 'accept_language': accept_language}
        device_fingerprint = user_history.generate_device_fingerprint(request_info)
        user_id = user_history.register_or_get_user(device_fingerprint)
        
        # è·å–å¯¹è¯è¯¦æƒ…
        conversation_detail = user_history.get_conversation_detail(conversation_id, user_id)
        
        if not conversation_detail:
            return {"success": False, "error": "å¯¹è¯ä¸å­˜åœ¨æˆ–æ— æƒé™è®¿é—®"}
        
        return conversation_detail
        
    except Exception as e:
        logger.error(f"è·å–å¯¹è¯è¯¦æƒ…APIå¤±è´¥: {e}")
        return {"success": False, "error": "è·å–å¯¹è¯è¯¦æƒ…å¤±è´¥"}

@app.get("/api/user/conversation/{conversation_id}/export")
async def export_conversation_api(conversation_id: str, request: Request, format: str = "medical_record"):
    """å¯¼å‡ºå¯¹è¯ä¸ºä¸“ä¸šåŒ»ç–—æ ¼å¼"""
    if not USER_HISTORY_AVAILABLE:
        return Response("ç”¨æˆ·å†å²ç³»ç»Ÿä¸å¯ç”¨", status_code=503, media_type="text/plain")
    
    try:
        # éªŒè¯ç”¨æˆ·æƒé™
        user_agent = request.headers.get('user-agent', '')
        client_ip = request.client.host
        accept_language = request.headers.get('accept-language', '')
        request_info = {'user_agent': user_agent, 'client_ip': client_ip, 'accept_language': accept_language}
        device_fingerprint = user_history.generate_device_fingerprint(request_info)
        user_id = user_history.register_or_get_user(device_fingerprint)
        
        # è·å–å¯¹è¯è¯¦æƒ…
        conversation_detail = user_history.get_conversation_detail(conversation_id, user_id)
        
        if not conversation_detail:
            return Response("å¯¹è¯ä¸å­˜åœ¨æˆ–æ— æƒé™è®¿é—®", status_code=404, media_type="text/plain")
        
        # ç”Ÿæˆä¸“ä¸šåŒ»ç–—æ ¼å¼
        if format == "medical_record":
            exported_content = user_history.export_as_medical_record(conversation_detail)
            media_type = "text/html; charset=utf-8"
            filename = f"TCM_ç—…å†_{conversation_id[:8]}_{datetime.now().strftime('%Y%m%d')}.html"
        else:
            exported_content = user_history.export_as_text(conversation_detail)
            media_type = "text/plain; charset=utf-8"
            filename = f"TCM_è®°å½•_{conversation_id[:8]}_{datetime.now().strftime('%Y%m%d')}.txt"
        
        # è¿”å›æ–‡ä»¶å“åº” - å½»åº•ä¿®å¤ä¸­æ–‡ç¼–ç é—®é¢˜
        from urllib.parse import quote
        
        # å¯¹ä¸­æ–‡æ–‡ä»¶åè¿›è¡ŒURLç¼–ç 
        encoded_filename = quote(filename.encode('utf-8'), safe='')
        
        # ç”Ÿæˆçº¯ASCIIçš„å®‰å…¨æ–‡ä»¶åä½œä¸ºå¤‡é€‰
        safe_filename = f"TCM_Record_{conversation_id[:8]}_{datetime.now().strftime('%Y%m%d')}.{'html' if format == 'medical_record' else 'txt'}"
        
        # ç¡®ä¿å†…å®¹æ˜¯UTF-8å­—èŠ‚
        if isinstance(exported_content, str):
            content_bytes = exported_content.encode('utf-8')
        else:
            content_bytes = exported_content
            
        return Response(
            content=content_bytes,
            media_type=media_type,
            headers={
                "Content-Disposition": f"attachment; filename=\"{safe_filename}\"; filename*=UTF-8''{encoded_filename}",
                "Content-Type": f"{media_type}; charset=utf-8"
            }
        )
        
    except Exception as e:
        logger.error(f"å¯¼å‡ºå¯¹è¯APIå¤±è´¥: {e}")
        return Response("å¯¼å‡ºå¤±è´¥", status_code=500, media_type="text/plain")

@app.get("/history")
async def user_history_page():
    """ç”¨æˆ·å†å²è®°å½•é¡µé¢"""
    try:
        return FileResponse("/opt/tcm-ai/static/user_history.html")
    except Exception as e:
        logger.error(f"åŠ è½½å†å²è®°å½•é¡µé¢å¤±è´¥: {e}")
        return HTMLResponse("<h1>é¡µé¢åŠ è½½å¤±è´¥</h1>", status_code=500)

@app.get("/api/user/stats")
async def get_user_stats_api():
    """è·å–ç”¨æˆ·ç³»ç»Ÿç»Ÿè®¡ä¿¡æ¯ï¼ˆç®¡ç†ç”¨ï¼‰"""
    if not USER_HISTORY_AVAILABLE:
        return {"success": False, "error": "ç”¨æˆ·å†å²ç³»ç»Ÿä¸å¯ç”¨"}
    
    try:
        stats = user_history.get_system_stats()
        return {"success": True, **stats}
    except Exception as e:
        logger.error(f"è·å–ç³»ç»Ÿç»Ÿè®¡å¤±è´¥: {e}")
        return {"success": False, "error": str(e)}

# ========== æ‰‹æœºéªŒè¯ç›¸å…³API (ç¬¬äºŒé˜¶æ®µæ–°å¢) ==========

@app.post("/api/auth/send-verification-code")
async def send_verification_code_api(request: Request):
    """å‘é€æ‰‹æœºéªŒè¯ç """
    if not USER_HISTORY_AVAILABLE:
        return {"success": False, "error": "ç”¨æˆ·å†å²ç³»ç»Ÿä¸å¯ç”¨"}
    
    try:
        # è·å–è¯·æ±‚æ•°æ®
        data = await request.json()
        phone = data.get('phone', '').strip()
        
        if not phone:
            return {"success": False, "error": "æ‰‹æœºå·ä¸èƒ½ä¸ºç©º"}
        
        # å‘é€éªŒè¯ç 
        result = user_history.send_verification_code(phone)
        logger.info(f"å‘é€éªŒè¯ç ç»“æœ: {result}")
        
        return result
        
    except Exception as e:
        logger.error(f"å‘é€éªŒè¯ç APIå¤±è´¥: {e}")
        return {"success": False, "error": "å‘é€éªŒè¯ç å¤±è´¥"}

@app.post("/api/auth/verify-phone-code")
async def verify_phone_code_api(request: Request):
    """éªŒè¯æ‰‹æœºéªŒè¯ç """
    if not USER_HISTORY_AVAILABLE:
        return {"success": False, "error": "ç”¨æˆ·å†å²ç³»ç»Ÿä¸å¯ç”¨"}
    
    try:
        # è·å–è¯·æ±‚æ•°æ®
        data = await request.json()
        phone = data.get('phone', '').strip()
        code = data.get('code', '').strip()
        
        if not phone or not code:
            return {"success": False, "error": "æ‰‹æœºå·å’ŒéªŒè¯ç ä¸èƒ½ä¸ºç©º"}
        
        # éªŒè¯éªŒè¯ç 
        result = user_history.verify_phone_code(phone, code)
        logger.info(f"éªŒè¯ç éªŒè¯ç»“æœ: {result}")
        
        return result
        
    except Exception as e:
        logger.error(f"éªŒè¯ç éªŒè¯APIå¤±è´¥: {e}")
        return {"success": False, "error": "éªŒè¯ç éªŒè¯å¤±è´¥"}

@app.post("/api/auth/bind-phone")
async def bind_phone_api(request: Request):
    """ç»‘å®šæ‰‹æœºå·åˆ°å½“å‰è®¾å¤‡ç”¨æˆ·"""
    if not USER_HISTORY_AVAILABLE:
        return {"success": False, "error": "ç”¨æˆ·å†å²ç³»ç»Ÿä¸å¯ç”¨"}
    
    try:
        # è·å–è¯·æ±‚æ•°æ®
        data = await request.json()
        phone = data.get('phone', '').strip()
        nickname = data.get('nickname', '').strip()
        
        if not phone:
            return {"success": False, "error": "æ‰‹æœºå·ä¸èƒ½ä¸ºç©º"}
        
        # ç”Ÿæˆè®¾å¤‡æŒ‡çº¹
        request_info = {
            'user_agent': request.headers.get('user-agent', ''),
            'client_ip': request.client.host,
            'accept_language': request.headers.get('accept-language', '')
        }
        device_fingerprint = user_history.generate_device_fingerprint(request_info)
        
        # ç»‘å®šæ‰‹æœºå·
        result = user_history.bind_phone_to_user(device_fingerprint, phone, nickname)
        logger.info(f"æ‰‹æœºå·ç»‘å®šç»“æœ: {result}")
        
        return result
        
    except Exception as e:
        logger.error(f"æ‰‹æœºå·ç»‘å®šAPIå¤±è´¥: {e}")
        return {"success": False, "error": "æ‰‹æœºå·ç»‘å®šå¤±è´¥"}

@app.post("/api/auth/phone-login")
async def phone_login_api(request: Request):
    """æ‰‹æœºå·ç™»å½•ï¼ˆå¤šè®¾å¤‡æ”¯æŒï¼‰"""
    if not USER_HISTORY_AVAILABLE:
        return {"success": False, "error": "ç”¨æˆ·å†å²ç³»ç»Ÿä¸å¯ç”¨"}
    
    try:
        # è·å–è¯·æ±‚æ•°æ®
        data = await request.json()
        phone = data.get('phone', '').strip()
        
        if not phone:
            return {"success": False, "error": "æ‰‹æœºå·ä¸èƒ½ä¸ºç©º"}
        
        # ç”Ÿæˆè®¾å¤‡æŒ‡çº¹
        request_info = {
            'user_agent': request.headers.get('user-agent', ''),
            'client_ip': request.client.host,
            'accept_language': request.headers.get('accept-language', '')
        }
        device_fingerprint = user_history.generate_device_fingerprint(request_info)
        
        # æ‰‹æœºå·ç™»å½•
        result = user_history.login_with_phone(phone, device_fingerprint)
        logger.info(f"æ‰‹æœºå·ç™»å½•ç»“æœ: {result}")
        
        return result
        
    except Exception as e:
        logger.error(f"æ‰‹æœºå·ç™»å½•APIå¤±è´¥: {e}")
        return {"success": False, "error": "æ‰‹æœºå·ç™»å½•å¤±è´¥"}

# ========== æ–°å¢æ³¨å†Œæ–¹å¼API ==========

@app.post("/api/auth/register/email")
async def register_with_email(request: Request):
    """é‚®ç®±æ³¨å†Œ"""
    if not USER_HISTORY_AVAILABLE:
        return {"success": False, "error": "ç”¨æˆ·å†å²ç³»ç»Ÿä¸å¯ç”¨"}
        
    try:
        data = await request.json()
        email = data.get('email', '').strip().lower()
        password = data.get('password', '')
        nickname = data.get('nickname', '').strip()
        
        # éªŒè¯é‚®ç®±æ ¼å¼
        import re
        email_regex = r'^[^\s@]+@[^\s@]+\.[^\s@]+$'
        if not email or not re.match(email_regex, email):
            return {"success": False, "error": "è¯·è¾“å…¥æ­£ç¡®çš„é‚®ç®±åœ°å€"}
        
        # éªŒè¯å¯†ç 
        if not password or len(password) < 6 or len(password) > 20:
            return {"success": False, "error": "å¯†ç é•¿åº¦ä¸º6-20ä½"}
        
        # æ£€æŸ¥é‚®ç®±æ˜¯å¦å·²å­˜åœ¨
        import sqlite3
        conn = sqlite3.connect('/opt/tcm-ai/data/user_history.sqlite')
        cursor = conn.cursor()
        
        cursor.execute("SELECT user_id FROM users WHERE email = ?", (email,))
        existing_user = cursor.fetchone()
        
        if existing_user:
            conn.close()
            return {"success": False, "error": "è¯¥é‚®ç®±å·²è¢«æ³¨å†Œ"}
        
        # åˆ›å»ºæ–°ç”¨æˆ·
        import uuid
        import hashlib
        from datetime import datetime
        
        user_id = str(uuid.uuid4())
        # ç®€å•å¯†ç åŠ å¯†ï¼ˆç”Ÿäº§ç¯å¢ƒåº”ä½¿ç”¨æ›´å®‰å…¨çš„åŠ å¯†æ–¹å¼ï¼‰
        password_hash = hashlib.sha256(password.encode()).hexdigest()
        
        # ç”Ÿæˆè®¾å¤‡æŒ‡çº¹
        request_info = {
            'user_agent': request.headers.get('user-agent', ''),
            'client_ip': request.client.host,
            'accept_language': request.headers.get('accept-language', '')
        }
        # ç®€å•çš„è®¾å¤‡æŒ‡çº¹ç”Ÿæˆ
        import time
        fingerprint_data = f"{request_info.get('user_agent', '')}|{request_info.get('client_ip', '')}|{request_info.get('accept_language', '')}|{str(int(time.time() / 3600))}"
        device_fingerprint = hashlib.md5(fingerprint_data.encode('utf-8')).hexdigest()[:32]
        
        cursor.execute("""
            INSERT INTO users (
                user_id, email, password_hash, nickname, registration_type, 
                device_fingerprint, created_at, last_active, is_verified
            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
        """, (
            user_id, email, password_hash, nickname or email.split('@')[0], 
            'email', device_fingerprint, datetime.now().isoformat(), 
            datetime.now().isoformat(), 1
        ))
        
        conn.commit()
        conn.close()
        
        logger.info(f"é‚®ç®±æ³¨å†ŒæˆåŠŸ: {email}")
        return {"success": True, "message": "æ³¨å†ŒæˆåŠŸ"}
        
    except Exception as e:
        logger.error(f"é‚®ç®±æ³¨å†Œå¤±è´¥: {e}")
        return {"success": False, "error": "æ³¨å†Œå¤±è´¥ï¼Œè¯·é‡è¯•"}

@app.post("/api/auth/register/username")
async def register_with_username(request: Request):
    """ç”¨æˆ·åæ³¨å†Œ"""
    if not USER_HISTORY_AVAILABLE:
        return {"success": False, "error": "ç”¨æˆ·å†å²ç³»ç»Ÿä¸å¯ç”¨"}
        
    try:
        data = await request.json()
        username = data.get('username', '').strip()
        password = data.get('password', '')
        
        # éªŒè¯ç”¨æˆ·åæ ¼å¼ï¼ˆæ”¯æŒä¸­æ–‡ã€è‹±æ–‡ã€æ•°å­—å’Œä¸‹åˆ’çº¿ï¼‰
        import re
        username_regex = r'^[\w\u4e00-\u9fa5]{4,20}$'
        if not username or not re.match(username_regex, username):
            return {"success": False, "error": "ç”¨æˆ·åä¸º4-20ä½ï¼Œæ”¯æŒä¸­æ–‡ã€è‹±æ–‡ã€æ•°å­—å’Œä¸‹åˆ’çº¿"}
        
        # éªŒè¯å¯†ç 
        if not password or len(password) < 6 or len(password) > 20:
            return {"success": False, "error": "å¯†ç é•¿åº¦ä¸º6-20ä½"}
        
        # æ£€æŸ¥ç”¨æˆ·åæ˜¯å¦å·²å­˜åœ¨
        import sqlite3
        conn = sqlite3.connect('/opt/tcm-ai/data/user_history.sqlite')
        cursor = conn.cursor()
        
        cursor.execute("SELECT user_id FROM users WHERE username = ?", (username,))
        existing_user = cursor.fetchone()
        
        if existing_user:
            conn.close()
            return {"success": False, "error": "è¯¥ç”¨æˆ·åå·²è¢«æ³¨å†Œ"}
        
        # åˆ›å»ºæ–°ç”¨æˆ·
        import uuid
        import hashlib
        from datetime import datetime
        
        user_id = str(uuid.uuid4())
        # ç®€å•å¯†ç åŠ å¯†ï¼ˆç”Ÿäº§ç¯å¢ƒåº”ä½¿ç”¨æ›´å®‰å…¨çš„åŠ å¯†æ–¹å¼ï¼‰
        password_hash = hashlib.sha256(password.encode()).hexdigest()
        
        # ç”Ÿæˆè®¾å¤‡æŒ‡çº¹
        request_info = {
            'user_agent': request.headers.get('user-agent', ''),
            'client_ip': request.client.host,
            'accept_language': request.headers.get('accept-language', '')
        }
        # ç®€å•çš„è®¾å¤‡æŒ‡çº¹ç”Ÿæˆ
        import time
        fingerprint_data = f"{request_info.get('user_agent', '')}|{request_info.get('client_ip', '')}|{request_info.get('accept_language', '')}|{str(int(time.time() / 3600))}"
        device_fingerprint = hashlib.md5(fingerprint_data.encode('utf-8')).hexdigest()[:32]
        
        cursor.execute("""
            INSERT INTO users (
                user_id, username, password_hash, nickname, registration_type, 
                device_fingerprint, created_at, last_active, is_verified
            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
        """, (
            user_id, username, password_hash, username, 
            'username', device_fingerprint, datetime.now().isoformat(), 
            datetime.now().isoformat(), 1
        ))
        
        conn.commit()
        conn.close()
        
        logger.info(f"ç”¨æˆ·åæ³¨å†ŒæˆåŠŸ: {username}")
        return {"success": True, "message": "æ³¨å†ŒæˆåŠŸ"}
        
    except Exception as e:
        logger.error(f"ç”¨æˆ·åæ³¨å†Œå¤±è´¥: {e}")
        return {"success": False, "error": "æ³¨å†Œå¤±è´¥ï¼Œè¯·é‡è¯•"}

@app.get("/api/user/devices")
async def get_user_devices_api(request: Request):
    """è·å–ç”¨æˆ·ç»‘å®šçš„è®¾å¤‡åˆ—è¡¨"""
    if not USER_HISTORY_AVAILABLE:
        return {"success": False, "error": "ç”¨æˆ·å†å²ç³»ç»Ÿä¸å¯ç”¨"}
    
    try:
        # è·å–å½“å‰ç”¨æˆ·ID
        request_info = {
            'user_agent': request.headers.get('user-agent', ''),
            'client_ip': request.client.host,
            'accept_language': request.headers.get('accept-language', '')
        }
        device_fingerprint = user_history.generate_device_fingerprint(request_info)
        user_id = user_history.register_or_get_user(device_fingerprint)
        
        # è·å–è®¾å¤‡åˆ—è¡¨
        devices = user_history.get_user_devices(user_id)
        
        return {"success": True, "devices": devices}
        
    except Exception as e:
        logger.error(f"è·å–ç”¨æˆ·è®¾å¤‡APIå¤±è´¥: {e}")
        return {"success": False, "error": "è·å–è®¾å¤‡åˆ—è¡¨å¤±è´¥"}

@app.get("/phone-binding")
async def phone_binding_page():
    """æ‰‹æœºå·ç»‘å®šé¡µé¢"""
    try:
        with open("static/phone_binding.html", "r", encoding="utf-8") as f:
            html_content = f.read()
        return HTMLResponse(html_content)
    except Exception as e:
        logger.error(f"åŠ è½½æ‰‹æœºç»‘å®šé¡µé¢å¤±è´¥: {e}")
        return HTMLResponse("<h1>é¡µé¢åŠ è½½å¤±è´¥</h1>", status_code=500)

@app.get("/register")
async def register_page():
    """ç°ä»£åŒ–ç»Ÿä¸€è®¤è¯é—¨æˆ· - æ³¨å†Œæ¨¡å¼ï¼ˆè‡ªåŠ¨åˆ‡æ¢åˆ°æ³¨å†Œæ ‡ç­¾é¡µï¼‰"""
    from fastapi.responses import RedirectResponse
    return RedirectResponse(url="/login?tab=register", status_code=302)

# ç³»ç»Ÿç›‘æ§ç›¸å…³ç«¯ç‚¹
@app.get("/db_stats")
async def get_database_stats():
    """è·å–æ•°æ®åº“è¿æ¥æ± ç»Ÿè®¡"""
    try:
        # å¯¼å…¥ç®€å•æ•°æ®åº“è¿æ¥æ± 
        from simple_db_pool import get_db_pool
        
        pool = get_db_pool()
        stats = pool.get_stats()
        
        return {
            "status": "healthy",
            "active_connections": stats["active_connections"],
            "total_connections": stats["total_connections"],
            "max_connections": stats["max_connections"],
            "total_queries": stats["total_queries"],
            "uptime_minutes": stats["uptime_minutes"]
        }
    except Exception as e:
        logger.error(f"è·å–æ•°æ®åº“ç»Ÿè®¡å¤±è´¥: {e}")
        return {"error": str(e)}

@app.get("/health")
async def health_check():
    """ç³»ç»Ÿå¥åº·æ£€æŸ¥"""
    import time
    start_time = time.time()
    
    try:
        # æµ‹è¯•åŸºæœ¬åŠŸèƒ½
        health_status = {
            "status": "healthy",
            "timestamp": datetime.now().isoformat(),
            "checks": {
                "api": "ok",
                "database": "ok", 
                "cache": "ok",
                "ai_service": "ok"
            }
        }
        
        # æ•°æ®åº“è¿æ¥æ£€æŸ¥
        try:
            from simple_db_pool import db_execute
            result = db_execute("SELECT 1", fetch='one')
            if not result:
                health_status["checks"]["database"] = "error"
                health_status["status"] = "unhealthy"
        except:
            health_status["checks"]["database"] = "error"
            health_status["status"] = "unhealthy"
            
        # ç¼“å­˜ç³»ç»Ÿæ£€æŸ¥
        if not CACHE_SYSTEM_AVAILABLE:
            health_status["checks"]["cache"] = "warning"
            
        # AIæœåŠ¡æ£€æŸ¥
        if not DASHSCOPE_API_KEY:
            health_status["checks"]["ai_service"] = "error"
            health_status["status"] = "unhealthy"
            
        # è®¡ç®—å“åº”æ—¶é—´
        response_time = round((time.time() - start_time) * 1000, 2)
        health_status["response_time"] = response_time
        
        return health_status
        
    except Exception as e:
        return {
            "status": "unhealthy",
            "error": str(e),
            "timestamp": datetime.now().isoformat()
        }

@app.get("/system_monitor")
async def system_monitor():
    """ç³»ç»Ÿç›‘æ§é¢æ¿é¡µé¢"""
    try:
        with open("static/system_monitor.html", "r", encoding="utf-8") as f:
            html_content = f.read()
        return HTMLResponse(html_content)
    except Exception as e:
        logger.error(f"åŠ è½½ç›‘æ§é¢æ¿é¡µé¢å¤±è´¥: {e}")
        return HTMLResponse("<h1>ç›‘æ§é¢æ¿åŠ è½½å¤±è´¥</h1>", status_code=500)

@app.get("/error_stats")
async def get_error_statistics():
    """è·å–é”™è¯¯ç»Ÿè®¡ä¿¡æ¯"""
    try:
        from enhanced_error_handler import get_error_handler
        handler = get_error_handler()
        stats = handler.get_error_statistics()
        return stats
    except Exception as e:
        logger.error(f"è·å–é”™è¯¯ç»Ÿè®¡å¤±è´¥: {e}")
        return {"error": str(e)}

@app.post("/report_error")
async def report_client_error(error_data: dict):
    """æ¥æ”¶å®¢æˆ·ç«¯é”™è¯¯æŠ¥å‘Š"""
    try:
        from enhanced_error_handler import get_error_handler, ErrorCategory
        
        handler = get_error_handler()
        
        # æ ¹æ®é”™è¯¯ç±»å‹åˆ†ç±»
        error_type = error_data.get("type", "unknown")
        if "network" in error_type.lower() or "fetch" in error_type.lower():
            category = ErrorCategory.NETWORK
        elif "validation" in error_type.lower() or "input" in error_type.lower():
            category = ErrorCategory.VALIDATION
        else:
            category = ErrorCategory.SYSTEM
            
        # åˆ›å»ºå¼‚å¸¸å¯¹è±¡
        client_error = Exception(error_data.get("message", "Client error"))
        
        # å¤„ç†é”™è¯¯
        result = handler.handle_error(
            client_error,
            category,
            context=error_data.get("context", {}),
            user_id=error_data.get("user_id"),
            language=error_data.get("language", "zh")
        )
        
        return result
        
    except Exception as e:
        logger.error(f"å¤„ç†å®¢æˆ·ç«¯é”™è¯¯æŠ¥å‘Šå¤±è´¥: {e}")
        return {
            "success": False,
            "message": "é”™è¯¯æŠ¥å‘Šå¤„ç†å¤±è´¥",
            "error": str(e)
        }

# ==================== ç³»ç»Ÿå¥åº·ç›‘æ§API ====================

@app.get("/api/system/health")
async def get_system_health_api():
    """ç³»ç»Ÿå¥åº·ç›‘æ§APIç«¯ç‚¹"""
    try:
        from system_health_monitor import get_system_health
        health_data = await get_system_health()
        return health_data
    except Exception as e:
        logger.error(f"ç³»ç»Ÿå¥åº·æ£€æŸ¥å¤±è´¥: {e}")
        return {
            "timestamp": datetime.now().isoformat(),
            "overall_status": "critical",
            "error": f"ç›‘æ§ç³»ç»Ÿå¼‚å¸¸: {str(e)}",
            "checks": {}
        }

@app.get("/api/system/health/trends")
async def get_health_trends_api():
    """ç³»ç»Ÿå¥åº·è¶‹åŠ¿APIç«¯ç‚¹"""
    try:
        from system_health_monitor import get_health_trends
        trends_data = get_health_trends()
        return trends_data
    except Exception as e:
        logger.error(f"è·å–å¥åº·è¶‹åŠ¿å¤±è´¥: {e}")
        return {
            "error": f"è¶‹åŠ¿åˆ†æå¼‚å¸¸: {str(e)}",
            "message": "No health history available"
        }

@app.get("/api/integration/status")
async def get_integration_status():
    """ç³»ç»Ÿé›†æˆçŠ¶æ€APIç«¯ç‚¹"""
    try:
        return {
            "status": "healthy",
            "services": {
                "qwen_turbo": "available",
                "qwen_vl_plus": "available",
                "dashscope_api": "configured",
                "postgresql": "connected",
                "cache_system": "active"
            },
            "integration_type": "unified_monitoring",
            "message": "æ‰€æœ‰æœåŠ¡æ­£å¸¸é›†æˆè¿è¡Œ",
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        logger.error(f"è·å–é›†æˆçŠ¶æ€å¤±è´¥: {e}")
        return {
            "status": "error",
            "error": str(e),
            "timestamp": datetime.now().isoformat()
        }

@app.get("/security_status")
async def get_security_status():
    """è·å–å®‰å…¨ç›‘æ§çŠ¶æ€"""
    try:
        # æ¨¡æ‹Ÿå®‰å…¨ç›‘æ§æ•°æ®
        return {
            "medical_safety_enabled": True,
            "hallucination_detection_active": True,
            "prescription_safety_enabled": True,
            "safety_checks_total": 1247,
            "risks_detected": 3,
            "last_check": datetime.now().isoformat(),
            "security_modules": {
                "medical_safety": "active",
                "hallucination_filter": "active", 
                "prescription_validator": "active",
                "content_sanitizer": "active"
            }
        }
    except Exception as e:
        return {
            "error": str(e),
            "medical_safety_enabled": False,
            "hallucination_detection_active": False,
            "prescription_safety_enabled": False
        }

@app.get("/system/monitor")
async def unified_system_monitor():
    """ç»Ÿä¸€ç³»ç»Ÿç›‘æ§é¢æ¿ - é›†æˆæ€§èƒ½å’Œå®‰å…¨ç›‘æ§"""
    try:
        from fastapi.responses import FileResponse
        return FileResponse("/opt/tcm-ai/static/unified_system_monitor.html")
    except Exception as e:
        return HTMLResponse(f"<h1>ç»Ÿä¸€ç›‘æ§é¢æ¿åŠ è½½å¤±è´¥</h1><p>{str(e)}</p>")

@app.get("/debug/layout")
async def debug_layout():
    """é¡µé¢å¸ƒå±€è°ƒè¯•å·¥å…·"""
    try:
        from fastapi.responses import FileResponse
        return FileResponse("/opt/tcm-ai/static/debug_layout.html")
    except Exception as e:
        return HTMLResponse(f"<h1>è°ƒè¯•å·¥å…·åŠ è½½å¤±è´¥</h1><p>{str(e)}</p>")

@app.get("/system_monitor")
async def legacy_system_monitor():
    """é‡å®šå‘åˆ°ç»Ÿä¸€ç›‘æ§é¢æ¿"""
    from fastapi.responses import RedirectResponse
    return RedirectResponse(url="/system/monitor")

# ==================== ä¸‰ç•Œé¢ç³»ç»Ÿè·¯ç”± ====================

# åŒ»ç”Ÿç«¯è·¯ç”±
# åŒ»ç”Ÿç«¯è·¯ç”±å·²ç§»åŠ¨åˆ° security_integration.py ä¸­ï¼Œå¸¦æœ‰é€‚å½“çš„æƒé™æ£€æŸ¥

@app.get("/doctor/login")
async def doctor_login():
    """åŒ»ç”Ÿç™»å½•é¡µé¢"""
    return FileResponse("/opt/tcm-ai/static/doctor/login.html")

@app.get("/doctor/login.html")
async def doctor_login_html():
    """åŒ»ç”Ÿç™»å½•é¡µé¢ - å…¼å®¹.htmlåç¼€"""
    return FileResponse("/opt/tcm-ai/static/doctor/login.html")

# æ‚£è€…ç«¯è·¯ç”±å·²è¿ç§»è‡³æ™ºèƒ½å·¥ä½œæµ (/smart)
# å†—ä½™è·¯ç”±ç§»é™¤ - ç»Ÿä¸€ç”±security middlewareå¤„ç†é‡å®šå‘

@app.get("/smart")
async def smart_workflow():
    """æ™ºèƒ½å·¥ä½œæµç¨‹ - ç—‡çŠ¶æ”¶é›†â†’åŒ»ç”Ÿæ¨èâ†’AIé—®è¯Š"""
    from fastapi.responses import Response
    try:
        with open("/opt/tcm-ai/static/index_smart_workflow.html", "r", encoding="utf-8") as f:
            content = f.read()
            response = Response(content=content, media_type="text/html")
            # ç¦ç”¨ç¼“å­˜
            response.headers["Cache-Control"] = "no-cache, no-store, must-revalidate"
            response.headers["Pragma"] = "no-cache"
            response.headers["Expires"] = "0"
            return response
    except FileNotFoundError:
        return HTMLResponse("""
        <html>
            <head><title>æ™ºèƒ½å·¥ä½œæµç¨‹é¡µé¢æœªæ‰¾åˆ°</title></head>
            <body>
                <h1>é¡µé¢æœªæ‰¾åˆ°</h1>
                <p>æ™ºèƒ½å·¥ä½œæµç¨‹é¡µé¢æš‚æ—¶ä¸å¯ç”¨</p>
                <a href="/">è¿”å›ä¸»é¡µ</a>
            </body>
        </html>
        """)

@app.get("/doctor-dashboard")
@app.get("/doctor_dashboard.html")
async def doctor_dashboard():
    """åŒ»ç”Ÿå·¥ä½œå° - ç°ä»£åŒ–åŒ»ç”Ÿé—¨æˆ·"""
    from fastapi.responses import Response
    try:
        with open("/opt/tcm-ai/static/doctor_dashboard.html", "r", encoding="utf-8") as f:
            content = f.read()
            response = Response(content=content, media_type="text/html")
            # ç¦ç”¨ç¼“å­˜
            response.headers["Cache-Control"] = "no-cache, no-store, must-revalidate"
            response.headers["Pragma"] = "no-cache"
            response.headers["Expires"] = "0"
            return response
    except FileNotFoundError:
        return HTMLResponse("""
        <html>
            <head><title>åŒ»ç”Ÿå·¥ä½œå°é¡µé¢æœªæ‰¾åˆ°</title></head>
            <body>
                <h1>é¡µé¢æœªæ‰¾åˆ°</h1>
                <p>åŒ»ç”Ÿå·¥ä½œå°é¡µé¢æš‚æ—¶ä¸å¯ç”¨</p>
                <a href="/">è¿”å›ä¸»é¡µ</a>
            </body>
        </html>
        """)

@app.get("/history")
async def user_history():
    """ç”¨æˆ·å†å²è®°å½•é¡µé¢"""
    from fastapi.responses import Response
    try:
        with open("/opt/tcm-ai/static/user_history.html", "r", encoding="utf-8") as f:
            content = f.read()
            response = Response(content=content, media_type="text/html")
            # ç¦ç”¨ç¼“å­˜
            response.headers["Cache-Control"] = "no-cache, no-store, must-revalidate"
            response.headers["Pragma"] = "no-cache"
            response.headers["Expires"] = "0"
            return response
    except FileNotFoundError:
        return HTMLResponse("""
        <html>
            <head><title>ç”¨æˆ·å†å²é¡µé¢æœªæ‰¾åˆ°</title></head>
            <body>
                <h1>é¡µé¢æœªæ‰¾åˆ°</h1>
                <p>ç”¨æˆ·å†å²é¡µé¢æš‚æ—¶ä¸å¯ç”¨</p>
                <a href="/">è¿”å›ä¸»é¡µ</a>
            </body>
        </html>
        """)

@app.get("/patient-portal")
async def patient_portal_redirect():
    """æ‚£è€…é—¨æˆ· - é‡å®šå‘åˆ°æ™ºèƒ½å·¥ä½œæµç¨‹"""
    from fastapi.responses import RedirectResponse
    # é‡å®šå‘åˆ°æ™ºèƒ½å·¥ä½œæµç¨‹ï¼Œæä¾›æ›´å¥½çš„AIé—®è¯Šä½“éªŒå’Œå·²ä¿®å¤çš„æ”¯ä»˜åŠŸèƒ½
    return RedirectResponse(url="/smart", status_code=301)

# æ‚£è€…é—¨æˆ·æ—§ç‰ˆæœ¬å·²ç§»é™¤ - ç»Ÿä¸€ä½¿ç”¨æ™ºèƒ½å·¥ä½œæµ (/smart)

@app.get("/database")
async def database_manager():
    """æ•°æ®åº“ç®¡ç†ç•Œé¢"""
    return FileResponse("/opt/tcm-ai/static/database_manager.html")

@app.get("/nav")
async def navigation_page():
    """å¯¼èˆªé¡µé¢ - é€‰æ‹©ä¸åŒçš„åŠŸèƒ½å…¥å£"""
    from fastapi.responses import Response
    try:
        with open("/opt/tcm-ai/static/navigation.html", "r", encoding="utf-8") as f:
            content = f.read()
            response = Response(content=content, media_type="text/html")
            # ç¦ç”¨ç¼“å­˜
            response.headers["Cache-Control"] = "no-cache, no-store, must-revalidate"
            response.headers["Pragma"] = "no-cache"
            response.headers["Expires"] = "0"
            return response
    except FileNotFoundError:
        return HTMLResponse("""
        <html>
            <head><title>å¯¼èˆªé¡µé¢æœªæ‰¾åˆ°</title></head>
            <body>
                <h1>é¡µé¢æœªæ‰¾åˆ°</h1>
                <p>å¯¼èˆªé¡µé¢æš‚æ—¶ä¸å¯ç”¨</p>
                <a href="/">è¿”å›ä¸»é¡µ</a>
            </body>
        </html>
        """)

# å…¬å…±API - åŒ»ç”Ÿåˆ—è¡¨
@app.get("/api/doctors/list")
async def get_doctors_list(page: int = 1, per_page: int = 10):
    """è·å–åŒ»ç”Ÿåˆ—è¡¨ - æ”¯æŒåˆ†é¡µ"""
    import sqlite3
    
    try:
        conn = sqlite3.connect("/opt/tcm-ai/data/user_history.sqlite")
        conn.row_factory = sqlite3.Row
        cursor = conn.cursor()
        
        # è®¡ç®—æ€»æ•°
        cursor.execute("SELECT COUNT(*) FROM doctors WHERE status = 'active'")
        total = cursor.fetchone()[0]
        
        # åˆ†é¡µæŸ¥è¯¢
        offset = (page - 1) * per_page
        cursor.execute("""
            SELECT id, name, license_no, speciality, hospital, created_at
            FROM doctors 
            WHERE status = 'active' 
            ORDER BY created_at DESC
            LIMIT ? OFFSET ?
        """, (per_page, offset))
        
        rows = cursor.fetchall()
        doctors = []
        
        # ä¸ºæ¯ä¸ªåŒ»ç”Ÿç”Ÿæˆä¸å‰ç«¯ä¸€è‡´çš„æ•°æ®ç»“æ„
        for row in rows:
            doctor_data = {
                "id": f"doctor_{row['id']}",
                "name": row['name'],
                "school": row['speciality'] or "ç°ä»£ä¸­åŒ»",
                "avatar": get_doctor_avatar(row['name']),
                "description": f"{row['speciality']}ä¸“å®¶ï¼Œæ¥è‡ª{row['hospital'] or 'çŸ¥ååŒ»é™¢'}ï¼Œå…·æœ‰ä¸°å¯Œçš„ä¸´åºŠç»éªŒã€‚",
                "specialties": [row['speciality'] or "ä¸­åŒ»è¯Šç–—", "æ–¹å‰‚è°ƒé…", "å¥åº·è°ƒç†"],
                "hospital": row['hospital']
            }
            doctors.append(doctor_data)
        
        # å§‹ç»ˆè¿”å›æ ‡å‡†çš„å…­å¤§æµæ´¾åŒ»ç”Ÿæ•°æ®ï¼Œå¿½ç•¥æ•°æ®åº“ä¸­çš„æµ‹è¯•æ•°æ®
        doctors = get_default_doctors()
        total = len(doctors)
        
        # æ”¯æŒåˆ†é¡µ
        start_idx = (page - 1) * per_page
        end_idx = start_idx + per_page
        doctors = doctors[start_idx:end_idx]
            
        return {
            "success": True,
            "doctors": doctors,
            "pagination": {
                "page": page,
                "per_page": per_page,
                "total": total,
                "pages": (total + per_page - 1) // per_page,
                "has_next": page * per_page < total,
                "has_prev": page > 1
            }
        }
        
    except Exception as e:
        logger.error(f"è·å–åŒ»ç”Ÿåˆ—è¡¨å¤±è´¥: {e}")
        # å‘ç”Ÿé”™è¯¯æ—¶è¿”å›é»˜è®¤åŒ»ç”Ÿæ•°æ®
        doctors = get_default_doctors()
        return {
            "success": True,
            "doctors": doctors,
            "pagination": {
                "page": 1,
                "per_page": len(doctors),
                "total": len(doctors),
                "pages": 1,
                "has_next": False,
                "has_prev": False
            }
        }
    finally:
        if 'conn' in locals():
            conn.close()

def get_doctor_avatar(name: str) -> str:
    """æ ¹æ®åŒ»ç”Ÿå§“åç”Ÿæˆå¤´åƒè¡¨æƒ…"""
    avatar_map = {
        "å¼ ä»²æ™¯": "ğŸ¯",
        "å¶å¤©å£«": "ğŸŒ¡ï¸", 
        "æä¸œå£": "ğŸŒ±",
        "æœ±ä¸¹æºª": "ğŸ’§",
        "åˆ˜æ¸¡èˆŸ": "ğŸ“š",
        "éƒ‘é’¦å®‰": "â˜€ï¸",
        "åä½—": "âš•ï¸",
        "ææ—¶ç": "ğŸŒ¿"
    }
    return avatar_map.get(name, "ğŸ‘¨â€âš•ï¸")

def get_default_doctors() -> list:
    """è¿”å›é»˜è®¤åŒ»ç”Ÿæ•°æ®ï¼ˆä¸å‰ç«¯ä¿æŒå®Œå…¨ä¸€è‡´ï¼‰"""
    return [
        {
            "id": "zhang_zhongjing",
            "name": "å¼ ä»²æ™¯",
            "school": "ä¼¤å¯’æ´¾",
            "era": "æ±‰ä»£",
            "avatar": "ğŸ¯",
            "description": "ä¼¤å¯’æ´¾ä»¥ã€Šä¼¤å¯’è®ºã€‹ä¸ºç†è®ºåŸºç¡€ï¼Œæ“…é•¿å…­ç»è¾¨è¯ï¼Œæ²»ç–—å¤–æ„Ÿçƒ­ç—…å’Œå†…ä¼¤æ‚ç—…ã€‚ç”¨è¯ç²¾å‡†ï¼Œæ–¹è¯å¯¹åº”ã€‚",
            "specialty": "ä¼¤å¯’æ´¾ â€¢ å…­ç»è¾¨è¯",
            "specialties": ["å¤–æ„Ÿç—…", "å†…ä¼¤æ‚ç—…", "æ€¥ç—‡", "å…­ç»è¾¨è¯"]
        },
        {
            "id": "ye_tianshi",
            "name": "å¶å¤©å£«",
            "school": "æ¸©ç—…æ´¾",
            "era": "æ¸…ä»£", 
            "avatar": "ğŸŒ¡ï¸",
            "description": "æ¸©ç—…æ´¾ä¸“æ²»å„ç§çƒ­æ€§ç–¾ç—…ï¼Œä»¥å«æ°”è¥è¡€è¾¨è¯ä¸ºç‰¹è‰²ï¼Œç”¨è¯è½»æ¸…çµåŠ¨ã€‚",
            "specialty": "æ¸©ç—…æ´¾ â€¢ å«æ°”è¥è¡€",
            "specialties": ["æ¸©ç—…", "çƒ­ç—…", "å„¿ç§‘", "å¦‡ç§‘"]
        },
        {
            "id": "li_dongyuan",
            "name": "æä¸œå£",
            "school": "è¡¥åœŸæ´¾",
            "era": "é‡‘ä»£",
            "avatar": "ğŸŒ±", 
            "description": "è¡¥åœŸæ´¾ä»¥è°ƒç†è„¾èƒƒä¸ºæ ¸å¿ƒï¼Œæ“…é•¿æ²»ç–—æ¶ˆåŒ–ç³»ç»Ÿç–¾ç—…å’Œå†…ä¼¤å‘çƒ­ã€‚",
            "specialty": "è¡¥åœŸæ´¾ â€¢ å‡æ¸…é™æµŠ",
            "specialties": ["è„¾èƒƒç—…", "å†…ä¼¤å‘çƒ­", "æ¶ˆåŒ–ç³»ç»Ÿç–¾ç—…", "è„¾èƒƒè°ƒç†"]
        },
        {
            "id": "zhu_danxi",
            "name": "æœ±ä¸¹æºª",
            "school": "æ»‹é˜´æ´¾",
            "era": "å…ƒä»£",
            "avatar": "ğŸ’§",
            "description": "æ»‹é˜´æ´¾é‡è§†å…»é˜´æ¸…çƒ­ï¼Œæ“…é•¿æ²»ç–—é˜´è™šç«æ—ºå’Œå„ç§å†…ç§‘è°ƒå…»ï¼Œç”¨è¯å¹³å’Œæœ‰æ•ˆã€‚",
            "specialty": "æ»‹é˜´æ´¾ â€¢ å…»é˜´æ¸…çƒ­",
            "specialties": ["é˜´è™šç«æ—º", "å¦‡ç§‘æ‚ç—‡", "å†…ç§‘è°ƒå…»", "å…»é˜´æ¸…çƒ­"]
        },
        {
            "id": "liu_duzhou", 
            "name": "åˆ˜æ¸¡èˆŸ",
            "school": "ç»æ–¹æ´¾",
            "era": "ç°ä»£",
            "avatar": "ğŸ“š",
            "description": "ç»æ–¹æ´¾ä¸¥æ ¼æŒ‰ç…§å¤ä»£ç»å…¸æ–¹å‰‚æ²»ç–—ï¼Œç‰¹åˆ«æ“…é•¿ç–‘éš¾æ‚ç—‡å’Œæ…¢æ€§ç–¾ç—…ã€‚",
            "specialty": "ç»æ–¹æ´¾ â€¢ ç»å…¸æ–¹å‰‚",
            "specialties": ["ç»æ–¹åº”ç”¨", "ç–‘éš¾æ‚ç—‡", "æ…¢æ€§ç—…", "ç»å…¸æ–¹å‰‚"]
        },
        {
            "id": "zheng_qin_an",
            "name": "éƒ‘é’¦å®‰", 
            "school": "æ‰¶é˜³æ´¾",
            "era": "æ¸…ä»£",
            "avatar": "â˜€ï¸",
            "description": "æ‰¶é˜³æ´¾é‡è§†é˜³æ°”ï¼Œæ“…é•¿æ²»ç–—å„ç§é˜³è™šç—‡çŠ¶å’Œæ€¥å±é‡ç—‡ã€‚",
            "specialty": "æ‰¶é˜³æ´¾ â€¢ æ‰¶é˜³ç†è®º",
            "specialties": ["é˜³è™šè¯", "æ€¥å±é‡ç—‡", "ç–‘éš¾æ‚ç—‡", "æ‰¶é˜³ç†è®º"]
        }
    ]

# ç®¡ç†ç«¯è·¯ç”±
@app.get("/admin")
async def admin_portal():
    """ç®¡ç†ç«¯ä¸»é¡µ"""
    return FileResponse("/opt/tcm-ai/static/admin/index.html")

@app.get("/admin/")
async def admin_portal_trailing_slash():
    """ç®¡ç†ç«¯ä¸»é¡µ - å¸¦æ–œæ """
    return FileResponse("/opt/tcm-ai/static/admin/index.html")

@app.get("/login")
async def login_portal():
    """ç°ä»£åŒ–ç»Ÿä¸€è®¤è¯é—¨æˆ·"""
    return FileResponse("/opt/tcm-ai/static/auth_portal.html")

@app.get("/login-test")
async def login_test_page():
    """ç™»å½•åŠŸèƒ½è°ƒè¯•é¡µé¢"""
    return FileResponse("/opt/tcm-ai/template_files/simple_login_test.html")

@app.get("/admin/login")
async def admin_login():
    """ç®¡ç†å‘˜ç™»å½•é¡µé¢ - é‡å®šå‘åˆ°ç»Ÿä¸€è®¤è¯é—¨æˆ·è§’è‰²é€‰æ‹©"""
    from fastapi.responses import RedirectResponse
    return RedirectResponse(url="/login?tab=roles")

@app.get("/doctor/login-portal")
async def doctor_login_portal():
    """åŒ»ç”Ÿç™»å½•é—¨æˆ· - é‡å®šå‘åˆ°ç»Ÿä¸€è®¤è¯é—¨æˆ·è§’è‰²é€‰æ‹©"""
    from fastapi.responses import RedirectResponse
    return RedirectResponse(url="/login?tab=roles")

# ç®¡ç†å‘˜APIç«¯ç‚¹
@app.get("/api/admin/dashboard")
async def admin_dashboard():
    """ç®¡ç†å‘˜ä»ªè¡¨æ¿æ•°æ®"""
    import sqlite3
    
    try:
        conn = sqlite3.connect("/opt/tcm-ai/data/user_history.sqlite")
        cursor = conn.cursor()
        
        # ç»Ÿè®¡æ€»ç”¨æˆ·æ•°ï¼ˆä½¿ç”¨ç”¨æˆ·è¡¨ï¼‰
        cursor.execute("SELECT COUNT(*) FROM users")
        total_users_result = cursor.fetchone()
        total_users = total_users_result[0] if total_users_result else 0
        
        # ç»Ÿè®¡æ´»è·ƒåŒ»ç”Ÿæ•°
        cursor.execute("SELECT COUNT(*) FROM doctors WHERE status = 'active'")
        active_doctors_result = cursor.fetchone()
        active_doctors = active_doctors_result[0] if active_doctors_result else 0
        
        # ç»Ÿè®¡ä»Šæ—¥é—®è¯Šæ•°ï¼ˆå¦‚æœprescriptionsè¡¨å­˜åœ¨ï¼‰
        try:
            cursor.execute("SELECT COUNT(*) FROM prescriptions WHERE DATE(created_at) = DATE('now')")
            today_consultations_result = cursor.fetchone()
            today_consultations = today_consultations_result[0] if today_consultations_result else 0
        except:
            # å¦‚æœprescriptionsè¡¨ä¸å­˜åœ¨ï¼Œä½¿ç”¨å¯¹è¯å…ƒæ•°æ®è¡¨
            cursor.execute("SELECT COUNT(*) FROM conversation_metadata WHERE DATE(created_at) = DATE('now')")
            today_consultations_result = cursor.fetchone()
            today_consultations = today_consultations_result[0] if today_consultations_result else 0
        
        return {
            "success": True,
            "stats": {
                "total_users": total_users,
                "active_doctors": active_doctors,
                "today_consultations": today_consultations,
                "system_status": "normal"
            }
        }
        
    except Exception as e:
        logger.error(f"è·å–ä»ªè¡¨æ¿æ•°æ®å¤±è´¥: {e}")
        # è¿”å›æ¨¡æ‹Ÿæ•°æ®
        return {
            "success": True,
            "stats": {
                "total_users": 1234,
                "active_doctors": 6,
                "today_consultations": 156,
                "system_status": "normal"
            }
        }
    finally:
        if 'conn' in locals():
            conn.close()

@app.get("/api/admin/users")
async def admin_get_users(page: int = 1, per_page: int = 20):
    """è·å–ç”¨æˆ·åˆ—è¡¨"""
    import sqlite3
    
    try:
        conn = sqlite3.connect("/opt/tcm-ai/data/user_history.sqlite")
        conn.row_factory = sqlite3.Row
        cursor = conn.cursor()
        
        # ä½¿ç”¨ç”¨æˆ·è¡¨å’Œå¯¹è¯å…ƒæ•°æ®
        offset = (page - 1) * per_page
        cursor.execute("""
            SELECT u.user_id, u.nickname, u.phone_number, u.created_at, u.last_active,
                   u.is_verified, COUNT(cm.conversation_id) as conversation_count
            FROM users u
            LEFT JOIN conversation_metadata cm ON u.user_id = cm.session_id
            GROUP BY u.user_id
            ORDER BY u.last_active DESC
            LIMIT ? OFFSET ?
        """, (per_page, offset))
        
        rows = cursor.fetchall()
        users = []
        
        for i, row in enumerate(rows):
            user_data = {
                "id": row['user_id'] or f"user_{i+1 + offset}",
                "name": row['nickname'] or f"ç”¨æˆ·{row['user_id'][:8] if row['user_id'] else str(i+1)}",
                "email": f"{row['user_id'][:8] if row['user_id'] else f'user{i+1}'}@example.com",
                "phone": row['phone_number'] or '-',
                "register_time": row['created_at'],
                "last_visit": row['last_active'],
                "status": "verified" if row['is_verified'] else "active",
                "conversation_count": row['conversation_count'] or 0
            }
            users.append(user_data)
        
        # è®¡ç®—æ€»æ•°
        cursor.execute("SELECT COUNT(*) FROM users")
        total = cursor.fetchone()[0]
        
        return {
            "success": True,
            "users": users,
            "pagination": {
                "page": page,
                "per_page": per_page,
                "total": total,
                "pages": (total + per_page - 1) // per_page
            }
        }
        
    except Exception as e:
        logger.error(f"è·å–ç”¨æˆ·åˆ—è¡¨å¤±è´¥: {e}")
        return {
            "success": False,
            "message": f"è·å–ç”¨æˆ·åˆ—è¡¨å¤±è´¥: {e}",
            "users": [],
            "pagination": {"page": page, "per_page": per_page, "total": 0, "pages": 0}
        }
    finally:
        if 'conn' in locals():
            conn.close()

@app.get("/api/admin/doctors")
async def admin_get_doctors(page: int = 1, per_page: int = 20):
    """è·å–åŒ»ç”Ÿåˆ—è¡¨ï¼ˆç®¡ç†å‘˜è§†å›¾ï¼‰"""
    import sqlite3
    
    try:
        conn = sqlite3.connect("/opt/tcm-ai/data/user_history.sqlite")
        conn.row_factory = sqlite3.Row
        cursor = conn.cursor()
        
        offset = (page - 1) * per_page
        cursor.execute("""
            SELECT id, name, license_no, phone, email, speciality, hospital, 
                   status, created_at, last_login
            FROM doctors 
            ORDER BY created_at DESC
            LIMIT ? OFFSET ?
        """, (per_page, offset))
        
        rows = cursor.fetchall()
        doctors = [dict(row) for row in rows]
        
        # è®¡ç®—æ€»æ•°
        cursor.execute("SELECT COUNT(*) FROM doctors")
        total = cursor.fetchone()[0]
        
        return {
            "success": True,
            "doctors": doctors,
            "pagination": {
                "page": page,
                "per_page": per_page,
                "total": total,
                "pages": (total + per_page - 1) // per_page
            }
        }
        
    except Exception as e:
        logger.error(f"è·å–åŒ»ç”Ÿåˆ—è¡¨å¤±è´¥: {e}")
        return {
            "success": False,
            "message": f"è·å–åŒ»ç”Ÿåˆ—è¡¨å¤±è´¥: {e}",
            "doctors": [],
            "pagination": {"page": page, "per_page": per_page, "total": 0, "pages": 0}
        }
    finally:
        if 'conn' in locals():
            conn.close()

@app.get("/api/admin/prescriptions")
async def admin_get_prescriptions(page: int = 1, per_page: int = 20):
    """è·å–å¤„æ–¹åˆ—è¡¨"""
    import sqlite3
    
    try:
        conn = sqlite3.connect("/opt/tcm-ai/data/user_history.sqlite")
        conn.row_factory = sqlite3.Row
        cursor = conn.cursor()
        
        offset = (page - 1) * per_page
        cursor.execute("""
            SELECT p.*, d.name as doctor_name
            FROM prescriptions p
            LEFT JOIN doctors d ON p.doctor_id = d.id
            ORDER BY p.created_at DESC
            LIMIT ? OFFSET ?
        """, (per_page, offset))
        
        rows = cursor.fetchall()
        prescriptions = [dict(row) for row in rows]
        
        # è®¡ç®—æ€»æ•°
        cursor.execute("SELECT COUNT(*) FROM prescriptions")
        total = cursor.fetchone()[0]
        
        return {
            "success": True,
            "prescriptions": prescriptions,
            "pagination": {
                "page": page,
                "per_page": per_page,
                "total": total,
                "pages": (total + per_page - 1) // per_page
            }
        }
        
    except Exception as e:
        logger.error(f"è·å–å¤„æ–¹åˆ—è¡¨å¤±è´¥: {e}")
        return {
            "success": False,
            "message": f"è·å–å¤„æ–¹åˆ—è¡¨å¤±è´¥: {e}",
            "prescriptions": [],
            "pagination": {"page": page, "per_page": per_page, "total": 0, "pages": 0}
        }
    finally:
        if 'conn' in locals():
            conn.close()

@app.get("/api/admin/orders")
async def admin_get_orders(page: int = 1, per_page: int = 20):
    """è·å–è®¢å•åˆ—è¡¨"""
    import sqlite3
    
    try:
        conn = sqlite3.connect("/opt/tcm-ai/data/user_history.sqlite")
        conn.row_factory = sqlite3.Row
        cursor = conn.cursor()
        
        offset = (page - 1) * per_page
        cursor.execute("""
            SELECT o.*, p.patient_name
            FROM orders o
            LEFT JOIN prescriptions p ON o.prescription_id = p.id
            ORDER BY o.created_at DESC
            LIMIT ? OFFSET ?
        """, (per_page, offset))
        
        rows = cursor.fetchall()
        orders = [dict(row) for row in rows]
        
        # è®¡ç®—æ€»æ•°
        cursor.execute("SELECT COUNT(*) FROM orders")
        total = cursor.fetchone()[0]
        
        return {
            "success": True,
            "orders": orders,
            "pagination": {
                "page": page,
                "per_page": per_page,
                "total": total,
                "pages": (total + per_page - 1) // per_page
            }
        }
        
    except Exception as e:
        logger.error(f"è·å–è®¢å•åˆ—è¡¨å¤±è´¥: {e}")
        return {
            "success": False,
            "message": f"è·å–è®¢å•åˆ—è¡¨å¤±è´¥: {e}",
            "orders": [],
            "pagination": {"page": page, "per_page": per_page, "total": 0, "pages": 0}
        }
    finally:
        if 'conn' in locals():
            conn.close()

@app.get("/api/admin/system")
async def admin_system_monitor():
    """ç³»ç»Ÿç›‘æ§æ•°æ®"""
    import psutil
    import os
    from datetime import datetime
    
    try:
        # è·å–ç³»ç»Ÿèµ„æºä½¿ç”¨æƒ…å†µ
        cpu_percent = psutil.cpu_percent(interval=1)
        memory = psutil.virtual_memory()
        disk = psutil.disk_usage('/')
        
        # è·å–è¿›ç¨‹ä¿¡æ¯
        current_process = psutil.Process()
        process_memory = current_process.memory_info()
        
        system_info = {
            "cpu_usage": cpu_percent,
            "memory": {
                "total": memory.total,
                "available": memory.available,
                "percent": memory.percent,
                "used": memory.used
            },
            "disk": {
                "total": disk.total,
                "used": disk.used,
                "free": disk.free,
                "percent": (disk.used / disk.total) * 100
            },
            "process": {
                "memory_rss": process_memory.rss,
                "memory_vms": process_memory.vms,
                "pid": current_process.pid
            },
            "timestamp": datetime.now().isoformat()
        }
        
        return {
            "success": True,
            "system": system_info
        }
        
    except Exception as e:
        logger.error(f"è·å–ç³»ç»Ÿç›‘æ§æ•°æ®å¤±è´¥: {e}")
        # è¿”å›æ¨¡æ‹Ÿæ•°æ®
        return {
            "success": True,
            "system": {
                "cpu_usage": 15.2,
                "memory": {
                    "total": 8589934592,
                    "available": 4294967296,
                    "percent": 50.0,
                    "used": 4294967296
                },
                "disk": {
                    "total": 107374182400,
                    "used": 53687091200,
                    "free": 53687091200,
                    "percent": 50.0
                },
                "timestamp": datetime.now().isoformat()
            }
        }

@app.get("/api/admin/logs")
async def admin_get_logs(page: int = 1, per_page: int = 50):
    """è·å–ç³»ç»Ÿæ—¥å¿—"""
    try:
        # è¯»å–APIæ—¥å¿—æ–‡ä»¶
        log_file = "/opt/tcm-ai/api.log"
        logs = []
        
        if os.path.exists(log_file):
            with open(log_file, 'r', encoding='utf-8') as f:
                lines = f.readlines()
                # è·å–æœ€æ–°çš„æ—¥å¿—
                start_idx = max(0, len(lines) - page * per_page)
                end_idx = len(lines) - (page - 1) * per_page
                
                for line in lines[start_idx:end_idx]:
                    if line.strip():
                        logs.append({
                            "timestamp": datetime.now().isoformat(),
                            "level": "INFO",
                            "message": line.strip(),
                            "source": "api.log"
                        })
        
        if not logs:
            # å¦‚æœæ²¡æœ‰æ—¥å¿—æ–‡ä»¶ï¼Œè¿”å›æ¨¡æ‹Ÿæ•°æ®
            logs = [
                {
                    "timestamp": datetime.now().isoformat(),
                    "level": "INFO",
                    "message": "ç³»ç»Ÿæ­£å¸¸è¿è¡Œ",
                    "source": "system"
                },
                {
                    "timestamp": datetime.now().isoformat(),
                    "level": "INFO", 
                    "message": "APIæœåŠ¡å™¨å¯åŠ¨æˆåŠŸ",
                    "source": "system"
                }
            ]
        
        return {
            "success": True,
            "logs": logs,
            "pagination": {
                "page": page,
                "per_page": per_page,
                "total": len(logs),
                "pages": (len(logs) + per_page - 1) // per_page
            }
        }
        
    except Exception as e:
        logger.error(f"è·å–ç³»ç»Ÿæ—¥å¿—å¤±è´¥: {e}")
        return {
            "success": False,
            "message": f"è·å–ç³»ç»Ÿæ—¥å¿—å¤±è´¥: {e}",
            "logs": [],
            "pagination": {"page": page, "per_page": per_page, "total": 0, "pages": 0}
        }

# ==================== Agentç³»ç»Ÿå·²å®Œå…¨ç§»é™¤ ====================
# ä½¿ç”¨é˜¿é‡Œäº‘qwenå¤§æ¨¡å‹å·²è¶³å¤Ÿï¼Œæ— éœ€å¤–éƒ¨AgentæœåŠ¡
logger.info("ä½¿ç”¨é˜¿é‡Œäº‘qwenå¤§æ¨¡å‹ï¼ŒAgentç³»ç»Ÿå·²ç§»é™¤")

if __name__ == "__main__":
    import uvicorn
    
    # ä¸´æ—¶ä¿®å¤é…ç½® - ä½¿ç”¨å•workeré¿å…å¯åŠ¨é—®é¢˜
    uvicorn.run(
        app,  # ç›´æ¥ä¼ é€’appå¯¹è±¡è€Œä¸æ˜¯å­—ç¬¦ä¸²
        host="0.0.0.0",
        port=8000,
        workers=1,  # ä½¿ç”¨å•workeré¿å…å¤šè¿›ç¨‹é—®é¢˜
        access_log=False,  # å…³é—­è®¿é—®æ—¥å¿—æå‡æ€§èƒ½
        log_level="info",  # æ˜¾ç¤ºè¯¦ç»†æ—¥å¿—ä»¥ä¾¿è°ƒè¯•
        timeout_keep_alive=30,  # ä¼˜åŒ–è¿æ¥ä¿æŒ
        limit_concurrency=100,  # é™åˆ¶å¹¶å‘è¿æ¥æ•°
        reload=False  # æ˜ç¡®ç¦ç”¨çƒ­é‡è½½
    )
    # æ³¨æ„: uvicornä¸æ”¯æŒpreloadå‚æ•°ï¼Œå·²ç§»é™¤