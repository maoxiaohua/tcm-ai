#!/usr/bin/env python3
"""
å†³ç­–æ ‘æ™ºèƒ½åŒ¹é…æœåŠ¡ - AIè¯­ä¹‰åŒ¹é…ç‰ˆ
åœ¨æ‚£è€…é—®è¯Šæ—¶,è‡ªåŠ¨åŒ¹é…åŒ»ç”Ÿä¿å­˜çš„å†³ç­–æ ‘,å®ç°ä¸ªæ€§åŒ–è¯Šç–—

æ ¸å¿ƒç†å¿µï¼š
1. åŸºäºä¸­åŒ»è¾¨è¯è®ºæ²»ç†è®ºï¼Œä¸æ˜¯ç®€å•çš„æ–‡æœ¬åŒ¹é…
2. åˆ©ç”¨å†³ç­–æ ‘symptomèŠ‚ç‚¹ä¸­çš„å®Œæ•´è¾¨è¯æè¿°
3. ä½¿ç”¨AIè¿›è¡Œè¯­ä¹‰ç†è§£å’Œç›¸ä¼¼åº¦è®¡ç®—
4. è€ƒè™‘ä¸»ç—‡ã€ç—…æœºã€èˆŒè„‰ç­‰å¤šç»´åº¦åŒ¹é…
"""

import sqlite3
import json
import logging
from typing import Dict, List, Optional, Any, Tuple
from datetime import datetime
from dataclasses import dataclass
import asyncio
import os

# å¯¼å…¥dashscopeç”¨äºAIè¯­ä¹‰åˆ†æ
try:
    from dashscope import Generation
    DASHSCOPE_AVAILABLE = True
except ImportError:
    DASHSCOPE_AVAILABLE = False
    logging.warning("Dashscope not available, falling back to basic matching")

logger = logging.getLogger(__name__)

@dataclass
class DecisionTreeMatch:
    """å†³ç­–æ ‘åŒ¹é…ç»“æœ"""
    pattern_id: str
    doctor_id: str
    disease_name: str
    match_score: float
    thinking_process: str
    tree_structure: Dict[str, Any]
    clinical_patterns: str
    usage_count: int
    success_count: int
    confidence: float  # åŒ¹é…ç½®ä¿¡åº¦
    match_reason: str = ""  # ğŸ†• åŒ¹é…åŸå› ï¼ˆå¯è§£é‡Šæ€§ï¼‰
    syndrome_description: str = ""  # ğŸ†• æå–çš„è¯å€™æè¿°

class DecisionTreeMatcher:
    """å†³ç­–æ ‘æ™ºèƒ½åŒ¹é…æœåŠ¡ - AIè¯­ä¹‰åŒ¹é…ç‰ˆ"""

    def __init__(self, db_path: str = "/opt/tcm-ai/data/user_history.sqlite"):
        """åˆå§‹åŒ–å†³ç­–æ ‘åŒ¹é…æœåŠ¡"""
        self.db_path = db_path
        self.api_key = os.getenv('DASHSCOPE_API_KEY', '')

        logger.info(f"âœ… å†³ç­–æ ‘åŒ¹é…æœåŠ¡åˆå§‹åŒ–å®Œæˆ (AIè¯­ä¹‰åŒ¹é…ç‰ˆ): {db_path}")
        if not self.api_key:
            logger.warning("âš ï¸ DASHSCOPE_API_KEYæœªè®¾ç½®ï¼Œå°†ä½¿ç”¨åŸºç¡€åŒ¹é…é€»è¾‘")

    def _extract_symptom_node_from_tree(self, tree_structure: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """
        ä»å†³ç­–æ ‘ç»“æ„ä¸­æå–symptomç±»å‹çš„èŠ‚ç‚¹

        symptomèŠ‚ç‚¹åŒ…å«äº†å®Œæ•´çš„è¾¨è¯æè¿°ï¼Œæ˜¯åŒ¹é…çš„æ ¸å¿ƒä¾æ®
        ä¾‹å¦‚ï¼š"å¤–æ„Ÿé£çƒ­ï¼Œé‚ªè¢­è‚ºå«ã€‚æ‚£è€…å‘çƒ­æ¶é£ï¼Œæ±—å‡ºä¸ç•…ï¼Œå¤´ç—›é¼»å¡..."
        """
        try:
            nodes = tree_structure.get('nodes', [])
            for node in nodes:
                if node.get('type') == 'symptom':
                    return node

            # å¦‚æœæ²¡æœ‰symptomèŠ‚ç‚¹ï¼Œå°è¯•ä½¿ç”¨ç¬¬äºŒä¸ªèŠ‚ç‚¹ï¼ˆé€šå¸¸æ˜¯ç—‡çŠ¶æè¿°ï¼‰
            if len(nodes) >= 2:
                logger.info(f"æœªæ‰¾åˆ°symptomèŠ‚ç‚¹ï¼Œä½¿ç”¨ç¬¬äºŒä¸ªèŠ‚ç‚¹ä½œä¸ºç—‡çŠ¶æè¿°")
                return nodes[1]

            return None
        except Exception as e:
            logger.error(f"æå–symptomèŠ‚ç‚¹å¤±è´¥: {e}")
            return None

    async def _calculate_ai_semantic_similarity(
        self,
        patient_description: str,
        syndrome_description: str
    ) -> Tuple[float, str]:
        """
        ä½¿ç”¨AIè®¡ç®—æ‚£è€…æè¿°ä¸å†³ç­–æ ‘è¯å€™æè¿°çš„è¯­ä¹‰ç›¸ä¼¼åº¦

        è¿”å›ï¼š(ç›¸ä¼¼åº¦åˆ†æ•° 0-1, åŒ¹é…åŸå› è¯´æ˜)
        """
        if not DASHSCOPE_AVAILABLE or not self.api_key:
            # é™çº§ä¸ºåŸºç¡€æ–‡æœ¬åŒ¹é…
            return self._fallback_similarity(patient_description, syndrome_description)

        try:
            prompt = f"""ä½ æ˜¯ä¸€ä½èµ„æ·±ä¸­åŒ»ä¸“å®¶ï¼Œè¯·åˆ†ææ‚£è€…ç—‡çŠ¶ä¸æŸä¸ªä¸´åºŠè¯å€™çš„åŒ¹é…ç¨‹åº¦ã€‚

ã€æ‚£è€…æè¿°ã€‘
{patient_description}

ã€å†³ç­–æ ‘è¯å€™æè¿°ã€‘
{syndrome_description}

è¯·ä»ä»¥ä¸‹ç»´åº¦åˆ†æåŒ¹é…ç¨‹åº¦ï¼š
1. ä¸»è¦ç—‡çŠ¶åŒ¹é…åº¦ï¼ˆå‘çƒ­ã€ç–¼ç—›ç­‰æ ¸å¿ƒç—‡çŠ¶ï¼‰
2. ç—…æœºæ˜¯å¦ä¸€è‡´ï¼ˆå¦‚ï¼šé£çƒ­çŠ¯è¡¨ vs é£å¯’æŸè¡¨ï¼‰
3. èˆŒè„‰ç­‰ä½“å¾æ˜¯å¦ç›¸ç¬¦
4. ç—…ä½ã€ç—…æ€§æ˜¯å¦å»åˆ

è¯·ç›´æ¥è¿”å›JSONæ ¼å¼ï¼š
{{
    "match_score": 0.85,  // 0-1ä¹‹é—´çš„åŒ¹é…åˆ†æ•°
    "reason": "ä¸»ç—‡é«˜åº¦å»åˆï¼Œç—…æœºä¸€è‡´",  // ç®€çŸ­è¯´æ˜
    "main_symptom_match": true,  // ä¸»ç—‡æ˜¯å¦åŒ¹é…
    "pathogenesis_match": true   // ç—…æœºæ˜¯å¦åŒ¹é…
}}

åªè¿”å›JSONï¼Œä¸è¦å…¶ä»–å†…å®¹ã€‚"""

            response = Generation.call(
                model='qwen-max',
                api_key=self.api_key,
                prompt=prompt,
                result_format='message'
            )

            if response.status_code == 200:
                content = response.output.choices[0].message.content
                # æå–JSON
                import re
                json_match = re.search(r'\{.*\}', content, re.DOTALL)
                if json_match:
                    result = json.loads(json_match.group())
                    score = float(result.get('match_score', 0))
                    reason = result.get('reason', '')

                    logger.info(f"ğŸ¤– AIè¯­ä¹‰åŒ¹é…: åˆ†æ•°={score:.2f}, åŸå› ={reason}")
                    return (score, reason)

            # AIè°ƒç”¨å¤±è´¥ï¼Œé™çº§
            logger.warning("AIè°ƒç”¨å¤±è´¥ï¼Œä½¿ç”¨åŸºç¡€åŒ¹é…")
            return self._fallback_similarity(patient_description, syndrome_description)

        except Exception as e:
            logger.error(f"AIè¯­ä¹‰åˆ†æå¤±è´¥: {e}")
            return self._fallback_similarity(patient_description, syndrome_description)

    def _fallback_similarity(self, text1: str, text2: str) -> Tuple[float, str]:
        """
        é™çº§æ–¹æ¡ˆï¼šåŸºäºå…³é”®è¯åŒ¹é…çš„ç›¸ä¼¼åº¦è®¡ç®—
        """
        # æå–å…³é”®ç—‡çŠ¶è¯
        ç—‡çŠ¶å…³é”®è¯ = [
            "å‘çƒ­", "æ¶å¯’", "æ¶é£", "å¤´ç—›", "å’³å—½", "å’½ç—›", "é¼»å¡",
            "å£æ¸´", "æ±—å‡º", "èƒƒç—›", "è…¹ç—›", "ä¾¿ç§˜", "è…¹æ³»", "å¤±çœ ",
            "å¿ƒæ‚¸", "æ°”çŸ­", "ä¹åŠ›", "èˆŒçº¢", "èˆŒæ·¡", "è‹”é»„", "è‹”ç™½",
            "è„‰æµ®", "è„‰æ²‰", "è„‰æ•°", "è„‰è¿Ÿ"
        ]

        matched_keywords = []
        total_keywords_in_syndrome = 0

        for keyword in ç—‡çŠ¶å…³é”®è¯:
            if keyword in text2:  # å†³ç­–æ ‘ä¸­åŒ…å«æ­¤ç—‡çŠ¶
                total_keywords_in_syndrome += 1
                if keyword in text1:  # æ‚£è€…ä¹Ÿæœ‰æ­¤ç—‡çŠ¶
                    matched_keywords.append(keyword)

        if total_keywords_in_syndrome == 0:
            return (0.0, "æ— å…³é”®ç—‡çŠ¶åŒ¹é…")

        match_rate = len(matched_keywords) / total_keywords_in_syndrome
        reason = f"ç—‡çŠ¶åŒ¹é…: {len(matched_keywords)}/{total_keywords_in_syndrome} ({', '.join(matched_keywords[:3])}...)"

        logger.info(f"ğŸ“Š åŸºç¡€åŒ¹é…: {reason}, åŒ¹é…ç‡={match_rate:.2f}")
        return (match_rate, reason)

    async def find_matching_patterns(
        self,
        disease_name: str,
        symptoms: List[str],
        patient_description: str = "",
        doctor_id: Optional[str] = None,
        min_match_score: float = 0.6  # ğŸ†• AIè¯­ä¹‰åŒ¹é…ï¼Œæé«˜é˜ˆå€¼ç¡®ä¿è´¨é‡
    ) -> List[DecisionTreeMatch]:
        """
        æŸ¥æ‰¾åŒ¹é…çš„å†³ç­–æ ‘ - AIè¯­ä¹‰åŒ¹é…ç‰ˆ

        æ ¸å¿ƒé€»è¾‘ï¼š
        1. ä»å†³ç­–æ ‘ä¸­æå–symptomèŠ‚ç‚¹ï¼ˆåŒ…å«å®Œæ•´è¾¨è¯æè¿°ï¼‰
        2. ä½¿ç”¨AIè®¡ç®—æ‚£è€…æè¿°ä¸symptomèŠ‚ç‚¹çš„è¯­ä¹‰ç›¸ä¼¼åº¦
        3. åŸºäºç›¸ä¼¼åº¦ã€å†å²æˆåŠŸç‡ç­‰ç»¼åˆè¯„åˆ†

        Args:
            disease_name: ç–¾ç—…åç§°ï¼ˆAIæå–ï¼Œå¯èƒ½ä¸å‡†ç¡®ï¼‰
            symptoms: æ‚£è€…ç—‡çŠ¶åˆ—è¡¨
            patient_description: æ‚£è€…å®Œæ•´æè¿°ï¼ˆæœ€é‡è¦ï¼ï¼‰
            doctor_id: æŒ‡å®šåŒ»ç”ŸID(å¯é€‰)
            min_match_score: æœ€å°åŒ¹é…åˆ†æ•°é˜ˆå€¼ï¼ˆ0.6è¡¨ç¤ºè‡³å°‘60%ç›¸ä¼¼åº¦ï¼‰

        Returns:
            åŒ¹é…çš„å†³ç­–æ ‘åˆ—è¡¨,æŒ‰åŒ¹é…åˆ†æ•°æ’åº
        """
        try:
            conn = sqlite3.connect(self.db_path)
            conn.row_factory = sqlite3.Row
            cursor = conn.cursor()

            # ğŸ”‘ åŒ»ç”ŸIDæ˜ å°„
            actual_doctor_id = doctor_id
            if doctor_id and not doctor_id.startswith('usr_'):
                doctor_name_map = {
                    'jin_daifu': 'é‡‘å¤§å¤«',
                    'zhang_zhongjing': 'å¼ ä»²æ™¯'
                }
                doctor_name = doctor_name_map.get(doctor_id, doctor_id)

                cursor.execute("""
                    SELECT user_id FROM doctors
                    WHERE name = ?
                    LIMIT 1
                """, (doctor_name,))

                doctor_row = cursor.fetchone()
                if doctor_row and doctor_row['user_id']:
                    actual_doctor_id = doctor_row['user_id']
                    logger.info(f"ğŸ”„ åŒ»ç”ŸIDæ˜ å°„: {doctor_id} ({doctor_name}) â†’ {actual_doctor_id}")

            # ğŸ”§ æŸ¥è¯¢å†³ç­–æ ‘
            if actual_doctor_id:
                logger.info(f"ğŸ” æŸ¥è¯¢åŒ»ç”Ÿ {actual_doctor_id} çš„å†³ç­–æ ‘ï¼ˆAIè¯­ä¹‰åŒ¹é…æ¨¡å¼ï¼‰")
                cursor.execute("""
                    SELECT * FROM doctor_clinical_patterns
                    WHERE doctor_id = ?
                    ORDER BY usage_count DESC, success_count DESC
                """, (actual_doctor_id,))
            else:
                logger.info(f"ğŸ” æŸ¥è¯¢æ‰€æœ‰åŒ»ç”Ÿçš„å†³ç­–æ ‘")
                cursor.execute("""
                    SELECT * FROM doctor_clinical_patterns
                    ORDER BY usage_count DESC, success_count DESC
                """)

            patterns = cursor.fetchall()
            conn.close()

            if not patterns:
                logger.info("âŒ æœªæ‰¾åˆ°ä»»ä½•åŒ»ç”Ÿå†³ç­–æ ‘")
                return []

            logger.info(f"ğŸ“š æ‰¾åˆ° {len(patterns)} ä¸ªå†³ç­–æ ‘ï¼Œå¼€å§‹AIè¯­ä¹‰åŒ¹é…...")

            # ğŸ†• ä½¿ç”¨AIè¯­ä¹‰åŒ¹é…
            matches = []
            for pattern in patterns:
                try:
                    tree_structure = json.loads(pattern['tree_structure'])
                except:
                    logger.warning(f"å†³ç­–æ ‘ {pattern['id']} ç»“æ„è§£æå¤±è´¥ï¼Œè·³è¿‡")
                    continue

                # æå–symptomèŠ‚ç‚¹
                symptom_node = self._extract_symptom_node_from_tree(tree_structure)
                if not symptom_node:
                    logger.warning(f"å†³ç­–æ ‘ {pattern['disease_name']} æ²¡æœ‰symptomèŠ‚ç‚¹ï¼Œè·³è¿‡")
                    continue

                syndrome_description = symptom_node.get('description', '') or symptom_node.get('name', '')
                if not syndrome_description:
                    logger.warning(f"å†³ç­–æ ‘ {pattern['disease_name']} symptomèŠ‚ç‚¹ä¸ºç©ºï¼Œè·³è¿‡")
                    continue

                # ğŸ¤– AIè¯­ä¹‰åŒ¹é…
                match_score, match_reason = await self._calculate_ai_semantic_similarity(
                    patient_description,
                    syndrome_description
                )

                logger.info(f"ğŸ¯ å†³ç­–æ ‘ã€{pattern['disease_name']}ã€‘åŒ¹é…åˆ†æ•°: {match_score:.2f} - {match_reason}")

                if match_score >= min_match_score:
                    # è®¡ç®—ç½®ä¿¡åº¦(åŸºäºå†å²æˆåŠŸç‡å’ŒAIåŒ¹é…åˆ†æ•°)
                    usage = pattern['usage_count']
                    success = pattern['success_count']
                    confidence = (success / usage * 0.5 + match_score * 0.5) if usage > 0 else match_score

                    match = DecisionTreeMatch(
                        pattern_id=pattern['id'],
                        doctor_id=pattern['doctor_id'],
                        disease_name=pattern['disease_name'],
                        match_score=match_score,
                        thinking_process=pattern['thinking_process'],
                        tree_structure=tree_structure,  # å·²ç»åœ¨ä¸Šé¢è§£æè¿‡äº†
                        clinical_patterns=pattern['clinical_patterns'],
                        usage_count=usage,
                        success_count=success,
                        confidence=confidence,
                        match_reason=match_reason,  # ğŸ†• åŒ¹é…åŸå› 
                        syndrome_description=syndrome_description  # ğŸ†• è¯å€™æè¿°
                    )
                    matches.append(match)
                    logger.info(f"âœ… å†³ç­–æ ‘ã€{pattern['disease_name']}ã€‘åŒ¹é…æˆåŠŸï¼")

            # æŒ‰AIåŒ¹é…åˆ†æ•°æ’åºï¼ˆç½®ä¿¡åº¦ä½œä¸ºæ¬¡è¦å› ç´ ï¼‰
            matches.sort(key=lambda x: (x.match_score * 0.7 + x.confidence * 0.3), reverse=True)

            if matches:
                logger.info(f"ğŸ‰ æ‰¾åˆ° {len(matches)} ä¸ªåŒ¹é…çš„å†³ç­–æ ‘ï¼æœ€ä½³åŒ¹é…: {matches[0].disease_name} (åˆ†æ•°: {matches[0].match_score:.2f})")
            else:
                logger.info(f"âŒ æœªæ‰¾åˆ°åŒ¹é…çš„å†³ç­–æ ‘ (æœ€ä½é˜ˆå€¼: {min_match_score})")

            return matches

        except Exception as e:
            logger.error(f"æŸ¥æ‰¾å†³ç­–æ ‘å¤±è´¥: {e}")
            return []

    def _calculate_match_score(
        self,
        pattern: sqlite3.Row,
        disease_name: str,
        symptoms: List[str],
        patient_description: str
    ) -> float:
        """
        è®¡ç®—å†³ç­–æ ‘åŒ¹é…åˆ†æ•°

        åŒ¹é…ç®—æ³•:
        1. ç–¾ç—…åç§°å®Œå…¨åŒ¹é…: 0.4åˆ†
        2. ç–¾ç—…åˆ«ååŒ¹é…: 0.35åˆ†
        3. æ ¸å¿ƒç–¾ç—…è¯åŒ¹é…: 0.3åˆ† (å¦‚"èƒƒç—›"åŒ¹é…"è„¾èƒƒè™šå¯’å‹èƒƒç—›")
        4. ç—‡çŠ¶åŒ¹é…åº¦: 0.5åˆ† (æé«˜æƒé‡ï¼Œæ”¯æŒç—‡çŠ¶é©±åŠ¨çš„åŒ¹é…)
        5. ä¸´åºŠæ¨¡å¼æ–‡æœ¬ç›¸ä¼¼åº¦: 0.2åˆ†
        """
        total_score = 0.0
        disease_match_score = 0.0

        # 1. ç–¾ç—…åç§°åŒ¹é… (æƒé‡: 0.4)
        pattern_disease = pattern['disease_name']
        if disease_name == pattern_disease:
            # å®Œå…¨åŒ¹é…
            disease_match_score = 0.4
        elif self._is_disease_alias(disease_name, pattern_disease):
            # åˆ«ååŒ¹é…ï¼ˆå¢å¼ºç‰ˆï¼ŒåŒ…å«æ„Ÿå†’ç±»ç–¾ç—…çš„æ™ºèƒ½åŒ¹é…ï¼‰
            disease_match_score = 0.35
        elif disease_name in pattern_disease:
            # æ‚£è€…æè¿°çš„ç–¾ç—…ååŒ…å«åœ¨å†³ç­–æ ‘ç–¾ç—…åä¸­ (å¦‚"èƒƒç—›" in "è„¾èƒƒè™šå¯’å‹èƒƒç—›")
            # è¿™ç§æƒ…å†µåº”è¯¥ç»™è¾ƒé«˜åˆ†æ•°,å› ä¸ºæ˜¯æ ¸å¿ƒç–¾ç—…è¯åŒ¹é…
            disease_match_score = 0.3
        elif pattern_disease in disease_name:
            # å†³ç­–æ ‘ç–¾ç—…ååŒ…å«åœ¨æ‚£è€…æè¿°ä¸­
            disease_match_score = 0.25

        total_score += disease_match_score

        # 2. ç—‡çŠ¶åŒ¹é…åº¦ (æƒé‡: 0.5ï¼Œæé«˜æƒé‡ä»¥æ”¯æŒç—‡çŠ¶é©±åŠ¨çš„åŒ¹é…)
        symptom_score = 0.0
        if symptoms:
            symptom_score = self._calculate_symptom_match(
                pattern['thinking_process'],
                pattern['clinical_patterns'],
                symptoms
            )
            total_score += symptom_score * 0.5

            # ğŸ”‘ å…³é”®ä¼˜åŒ–ï¼šå¦‚æœç–¾ç—…åç§°åŒ¹é…åº¦ä½ï¼Œä½†ç—‡çŠ¶åŒ¹é…åº¦é«˜ï¼Œä»ç„¶ç»™äºˆè¾ƒé«˜æ€»åˆ†
            # ä¾‹å¦‚ï¼šAIæå–"å‘çƒ­"ï¼Œå†³ç­–æ ‘æ˜¯"é£çƒ­æ„Ÿå†’"ï¼Œä½†ç—‡çŠ¶é«˜åº¦å»åˆ
            if disease_match_score < 0.3 and symptom_score >= 0.6:
                logger.info(f"âš¡ ç—‡çŠ¶é©±åŠ¨åŒ¹é…: ç–¾ç—…'{disease_name}'â†’'{pattern_disease}', ç—‡çŠ¶åŒ¹é…åº¦={symptom_score:.2f}")
                # ç»™äºˆé¢å¤–çš„ç–¾ç—…åŒ¹é…åˆ†æ•°è¡¥å¿
                total_score += 0.15

        # 3. ä¸´åºŠæ¨¡å¼æ–‡æœ¬ç›¸ä¼¼åº¦ (æƒé‡: 0.2)
        if patient_description:
            text_similarity = self._calculate_text_similarity(
                patient_description,
                pattern['thinking_process'] + " " + pattern['clinical_patterns']
            )
            total_score += text_similarity * 0.2

        return min(total_score, 1.0)

    def _is_disease_alias(self, disease1: str, disease2: str) -> bool:
        """
        æ£€æŸ¥ä¸¤ä¸ªç–¾ç—…åç§°æ˜¯å¦ä¸ºåˆ«åå…³ç³»

        ç­–ç•¥ï¼š
        1. å®Œå…¨åŒ¹é…åŒä¸€ä¸ªåˆ«åç»„
        2. éƒ¨åˆ†åŒ¹é…ï¼šdisease1åŒ…å«åœ¨disease2çš„åˆ«åç»„ä¸­ï¼Œæˆ–åä¹‹
        """
        for main_disease, aliases in self.disease_aliases.items():
            # å®Œå…¨åŒ¹é…ï¼šä¸¤ä¸ªç–¾ç—…éƒ½åœ¨åŒä¸€ä¸ªåˆ«åç»„ä¸­
            if disease1 in aliases and disease2 in aliases:
                return True

            # éƒ¨åˆ†åŒ¹é…ï¼šdisease1åœ¨åˆ«åç»„ä¸­ï¼Œä¸”disease2åŒ…å«åˆ«åç»„ä¸­çš„ä»»æ„è¯
            if disease1 in aliases:
                for alias in aliases:
                    if alias in disease2 or disease2 in alias:
                        logger.info(f"ğŸ” ç–¾ç—…åˆ«ååŒ¹é…: '{disease1}' â†” '{disease2}' (é€šè¿‡'{alias}')")
                        return True

            # éƒ¨åˆ†åŒ¹é…ï¼šdisease2åœ¨åˆ«åç»„ä¸­ï¼Œä¸”disease1åŒ…å«åˆ«åç»„ä¸­çš„ä»»æ„è¯
            if disease2 in aliases:
                for alias in aliases:
                    if alias in disease1 or disease1 in alias:
                        logger.info(f"ğŸ” ç–¾ç—…åˆ«ååŒ¹é…: '{disease1}' â†” '{disease2}' (é€šè¿‡'{alias}')")
                        return True

        return False

    def _calculate_symptom_match(
        self,
        thinking_process: str,
        clinical_patterns: str,
        symptoms: List[str]
    ) -> float:
        """è®¡ç®—ç—‡çŠ¶åŒ¹é…åº¦"""
        if not symptoms:
            return 0.0

        combined_text = thinking_process + " " + clinical_patterns
        matched_count = 0

        for symptom in symptoms:
            if symptom in combined_text:
                matched_count += 1

        return matched_count / len(symptoms) if symptoms else 0.0

    def _calculate_text_similarity(self, text1: str, text2: str) -> float:
        """è®¡ç®—æ–‡æœ¬ç›¸ä¼¼åº¦(åŸºäºå…³é”®è¯é‡å )"""
        # åˆ†è¯
        words1 = set(jieba.cut(text1))
        words2 = set(jieba.cut(text2))

        # è¿‡æ»¤åœç”¨è¯
        stopwords = {"çš„", "äº†", "åœ¨", "æ˜¯", "æˆ‘", "æœ‰", "å’Œ", "å°±", "ä¸", "äºº", "éƒ½", "ä¸€", "ä¸€ä¸ª", "ä¸Š", "ä¹Ÿ", "å¾ˆ", "åˆ°", "è¯´", "è¦", "å»", "ä½ ", "ä¼š", "ç€", "æ²¡æœ‰", "çœ‹", "å¥½", "è‡ªå·±", "è¿™"}
        words1 = words1 - stopwords
        words2 = words2 - stopwords

        if not words1 or not words2:
            return 0.0

        # Jaccardç›¸ä¼¼åº¦
        intersection = words1 & words2
        union = words1 | words2

        return len(intersection) / len(union) if union else 0.0

    async def get_pattern_by_id(self, pattern_id: str) -> Optional[DecisionTreeMatch]:
        """æ ¹æ®IDè·å–å†³ç­–æ ‘"""
        try:
            conn = sqlite3.connect(self.db_path)
            conn.row_factory = sqlite3.Row
            cursor = conn.cursor()

            cursor.execute("""
                SELECT * FROM doctor_clinical_patterns WHERE id = ?
            """, (pattern_id,))

            pattern = cursor.fetchone()
            conn.close()

            if not pattern:
                return None

            try:
                tree_structure = json.loads(pattern['tree_structure'])
            except:
                tree_structure = {}

            usage = pattern['usage_count']
            success = pattern['success_count']
            confidence = (success / usage) if usage > 0 else 0.5

            return DecisionTreeMatch(
                pattern_id=pattern['id'],
                doctor_id=pattern['doctor_id'],
                disease_name=pattern['disease_name'],
                match_score=1.0,
                thinking_process=pattern['thinking_process'],
                tree_structure=tree_structure,
                clinical_patterns=pattern['clinical_patterns'],
                usage_count=usage,
                success_count=success,
                confidence=confidence
            )

        except Exception as e:
            logger.error(f"è·å–å†³ç­–æ ‘å¤±è´¥: {e}")
            return None

    async def record_pattern_usage(
        self,
        pattern_id: str,
        success: bool = False,
        feedback: Optional[str] = None
    ):
        """è®°å½•å†³ç­–æ ‘ä½¿ç”¨æƒ…å†µ"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()

            if success:
                cursor.execute("""
                    UPDATE doctor_clinical_patterns
                    SET usage_count = usage_count + 1,
                        success_count = success_count + 1,
                        last_used_at = ?
                    WHERE id = ?
                """, (datetime.now().isoformat(), pattern_id))
            else:
                cursor.execute("""
                    UPDATE doctor_clinical_patterns
                    SET usage_count = usage_count + 1,
                        last_used_at = ?
                    WHERE id = ?
                """, (datetime.now().isoformat(), pattern_id))

            conn.commit()
            conn.close()

            logger.info(f"âœ… è®°å½•å†³ç­–æ ‘ä½¿ç”¨: {pattern_id}, æˆåŠŸ: {success}")

        except Exception as e:
            logger.error(f"è®°å½•å†³ç­–æ ‘ä½¿ç”¨å¤±è´¥: {e}")

    def extract_symptoms_from_text(self, text: str) -> List[str]:
        """ä»æ–‡æœ¬ä¸­æå–ç—‡çŠ¶å…³é”®è¯"""
        symptoms = []

        # å¸¸è§ç—‡çŠ¶å…³é”®è¯
        symptom_keywords = [
            "å¤´ç—›", "å¤´ç–¼", "å‘çƒ­", "å‘çƒ§", "å’³å—½", "å¤±çœ ", "å¤šæ¢¦",
            "èƒƒç—›", "è…¹ç—›", "è…¹æ³»", "ä¾¿ç§˜", "å¿ƒæ‚¸", "å¿ƒæ…Œ", "ä¹åŠ›",
            "é£Ÿæ¬²ä¸æŒ¯", "æ¶å¿ƒ", "å‘•å", "èƒ¸é—·", "æ°”çŸ­", "çœ©æ™•",
            "è€³é¸£", "æ€•å†·", "æ€•çƒ­", "å‡ºæ±—", "ç›—æ±—", "å£å¹²", "å£è‹¦",
            "å’½ç—›", "é¼»å¡", "æµæ¶•", "è…°ç—›", "è†ç—›", "å…³èŠ‚ç—›"
        ]

        for keyword in symptom_keywords:
            if keyword in text:
                symptoms.append(keyword)

        return list(set(symptoms))  # å»é‡

    def extract_disease_from_text(self, text: str) -> Optional[str]:
        """
        ä»æ–‡æœ¬ä¸­æå–ç–¾ç—…åç§°

        ç­–ç•¥ï¼šæ‰¾åˆ°æ‰€æœ‰åŒ¹é…çš„ç–¾ç—…ï¼Œä¼˜å…ˆé€‰æ‹©åœ¨æ–‡æœ¬ä¸­æœ€æ—©å‡ºç°çš„ï¼ˆä¸»è¦ç—‡çŠ¶ï¼‰
        ä¾‹å¦‚ï¼š"èƒƒè„˜éšç—›...å¤§ä¾¿æºè–„" â†’ ä¼˜å…ˆè¿”å›"èƒƒç—›"è€Œä¸æ˜¯"è…¹æ³»"
        """
        matched_diseases = []

        for main_disease, aliases in self.disease_aliases.items():
            for alias in aliases:
                if alias in text:
                    # è®°å½•ç–¾ç—…åç§°å’Œåœ¨æ–‡æœ¬ä¸­çš„ä½ç½®
                    position = text.find(alias)
                    matched_diseases.append((main_disease, position, alias))
                    break  # æ‰¾åˆ°ä¸€ä¸ªåˆ«åå°±è·³å‡ºï¼Œé¿å…é‡å¤

        if not matched_diseases:
            return None

        # æŒ‰ç…§åœ¨æ–‡æœ¬ä¸­çš„ä½ç½®æ’åºï¼Œé€‰æ‹©æœ€æ—©å‡ºç°çš„ç–¾ç—…
        matched_diseases.sort(key=lambda x: x[1])

        selected_disease = matched_diseases[0][0]
        logger.info(f"ğŸ” ç–¾ç—…æå–: æ‰¾åˆ° {len(matched_diseases)} ä¸ªå€™é€‰ç–¾ç—…ï¼Œé€‰æ‹©æœ€æ—©å‡ºç°çš„ '{selected_disease}'")

        return selected_disease

# å…¨å±€å•ä¾‹
_matcher_instance = None

def get_decision_tree_matcher() -> DecisionTreeMatcher:
    """è·å–å†³ç­–æ ‘åŒ¹é…å™¨å•ä¾‹"""
    global _matcher_instance
    if _matcher_instance is None:
        _matcher_instance = DecisionTreeMatcher()
    return _matcher_instance
