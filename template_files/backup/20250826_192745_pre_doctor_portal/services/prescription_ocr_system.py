#!/usr/bin/env python3
"""
ä¸­åŒ»å¤„æ–¹OCRè¯†åˆ«ç³»ç»Ÿ - Prescription OCR Recognition System
åŠŸèƒ½ï¼šå›¾ç‰‡/PDFè¯†åˆ«ã€åŒ»å­¦æ–‡æœ¬çº é”™ã€ä¸ç°æœ‰å¤„æ–¹æ£€æŸ¥ç³»ç»Ÿé›†æˆ
ä½œè€…ï¼šTCM AI System
"""

import os
import re
import json
import base64
import requests
import fitz  # PyMuPDF
from PIL import Image, ImageEnhance, ImageFilter
from typing import Dict, List, Optional, Any, Tuple
from io import BytesIO
import logging
from dataclasses import dataclass
from datetime import datetime

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class OCRResult:
    """OCRè¯†åˆ«ç»“æœç»“æ„"""
    text: str  # è¯†åˆ«çš„æ–‡æœ¬
    confidence: float  # è¯†åˆ«ç½®ä¿¡åº¦
    corrected_text: Optional[str] = None  # åŒ»å­¦çº é”™åçš„æ–‡æœ¬
    words_info: Optional[List[Dict]] = None  # è¯æ±‡ä½ç½®ä¿¡æ¯
    processing_time: Optional[float] = None  # å¤„ç†æ—¶é—´

class PrescriptionImageProcessor:
    """å¤„æ–¹å›¾åƒé¢„å¤„ç†ç³»ç»Ÿ"""
    
    def __init__(self):
        """åˆå§‹åŒ–å›¾åƒå¤„ç†å™¨"""
        self.supported_formats = ['jpg', 'jpeg', 'png', 'bmp', 'tiff', 'pdf']
        self.max_size = (1600, 1600)  # ç™¾åº¦OCRè¶…ä¸¥æ ¼é™åˆ¶: æ›´ä¿å®ˆçš„å°ºå¯¸
        self.max_file_size = 500 * 1024  # 500KBæ–‡ä»¶å¤§å°é™åˆ¶ (è¶…ä¿å®ˆ)
        self.max_base64_size = int(700 * 1024)  # 700KB base64é™åˆ¶ (è¶…ä¿å®ˆ)
        self.min_size = (15, 15)  # ç™¾åº¦OCRæœ€å°é™åˆ¶: æœ€çŸ­è¾¹å¤§äº10px
        
    def preprocess_image(self, image_data: bytes, format_hint: str = None) -> bytes:
        """å›¾åƒé¢„å¤„ç†ï¼šæ™ºèƒ½å‹ç¼©ã€å»å™ªã€çŸ«æ­£ã€å¯¹æ¯”åº¦å¢å¼º"""
        try:
            # æ£€æŸ¥æ–‡ä»¶å¤§å°
            file_size = len(image_data)
            logger.info(f"åŸå§‹å›¾ç‰‡å¤§å°: {file_size / 1024 / 1024:.2f} MB")
            
            # æ‰“å¼€å›¾åƒ
            image = Image.open(BytesIO(image_data))
            original_size = image.size
            logger.info(f"åŸå§‹å›¾ç‰‡å°ºå¯¸: {original_size}")
            
            # æ£€æŸ¥å°ºå¯¸é™åˆ¶
            if (original_size[0] < self.min_size[0] or original_size[1] < self.min_size[1]):
                logger.warning(f"å›¾ç‰‡å°ºå¯¸å¤ªå°: {original_size}, æœ€å°è¦æ±‚: {self.min_size}")
                # ä¸æŠ›å‡ºå¼‚å¸¸ï¼Œè€Œæ˜¯æ”¾å¤§å›¾ç‰‡åˆ°æœ€å°å°ºå¯¸
                scale_factor = max(self.min_size[0] / original_size[0], self.min_size[1] / original_size[1])
                new_size = (int(original_size[0] * scale_factor), int(original_size[1] * scale_factor))
                image = image.resize(new_size, Image.Resampling.LANCZOS)
                logger.info(f"å›¾ç‰‡å·²æ”¾å¤§åˆ°: {image.size}")
            
            # è½¬æ¢ä¸ºRGBæ¨¡å¼
            if image.mode != 'RGB':
                image = image.convert('RGB')
            
            # 1. æ™ºèƒ½å°ºå¯¸è°ƒæ•´
            needs_resize = False
            if image.size[0] > self.max_size[0] or image.size[1] > self.max_size[1]:
                needs_resize = True
                logger.info(f"å›¾ç‰‡å°ºå¯¸è¶…é™ï¼Œéœ€è¦å‹ç¼©: {image.size} -> {self.max_size}")
                image.thumbnail(self.max_size, Image.Resampling.LANCZOS)
                logger.info(f"å‹ç¼©åå°ºå¯¸: {image.size}")
            
            # 2. å¯¹æ¯”åº¦å¢å¼ºï¼ˆå¤„æ–¹å•é€šå¸¸å¯¹æ¯”åº¦ä¸å¤Ÿï¼‰
            enhancer = ImageEnhance.Contrast(image)
            image = enhancer.enhance(1.3)
            
            # 3. é”åŒ–å¤„ç†ï¼ˆæå‡å­—ç¬¦æ¸…æ™°åº¦ï¼‰
            image = image.filter(ImageFilter.UnsharpMask(radius=1, percent=150, threshold=3))
            
            # 4. äº®åº¦è°ƒæ•´
            enhancer = ImageEnhance.Brightness(image)
            image = enhancer.enhance(1.1)
            
            # è½¬æ¢å›å­—èŠ‚æµï¼Œæ™ºèƒ½è´¨é‡æ§åˆ¶
            output = BytesIO()
            
            # æ ¹æ®æ–‡ä»¶å¤§å°æ™ºèƒ½è°ƒæ•´è´¨é‡ - è¶…æ¿€è¿›çš„å‹ç¼©ç­–ç•¥
            if file_size > self.max_file_size:
                # å¤§æ–‡ä»¶ä½¿ç”¨è¶…ä½è´¨é‡
                quality = 50
                logger.info("å¤§æ–‡ä»¶ï¼Œä½¿ç”¨è´¨é‡50%å‹ç¼©")
            elif needs_resize:
                # å°ºå¯¸è°ƒæ•´è¿‡çš„æ–‡ä»¶ä½¿ç”¨ä½è´¨é‡
                quality = 60
                logger.info("å°ºå¯¸è°ƒæ•´ï¼Œä½¿ç”¨è´¨é‡60%")
            else:
                # æ­£å¸¸æ–‡ä»¶ä½¿ç”¨ä¸­ä½è´¨é‡
                quality = 65
                logger.info("æ­£å¸¸æ–‡ä»¶ï¼Œä½¿ç”¨è´¨é‡65%")
            
            image.save(output, format='JPEG', quality=quality, optimize=True)
            processed_data = output.getvalue()
            
            processed_size = len(processed_data)
            logger.info(f"å¤„ç†åå›¾ç‰‡å¤§å°: {processed_size / 1024 / 1024:.2f} MB")
            
            # æœ€ç»ˆæ£€æŸ¥æ–‡ä»¶å¤§å°
            if processed_size > self.max_file_size:
                logger.warning("å¤„ç†åæ–‡ä»¶ä»ç„¶è¿‡å¤§ï¼Œè¿›è¡Œè¿›ä¸€æ­¥å‹ç¼©")
                output = BytesIO()
                image.save(output, format='JPEG', quality=75, optimize=True)
                processed_data = output.getvalue()
                logger.info(f"æœ€ç»ˆå›¾ç‰‡å¤§å°: {len(processed_data) / 1024 / 1024:.2f} MB")
            
            # æ£€æŸ¥base64ç¼–ç åçš„å¤§å° (é‡è¦!)
            import base64
            base64_size = len(base64.b64encode(processed_data))
            logger.info(f"base64ç¼–ç å¤§å°: {base64_size / 1024 / 1024:.2f} MB")
            
            if base64_size > self.max_base64_size:
                logger.warning("base64ç¼–ç è¿‡å¤§ï¼Œè¿›è¡Œæ¿€è¿›å‹ç¼©")
                # æ¿€è¿›å‹ç¼©æ¨¡å¼ - æ›´ä¸¥æ ¼çš„ç­–ç•¥
                quality = 50  # ä»æ›´ä½è´¨é‡å¼€å§‹
                while base64_size > self.max_base64_size and quality >= 20:
                    output = BytesIO()
                    image.save(output, format='JPEG', quality=quality, optimize=True)
                    processed_data = output.getvalue()
                    base64_size = len(base64.b64encode(processed_data))
                    logger.info(f"æ¿€è¿›å‹ç¼©-è´¨é‡{quality}%: æ–‡ä»¶{len(processed_data)/1024/1024:.2f}MB, base64:{base64_size/1024/1024:.2f}MB")
                    quality -= 5  # æ›´å°çš„æ­¥é•¿
                
                # å¦‚æœè¿˜æ˜¯å¤ªå¤§ï¼Œå°è¯•è¿›ä¸€æ­¥ç¼©å°å°ºå¯¸
                if base64_size > self.max_base64_size:
                    logger.warning("ç»§ç»­ç¼©å°å›¾ç‰‡å°ºå¯¸")
                    scale_factor = 0.8
                    while base64_size > self.max_base64_size and scale_factor >= 0.5:
                        new_size = (int(image.size[0] * scale_factor), int(image.size[1] * scale_factor))
                        resized_image = image.resize(new_size, Image.Resampling.LANCZOS)
                        output = BytesIO()
                        resized_image.save(output, format='JPEG', quality=60, optimize=True)
                        processed_data = output.getvalue()
                        base64_size = len(base64.b64encode(processed_data))
                        logger.info(f"å°ºå¯¸ç¼©æ”¾{scale_factor:.1f}: å°ºå¯¸{new_size}, æ–‡ä»¶{len(processed_data)/1024/1024:.2f}MB, base64:{base64_size/1024/1024:.2f}MB")
                        scale_factor -= 0.1
                
                if base64_size > self.max_base64_size:
                    logger.error(f"æ— æ³•å°†å›¾ç‰‡å‹ç¼©åˆ°åˆé€‚å¤§å°ï¼Œå½“å‰base64: {base64_size/1024/1024:.2f}MB")
                    raise ValueError("å›¾ç‰‡è¿‡å¤§ï¼Œæ— æ³•å‹ç¼©åˆ°ç™¾åº¦OCRè¦æ±‚çš„å¤§å°")
            
            return processed_data
            
        except Exception as e:
            logger.error(f"å›¾åƒé¢„å¤„ç†å¤±è´¥: {e}")
            return image_data  # è¿”å›åŸå§‹æ•°æ®
    
    def extract_pdf_images(self, pdf_data: bytes) -> List[bytes]:
        """ä»PDFæå–å›¾åƒé¡µé¢"""
        try:
            doc = fitz.open(stream=pdf_data, filetype="pdf")
            images = []
            
            for page_num in range(doc.page_count):
                page = doc.load_page(page_num)
                
                # å°†é¡µé¢æ¸²æŸ“ä¸ºå›¾åƒ
                mat = fitz.Matrix(2.0, 2.0)  # æå‡åˆ†è¾¨ç‡
                pix = page.get_pixmap(matrix=mat)
                img_data = pix.tobytes("jpeg")
                images.append(img_data)
            
            doc.close()
            return images
            
        except Exception as e:
            logger.error(f"PDFå›¾åƒæå–å¤±è´¥: {e}")
            return []

class MedicalTextCorrector:
    """åŒ»å­¦æ–‡æœ¬æ™ºèƒ½çº é”™ç³»ç»Ÿ"""
    
    def __init__(self):
        """åˆå§‹åŒ–åŒ»å­¦æ–‡æœ¬çº é”™å™¨"""
        # å¸¸è§OCRé”™è¯¯æ˜ å°„ï¼ˆåŸºäºå®é™…ä½¿ç”¨ç»éªŒï¼‰
        self.common_ocr_errors = {
            # ä¸­è¯åç§°å¸¸è§é”™è¯¯
            "å½“å½’": ["å½“å½’", "å½“å½’", "å½“å¸°", "å½“å½’"],
            "é»„èŠª": ["é»„èŠª", "é»„èŠª", "é»„èŠ©", "é»„è“"],
            "äººå‚": ["äººå‚", "äººå‚", "äººè”˜", "äººæ£®"],
            "ç™½æœ¯": ["ç™½æœ¯", "ç™½æœ¯", "ç™½æœ¯", "ç™½æœ®"],
            "èŒ¯è‹“": ["èŒ¯è‹“", "èŒ¯è‹“", "èŒ¯çµ", "ä¼è‹“"],
            "ç”˜è‰": ["ç”˜è‰", "ç”˜è‰", "ç”˜æ—©", "ç”˜è†"],
            "å·èŠ": ["å·èŠ", "å·èŠ", "å·å¼“", "å·ç©¹"],
            "å½“å½’": ["å½“å½’", "å½“å¸°", "ç•¶æ­¸"],
            "çº¢èŠ±": ["çº¢èŠ±", "çº¢èŠ±", "ç´…èŠ±", "çº¢å"],
            "æ¡ƒä»": ["æ¡ƒä»", "æ¡ƒä»", "æ¡ƒäºº", "æŒ‘ä»"],
            
            # å‰‚é‡å•ä½å¸¸è§é”™è¯¯
            "å…‹": ["å…‹", "g", "å…Ÿ", "çª©"],
            "æ¯«å‡": ["æ¯«å‡", "ml", "è±ªå‡", "æ¯«å¼€"],
            "ç‰‡": ["ç‰‡", "ç‰‡", "æ–¤", "æ–¤"],
            "ç²’": ["ç²’", "ç²’", "ç²’", "ç«‹"],
            
            # ç”¨æ³•ç”¨é‡
            "æ°´ç…æœ": ["æ°´ç…æœ", "æ°´å‰æœ", "æ°´ç®­æœ", "æ°´å‰‘æœ"],
            "æ¯æ—¥": ["æ¯æ—¥", "æ¯ç›®", "æ¯æ›°", "æ¯ã€…"],
            "åˆ†æœ": ["åˆ†æœ", "åˆ†æœ", "ä»½æœ", "åˆ†è…¹"],
            "æ¸©æœ": ["æ¸©æœ", "æº«æœ", "æ¸©è…¹", "æ¹¿æœ"],
            
            # åŒ»å­¦æœ¯è¯­
            "è¯å€™": ["è¯å€™", "ç—‡å€™", "å¾å€™", "è¨¼å€™"],
            "æ–¹å‰‚": ["æ–¹å‰‚", "æ–¹å‰‚", "æ–¹é½", "èŠ³å‰‚"],
            "é…ä¼": ["é…ä¼", "é…ä¼", "é…åˆ", "é…äº”"],
        }
        
        # æ„å»ºåå‘æ˜ å°„è¡¨
        self.correction_map = {}
        for correct, errors in self.common_ocr_errors.items():
            for error in errors:
                if error != correct:  # æ’é™¤æ­£ç¡®çš„å†™æ³•
                    self.correction_map[error] = correct
    
    def correct_medical_text(self, text: str) -> Tuple[str, List[str]]:
        """åŒ»å­¦æ–‡æœ¬æ™ºèƒ½çº é”™"""
        try:
            corrected_text = text
            corrections = []
            
            # 1. åŸºäºå­—å…¸çš„çº é”™
            for error, correct in self.correction_map.items():
                if error in corrected_text:
                    corrected_text = corrected_text.replace(error, correct)
                    corrections.append(f"{error} â†’ {correct}")
            
            # 2. å‰‚é‡æ ¼å¼æ ‡å‡†åŒ–
            # åŒ¹é…å„ç§å‰‚é‡æ ¼å¼: 10g, 10 g, 10å…‹, åå…‹ç­‰
            dose_patterns = [
                (r'(\d+)\s*å…‹', r'\1g'),
                (r'(\d+)\s*æ¯«å‡', r'\1ml'),
                (r'(\d+)\s*é’±', r'\1g'),  # 1é’±çº¦ç­‰äº3gï¼Œè¿™é‡Œç®€åŒ–å¤„ç†
                (r'([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+)å…‹', self._chinese_num_to_g),
                (r'(\d+)-(\d+)\s*g', r'\1-\2g'),  # è§„èŒƒåŒ–èŒƒå›´è¡¨ç¤º
            ]
            
            for pattern, replacement in dose_patterns:
                if callable(replacement):
                    corrected_text = re.sub(pattern, replacement, corrected_text)
                else:
                    old_text = corrected_text
                    corrected_text = re.sub(pattern, replacement, corrected_text)
                    if old_text != corrected_text:
                        corrections.append("å‰‚é‡æ ¼å¼æ ‡å‡†åŒ–")
            
            # 3. ä¸­è¯åç§°å®Œæ•´æ€§æ£€æŸ¥
            corrected_text = self._fix_incomplete_herb_names(corrected_text, corrections)
            
            return corrected_text, corrections
            
        except Exception as e:
            logger.error(f"åŒ»å­¦æ–‡æœ¬çº é”™å¤±è´¥: {e}")
            return text, []
    
    def _chinese_num_to_g(self, match) -> str:
        """ä¸­æ–‡æ•°å­—è½¬æ¢ä¸ºé˜¿æ‹‰ä¼¯æ•°å­—+g"""
        chinese_nums = {
            'ä¸€': '1', 'äºŒ': '2', 'ä¸‰': '3', 'å››': '4', 'äº”': '5',
            'å…­': '6', 'ä¸ƒ': '7', 'å…«': '8', 'ä¹': '9', 'å': '10'
        }
        chinese_num = match.group(1)
        arabic_num = chinese_nums.get(chinese_num, chinese_num)
        return f"{arabic_num}g"
    
    def _fix_incomplete_herb_names(self, text: str, corrections: List[str]) -> str:
        """ä¿®å¤ä¸å®Œæ•´çš„è¯åè¯†åˆ«"""
        # å¸¸è§çš„ä¸å®Œæ•´è¯åæ¨¡å¼
        incomplete_patterns = {
            r'å½“\s*å½’': 'å½“å½’',
            r'é»„\s*èŠª': 'é»„èŠª',
            r'äºº\s*å‚': 'äººå‚',
            r'ç™½\s*æœ¯': 'ç™½æœ¯',
            r'èŒ¯\s*è‹“': 'èŒ¯è‹“',
            r'å·\s*èŠ': 'å·èŠ',
            r'çº¢\s*èŠ±': 'çº¢èŠ±',
            r'æ¡ƒ\s*ä»': 'æ¡ƒä»',
        }
        
        for pattern, replacement in incomplete_patterns.items():
            old_text = text
            text = re.sub(pattern, replacement, text)
            if old_text != text:
                corrections.append(f"ä¿®å¤è¯å: {replacement}")
        
        return text

class BaiduOCRService:
    """ç™¾åº¦OCRæœåŠ¡æ¥å£"""
    
    def __init__(self):
        """åˆå§‹åŒ–ç™¾åº¦OCRæœåŠ¡"""
        # ä».envæ–‡ä»¶è¯»å–APIå¯†é’¥
        self.api_key = None
        self.secret_key = None
        
        # å°è¯•ä».envæ–‡ä»¶åŠ è½½é…ç½®
        env_file = '/opt/tcm/.env'
        if os.path.exists(env_file):
            with open(env_file, 'r') as f:
                for line in f:
                    line = line.strip()
                    if line and not line.startswith('#') and '=' in line:
                        key, value = line.split('=', 1)
                        if key == 'BAIDU_OCR_API_KEY':
                            self.api_key = value
                        elif key == 'BAIDU_OCR_SECRET_KEY':
                            self.secret_key = value
        
        # å¦‚æœè¿˜æ²¡æœ‰æ‰¾åˆ°ï¼Œå°è¯•ç¯å¢ƒå˜é‡
        if not self.api_key:
            self.api_key = os.getenv('BAIDU_OCR_API_KEY')
        if not self.secret_key:
            self.secret_key = os.getenv('BAIDU_OCR_SECRET_KEY')
        
        # å¦‚æœæ²¡æœ‰è®¾ç½®ï¼Œä½¿ç”¨æµ‹è¯•å¯†é’¥ï¼ˆå®é™…ç”Ÿäº§ä¸­åº”è¯¥è®¾ç½®çœŸå®å¯†é’¥ï¼‰
        if not self.api_key or not self.secret_key:
            logger.warning("ç™¾åº¦OCRå¯†é’¥æœªè®¾ç½®ï¼Œä½¿ç”¨æµ‹è¯•æ¨¡å¼")
            self.api_key = "your_baidu_api_key"
            self.secret_key = "your_baidu_secret_key"
        
        self.access_token = None
        self.token_expires_at = 0
    
    def get_access_token(self) -> Optional[str]:
        """è·å–ç™¾åº¦APIè®¿é—®ä»¤ç‰Œ"""
        try:
            current_time = datetime.now().timestamp()
            
            # å¦‚æœtokenè¿˜æœ‰æ•ˆï¼Œç›´æ¥è¿”å›
            if self.access_token and current_time < self.token_expires_at:
                return self.access_token
            
            # è·å–æ–°çš„access_token
            url = "https://aip.baidubce.com/oauth/2.0/token"
            params = {
                "grant_type": "client_credentials",
                "client_id": self.api_key,
                "client_secret": self.secret_key
            }
            
            response = requests.post(url, params=params, timeout=10)
            
            if response.status_code == 200:
                data = response.json()
                self.access_token = data.get("access_token")
                expires_in = data.get("expires_in", 3600)
                self.token_expires_at = current_time + expires_in - 300  # æå‰5åˆ†é’Ÿè¿‡æœŸ
                return self.access_token
            else:
                logger.error(f"è·å–ç™¾åº¦access_tokenå¤±è´¥: {response.text}")
                return None
                
        except Exception as e:
            logger.error(f"è·å–ç™¾åº¦access_tokenå¼‚å¸¸: {e}")
            return None
    
    def recognize_text(self, image_data: bytes) -> OCRResult:
        """ä½¿ç”¨ç™¾åº¦OCRè¯†åˆ«å›¾ç‰‡æ–‡å­—"""
        try:
            start_time = datetime.now()
            
            # è·å–è®¿é—®ä»¤ç‰Œ
            access_token = self.get_access_token()
            if not access_token:
                return OCRResult(text="", confidence=0.0)
            
            # å‡†å¤‡è¯·æ±‚ - ä½¿ç”¨é«˜ç²¾åº¦ç‰ˆæœ¬
            url = f"https://aip.baidubce.com/rest/2.0/ocr/v1/accurate?access_token={access_token}"
            
            # å›¾ç‰‡è½¬base64å¹¶è®°å½•ä¿¡æ¯
            image_b64 = base64.b64encode(image_data).decode()
            
            # è®°å½•å›¾ç‰‡ä¿¡æ¯ç”¨äºè°ƒè¯•
            file_size = len(image_data)
            base64_size = len(image_b64)
            logger.info(f"ç™¾åº¦OCRè¯·æ±‚: æ–‡ä»¶{file_size/1024:.1f}KB, base64:{base64_size/1024:.1f}KB")
            
            # æ£€æŸ¥æ˜¯å¦æœ‰æ˜æ˜¾é—®é¢˜
            if file_size < 1000:  # å°äº1KB
                logger.warning(f"å›¾ç‰‡æ–‡ä»¶è¿‡å° ({file_size} bytes)ï¼Œå¯èƒ½å¯¼è‡´è¯†åˆ«å¤±è´¥")
            elif base64_size > 5 * 1024 * 1024:  # å¤§äº5MB base64
                logger.warning(f"base64ç¼–ç è¿‡å¤§ ({base64_size/1024/1024:.1f}MB)ï¼Œå¯èƒ½å¯¼è‡´è¯†åˆ«å¤±è´¥")
            
            data = {
                "image": image_b64,
                "detect_direction": "false",     # å…³é—­æœå‘æ£€æµ‹(é«˜ç²¾åº¦ç‰ˆæ¨è)
                "vertexes_location": "true",     # è¿”å›æ–‡å­—ä½ç½®ä¿¡æ¯
                "paragraph": "false",            # ä¸åˆå¹¶æ®µè½
                "probability": "true",           # è¿”å›ç½®ä¿¡åº¦
                "char_probability": "false",     # ä¸è¿”å›å•å­—ç½®ä¿¡åº¦
                "multidirectional_recognize": "false"  # å…³é—­å¤šæ–¹å‘è¯†åˆ«
            }
            
            headers = {
                'Content-Type': 'application/x-www-form-urlencoded'
            }
            
            # å‘é€è¯·æ±‚
            response = requests.post(url, data=data, headers=headers, timeout=30)
            processing_time = (datetime.now() - start_time).total_seconds()
            
            if response.status_code == 200:
                result = response.json()
                
                # è®°å½•APIå“åº”è¯¦æƒ…ç”¨äºè°ƒè¯•
                logger.info(f"ç™¾åº¦OCR APIå“åº”: {result}")
                
                if "words_result" in result:
                    # æå–è¯†åˆ«çš„æ–‡å­—
                    text_lines = []
                    total_confidence = 0
                    word_count = 0
                    words_info = []
                    
                    for item in result["words_result"]:
                        words = item.get("words", "")
                        if words.strip():
                            text_lines.append(words.strip())
                            
                            # æ”¶é›†ç½®ä¿¡åº¦ä¿¡æ¯
                            if "probability" in item:
                                confidence_info = item["probability"]
                                avg_confidence = confidence_info.get("average", 0)
                                total_confidence += avg_confidence
                                word_count += 1
                                
                                words_info.append({
                                    "text": words,
                                    "confidence": avg_confidence
                                })
                    
                    full_text = "\n".join(text_lines)
                    avg_confidence = total_confidence / word_count if word_count > 0 else 0
                    
                    return OCRResult(
                        text=full_text,
                        confidence=avg_confidence / 100.0,  # è½¬æ¢ä¸º0-1èŒƒå›´
                        words_info=words_info,
                        processing_time=processing_time
                    )
                else:
                    error_msg = result.get("error_msg", "æœªçŸ¥é”™è¯¯")
                    logger.error(f"ç™¾åº¦OCRè¯†åˆ«å¤±è´¥: {error_msg}")
                    return OCRResult(text="", confidence=0.0, processing_time=processing_time)
            
            else:
                logger.error(f"ç™¾åº¦OCR APIè¯·æ±‚å¤±è´¥: {response.status_code}, {response.text}")
                return OCRResult(text="", confidence=0.0, processing_time=processing_time)
                
        except Exception as e:
            logger.error(f"ç™¾åº¦OCRè¯†åˆ«å¼‚å¸¸: {e}")
            return OCRResult(text="", confidence=0.0)

class PrescriptionOCRSystem:
    """å¤„æ–¹OCRè¯†åˆ«ä¸»ç³»ç»Ÿ - æ”¯æŒå¤šOCRæœåŠ¡å•†"""
    
    def __init__(self, primary_service='baidu'):
        """åˆå§‹åŒ–OCRç³»ç»Ÿ"""
        self.image_processor = PrescriptionImageProcessor()
        self.text_corrector = MedicalTextCorrector()
        
        # æ”¯æŒå¤šä¸ªOCRæœåŠ¡å•†
        self.ocr_services = {
            'baidu': BaiduOCRService(),
            # 'tencent': TencentOCRService(),  # å¾…æ‰©å±•
            # 'ali': AliOCRService(),          # å¾…æ‰©å±•  
        }
        self.primary_service = primary_service
        self.fallback_services = [s for s in self.ocr_services.keys() if s != primary_service]
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            "total_processed": 0,
            "success_count": 0,
            "average_confidence": 0.0,
            "average_processing_time": 0.0
        }
    
    def process_image(self, image_data: bytes, filename: str = None) -> Dict[str, Any]:
        """å¤„ç†å•å¼ å›¾ç‰‡çš„OCRè¯†åˆ«"""
        try:
            start_time = datetime.now()
            
            # 1. å¢å¼ºå›¾åƒé¢„å¤„ç†
            try:
                from enhanced_image_preprocessor import get_enhanced_image_preprocessor
                enhanced_processor = get_enhanced_image_preprocessor()
                processed_image = enhanced_processor.process_prescription_image(image_data)
                logger.info("ä½¿ç”¨å¢å¼ºå›¾åƒé¢„å¤„ç†å™¨")
            except ImportError:
                # å›é€€åˆ°åŸå§‹é¢„å¤„ç†å™¨
                processed_image = self.image_processor.preprocess_image(image_data)
                logger.info("ä½¿ç”¨åŸå§‹å›¾åƒé¢„å¤„ç†å™¨")
            
            # 2. OCRæ–‡å­—è¯†åˆ« (æ”¯æŒæœåŠ¡é™çº§)
            ocr_result = self._recognize_with_fallback(processed_image)
            
            if not ocr_result.text.strip():
                return {
                    "success": False,
                    "error": "æ— æ³•ä»å›¾ç‰‡ä¸­è¯†åˆ«åˆ°æ–‡å­—",
                    "confidence": 0.0
                }
            
            # 3. åŒ»å­¦æ–‡æœ¬çº é”™
            corrected_text, corrections = self.text_corrector.correct_medical_text(ocr_result.text)
            ocr_result.corrected_text = corrected_text
            
            # 4. æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
            self._update_stats(ocr_result)
            
            total_time = (datetime.now() - start_time).total_seconds()
            
            return {
                "success": True,
                "original_text": ocr_result.text,
                "corrected_text": ocr_result.corrected_text,
                "confidence": round(ocr_result.confidence, 3),
                "corrections_made": corrections,
                "words_info": ocr_result.words_info,
                "processing_time": round(total_time, 2),
                "filename": filename or "uploaded_image"
            }
            
        except Exception as e:
            logger.error(f"å›¾ç‰‡OCRå¤„ç†å¤±è´¥: {e}")
            return {
                "success": False,
                "error": f"å›¾ç‰‡å¤„ç†å¤±è´¥: {str(e)}",
                "confidence": 0.0
            }
    
    def process_pdf(self, pdf_data: bytes, filename: str = None) -> Dict[str, Any]:
        """å¤„ç†PDFæ–‡æ¡£çš„OCRè¯†åˆ«"""
        try:
            # 1. ä»PDFæå–å›¾åƒ
            images = self.image_processor.extract_pdf_images(pdf_data)
            
            if not images:
                return {
                    "success": False,
                    "error": "æ— æ³•ä»PDFä¸­æå–å›¾åƒ",
                    "pages": 0
                }
            
            # 2. å¤„ç†æ¯ä¸€é¡µ
            pages_result = []
            combined_text = []
            total_confidence = 0
            
            for i, image_data in enumerate(images):
                page_result = self.process_image(image_data, f"{filename}_page_{i+1}")
                pages_result.append({
                    "page": i + 1,
                    "result": page_result
                })
                
                if page_result["success"]:
                    combined_text.append(f"=== ç¬¬{i+1}é¡µ ===")
                    combined_text.append(page_result["corrected_text"])
                    total_confidence += page_result["confidence"]
            
            success_pages = len([r for r in pages_result if r["result"]["success"]])
            avg_confidence = total_confidence / success_pages if success_pages > 0 else 0
            
            return {
                "success": success_pages > 0,
                "total_pages": len(images),
                "success_pages": success_pages,
                "combined_text": "\n\n".join(combined_text),
                "pages_detail": pages_result,
                "average_confidence": round(avg_confidence, 3),
                "filename": filename or "uploaded_pdf"
            }
            
        except Exception as e:
            logger.error(f"PDF OCRå¤„ç†å¤±è´¥: {e}")
            return {
                "success": False,
                "error": f"PDFå¤„ç†å¤±è´¥: {str(e)}",
                "pages": 0
            }
    
    def _update_stats(self, ocr_result: OCRResult):
        """æ›´æ–°ç³»ç»Ÿç»Ÿè®¡ä¿¡æ¯"""
        self.stats["total_processed"] += 1
        if ocr_result.text.strip():
            self.stats["success_count"] += 1
        
        # æ›´æ–°å¹³å‡ç½®ä¿¡åº¦
        total_confidence = self.stats["average_confidence"] * (self.stats["total_processed"] - 1)
        total_confidence += ocr_result.confidence
        self.stats["average_confidence"] = total_confidence / self.stats["total_processed"]
        
        # æ›´æ–°å¹³å‡å¤„ç†æ—¶é—´
        if ocr_result.processing_time:
            total_time = self.stats["average_processing_time"] * (self.stats["total_processed"] - 1)
            total_time += ocr_result.processing_time
            self.stats["average_processing_time"] = total_time / self.stats["total_processed"]
    
    def _recognize_with_fallback(self, image_data: bytes) -> OCRResult:
        """å¸¦é™çº§çš„OCRè¯†åˆ«"""
        services_to_try = [self.primary_service] + self.fallback_services
        
        for service_name in services_to_try:
            try:
                if service_name in self.ocr_services:
                    service = self.ocr_services[service_name]
                    result = service.recognize_text(image_data)
                    
                    # å¦‚æœç½®ä¿¡åº¦è¶³å¤Ÿé«˜ï¼Œç›´æ¥è¿”å›
                    if result.confidence > 0.01:
                        logger.info(f"OCRè¯†åˆ«æˆåŠŸï¼Œä½¿ç”¨æœåŠ¡: {service_name}")
                        return result
                    
                    # ç½®ä¿¡åº¦è¾ƒä½ä½†æœ‰ç»“æœï¼Œç»§ç»­å°è¯•å…¶ä»–æœåŠ¡
                    if result.text.strip():
                        logger.info(f"{service_name} OCRç½®ä¿¡åº¦: {result.confidence} (å†…å®¹é•¿åº¦: {len(result.text)})")
                        return result  # ç›®å‰åªæœ‰ç™¾åº¦æœåŠ¡ï¼Œç›´æ¥è¿”å›
                        
            except Exception as e:
                logger.warning(f"{service_name} OCRè¯†åˆ«å¤±è´¥: {e}")
                continue
        
        # æ‰€æœ‰æœåŠ¡éƒ½å¤±è´¥ï¼Œè¿”å›ç©ºç»“æœ
        logger.error("æ‰€æœ‰OCRæœåŠ¡éƒ½å¤±è´¥")
        return OCRResult(text="", confidence=0.0)
    

    def _assess_content_quality(self, text: str) -> float:
        """è¯„ä¼°OCRè¯†åˆ«å†…å®¹çš„è´¨é‡"""
        if not text.strip():
            return 0.0
        
        quality_score = 0.0
        
        # 1. ä¸­æ–‡å­—ç¬¦æ¯”ä¾‹
        chinese_chars = len([c for c in text if '\u4e00' <= c <= '\u9fff'])
        if len(text) > 0:
            chinese_ratio = chinese_chars / len(text)
            quality_score += chinese_ratio * 0.3
        
        # 2. åŒ»å­¦ç›¸å…³å…³é”®è¯
        medical_keywords = ['å…‹', 'g', 'å‡€', 'å¸–', 'å‰‚', 'æœ', 'æ–¹', 'è¯', 'æ²»', 'ç—‡']
        keyword_count = sum(1 for kw in medical_keywords if kw in text)
        quality_score += min(keyword_count / 5, 1.0) * 0.3
        
        # 3. æ•°å­—å’Œå‰‚é‡ä¿¡æ¯
        if re.search(r'\d+(?:\.\d+)?\s*[å…‹g]', text):
            quality_score += 0.2
        
        # 4. ä¸­è¯åç§°æ¨¡å¼
        herb_patterns = [
            r'[ä¸€-é¾¯]{2,4}ï¼ˆå‡€ï¼‰',  # å¦‚ï¼šæ¡”æ¢—ï¼ˆå‡€ï¼‰
            r'[ä¸€-é¾¯]{2,4}\s*\d+[å…‹g]',  # å¦‚ï¼šç”˜è‰ 6å…‹
            r'ç‚’[ä¸€-é¾¯]{2,4}',  # å¦‚ï¼šç‚’è±è”å­
        ]
        for pattern in herb_patterns:
            if re.search(pattern, text):
                quality_score += 0.1
        
        # 5. æ–‡æœ¬é•¿åº¦åˆç†æ€§
        if 50 <= len(text) <= 2000:
            quality_score += 0.1
        
        return min(quality_score, 1.0)
    def switch_primary_service(self, service_name: str):
        """åˆ‡æ¢ä¸»è¦OCRæœåŠ¡"""
        if service_name in self.ocr_services:
            self.primary_service = service_name
            self.fallback_services = [s for s in self.ocr_services.keys() if s != service_name]
            logger.info(f"ä¸»OCRæœåŠ¡å·²åˆ‡æ¢è‡³: {service_name}")
            return True
        return False

    def get_system_stats(self) -> Dict[str, Any]:
        """è·å–ç³»ç»Ÿç»Ÿè®¡ä¿¡æ¯"""
        return {
            "total_processed": self.stats["total_processed"],
            "success_count": self.stats["success_count"],
            "success_rate": round(self.stats["success_count"] / max(1, self.stats["total_processed"]), 3),
            "average_confidence": round(self.stats["average_confidence"], 3),
            "average_processing_time": round(self.stats["average_processing_time"], 2),
            "primary_service": self.primary_service,
            "available_services": list(self.ocr_services.keys())
        }

# å…¨å±€OCRç³»ç»Ÿå®ä¾‹
ocr_system = None

def get_ocr_system():
    """è·å–å…¨å±€OCRç³»ç»Ÿå®ä¾‹"""
    global ocr_system
    if ocr_system is None:
        ocr_system = PrescriptionOCRSystem()
    return ocr_system

# æµ‹è¯•å‡½æ•°
def test_ocr_system():
    """æµ‹è¯•OCRç³»ç»ŸåŠŸèƒ½"""
    print("=== æµ‹è¯•å¤„æ–¹OCRè¯†åˆ«ç³»ç»Ÿ ===")
    
    ocr = get_ocr_system()
    
    # æµ‹è¯•å›¾åƒé¢„å¤„ç†
    processor = PrescriptionImageProcessor()
    print(f"âœ… å›¾åƒå¤„ç†å™¨åˆå§‹åŒ–æˆåŠŸ")
    print(f"   æ”¯æŒæ ¼å¼: {processor.supported_formats}")
    print(f"   æœ€å¤§å°ºå¯¸: {processor.max_size}")
    
    # æµ‹è¯•åŒ»å­¦æ–‡æœ¬çº é”™
    corrector = MedicalTextCorrector()
    test_text = "ç•¶å¸° 12å…Ÿï¼Œé»„èŠª 15å…‹ï¼Œäººè”˜ 9gï¼Œç™½æœ® 10gï¼Œæ°´å‰æœ"
    corrected, corrections = corrector.correct_medical_text(test_text)
    print(f"\nâœ… åŒ»å­¦æ–‡æœ¬çº é”™æµ‹è¯•:")
    print(f"   åŸæ–‡: {test_text}")
    print(f"   çº é”™: {corrected}")
    print(f"   ä¿®æ­£: {corrections}")
    
    # æ˜¾ç¤ºç³»ç»Ÿç»Ÿè®¡
    stats = ocr.get_system_stats()
    print(f"\nğŸ“Š ç³»ç»Ÿç»Ÿè®¡: {stats}")
    
    print("\nğŸš€ OCRç³»ç»Ÿåˆå§‹åŒ–å®Œæˆï¼Œç­‰å¾…APIé›†æˆ...")

if __name__ == "__main__":
    test_ocr_system()