#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
main.pyæ–‡ä»¶ç»“æ„åˆ†æå·¥å…·
åˆ†æä»£ç ç»“æ„ã€é‡å¤å‡½æ•°ã€æ¨¡å—åŒ–é‡æ„æœºä¼š
"""

import ast
import re
import sys
from typing import Dict, List, Tuple, Set
from collections import defaultdict, Counter

class MainPyAnalyzer:
    """main.pyæ–‡ä»¶åˆ†æå™¨"""
    
    def __init__(self, file_path: str):
        self.file_path = file_path
        self.content = ""
        self.lines = []
        self.functions = {}
        self.classes = {}
        self.imports = []
        self.duplicates = []
        self.code_blocks = {}
        
    def load_file(self):
        """åŠ è½½æ–‡ä»¶å†…å®¹"""
        with open(self.file_path, 'r', encoding='utf-8') as f:
            self.content = f.read()
            self.lines = self.content.split('\n')
        print(f"ğŸ“„ æ–‡ä»¶åŠ è½½å®Œæˆ: {len(self.lines)}è¡Œä»£ç ")
    
    def analyze_structure(self):
        """åˆ†ææ–‡ä»¶ç»“æ„"""
        print("\nğŸ” åˆ†ææ–‡ä»¶ç»“æ„")
        print("=" * 50)
        
        # ç»Ÿè®¡åŸºæœ¬ä¿¡æ¯
        total_lines = len(self.lines)
        empty_lines = sum(1 for line in self.lines if not line.strip())
        comment_lines = sum(1 for line in self.lines if line.strip().startswith('#'))
        code_lines = total_lines - empty_lines - comment_lines
        
        print(f"ğŸ“Š åŸºæœ¬ç»Ÿè®¡:")
        print(f"   æ€»è¡Œæ•°: {total_lines}")
        print(f"   ä»£ç è¡Œ: {code_lines}")
        print(f"   æ³¨é‡Šè¡Œ: {comment_lines}")
        print(f"   ç©ºè¡Œ: {empty_lines}")
        print(f"   ä»£ç å¯†åº¦: {code_lines/total_lines:.1%}")
        
        # åˆ†æAST
        try:
            tree = ast.parse(self.content)
            self._analyze_ast(tree)
        except SyntaxError as e:
            print(f"âŒ ASTè§£æå¤±è´¥: {e}")
    
    def _analyze_ast(self, tree):
        """åˆ†æASTç»“æ„"""
        for node in ast.walk(tree):
            if isinstance(node, ast.FunctionDef):
                func_info = {
                    'name': node.name,
                    'line': node.lineno,
                    'lines': node.end_lineno - node.lineno + 1 if hasattr(node, 'end_lineno') else 'unknown',
                    'args': len(node.args.args),
                    'docstring': ast.get_docstring(node),
                    'is_async': False
                }
                self.functions[node.name] = func_info
                
            elif isinstance(node, ast.AsyncFunctionDef):
                func_info = {
                    'name': node.name,
                    'line': node.lineno,
                    'lines': node.end_lineno - node.lineno + 1 if hasattr(node, 'end_lineno') else 'unknown',
                    'args': len(node.args.args),
                    'docstring': ast.get_docstring(node),
                    'is_async': True
                }
                self.functions[node.name] = func_info
                
            elif isinstance(node, ast.ClassDef):
                class_info = {
                    'name': node.name,
                    'line': node.lineno,
                    'lines': node.end_lineno - node.lineno + 1 if hasattr(node, 'end_lineno') else 'unknown',
                    'methods': [n.name for n in node.body if isinstance(n, (ast.FunctionDef, ast.AsyncFunctionDef))]
                }
                self.classes[node.name] = class_info
                
            elif isinstance(node, ast.Import):
                for alias in node.names:
                    self.imports.append(('import', alias.name, node.lineno))
                    
            elif isinstance(node, ast.ImportFrom):
                module = node.module if node.module else ''
                for alias in node.names:
                    self.imports.append(('from', f"{module}.{alias.name}", node.lineno))
    
    def analyze_functions(self):
        """åˆ†æå‡½æ•°è¯¦æƒ…"""
        print(f"\nğŸ”§ å‡½æ•°åˆ†æ (å…±{len(self.functions)}ä¸ªå‡½æ•°)")
        print("=" * 50)
        
        # æŒ‰è¡Œæ•°æ’åº
        sorted_functions = sorted(self.functions.items(), key=lambda x: x[1].get('lines', 0), reverse=True)
        
        print("ğŸ“‹ æœ€å¤§çš„å‡½æ•° (Top 10):")
        for i, (name, info) in enumerate(sorted_functions[:10], 1):
            lines = info.get('lines', 'unknown')
            line_no = info['line']
            is_async = " (async)" if info['is_async'] else ""
            print(f"   {i:2d}. {name}{is_async}: {lines}è¡Œ (ç¬¬{line_no}è¡Œ)")
        
        # ç»Ÿè®¡å‡½æ•°ç±»å‹
        sync_funcs = sum(1 for f in self.functions.values() if not f['is_async'])
        async_funcs = sum(1 for f in self.functions.values() if f['is_async'])
        
        print(f"\nğŸ“Š å‡½æ•°ç±»å‹åˆ†å¸ƒ:")
        print(f"   åŒæ­¥å‡½æ•°: {sync_funcs}")
        print(f"   å¼‚æ­¥å‡½æ•°: {async_funcs}")
        
        # åˆ†æå‡½æ•°èŒè´£
        self._analyze_function_responsibilities()
    
    def _analyze_function_responsibilities(self):
        """åˆ†æå‡½æ•°èŒè´£"""
        print(f"\nğŸ¯ å‡½æ•°èŒè´£åˆ†æ:")
        
        categories = {
            'APIç«¯ç‚¹': [],
            'æ•°æ®å¤„ç†': [],
            'å·¥å…·å‡½æ•°': [],
            'å®‰å…¨æ£€æŸ¥': [],
            'å›¾åƒå¤„ç†': [],
            'æ•°æ®åº“æ“ä½œ': [],
            'AIè°ƒç”¨': [],
            'å…¶ä»–': []
        }
        
        for name, info in self.functions.items():
            if name.startswith('get_') or name.startswith('post_') or 'endpoint' in name.lower():
                categories['APIç«¯ç‚¹'].append(name)
            elif 'extract' in name or 'parse' in name or 'process' in name:
                categories['æ•°æ®å¤„ç†'].append(name)
            elif 'check' in name or 'validate' in name or 'sanitize' in name or 'safety' in name:
                categories['å®‰å…¨æ£€æŸ¥'].append(name)
            elif 'image' in name or 'picture' in name or 'multimodal' in name:
                categories['å›¾åƒå¤„ç†'].append(name)
            elif 'database' in name or 'db_' in name or 'search' in name:
                categories['æ•°æ®åº“æ“ä½œ'].append(name)
            elif 'llm' in name or 'ai_' in name or 'model' in name:
                categories['AIè°ƒç”¨'].append(name)
            elif len(name) < 15 and not name.startswith('_'):
                categories['å·¥å…·å‡½æ•°'].append(name)
            else:
                categories['å…¶ä»–'].append(name)
        
        for category, functions in categories.items():
            if functions:
                print(f"   {category}: {len(functions)}ä¸ª")
                for func in functions[:3]:  # åªæ˜¾ç¤ºå‰3ä¸ª
                    print(f"      â€¢ {func}")
                if len(functions) > 3:
                    print(f"      ... è¿˜æœ‰{len(functions)-3}ä¸ª")
    
    def find_duplicate_code(self):
        """æŸ¥æ‰¾é‡å¤ä»£ç """
        print(f"\nğŸ”„ é‡å¤ä»£ç åˆ†æ")
        print("=" * 50)
        
        # æŸ¥æ‰¾é‡å¤çš„å‡½æ•°åæ¨¡å¼
        self._find_similar_function_names()
        
        # æŸ¥æ‰¾é‡å¤çš„ä»£ç å—
        self._find_duplicate_blocks()
        
        # æŸ¥æ‰¾é‡å¤çš„å¯¼å…¥
        self._find_duplicate_imports()
    
    def _find_similar_function_names(self):
        """æŸ¥æ‰¾ç›¸ä¼¼çš„å‡½æ•°å"""
        print("ğŸ” ç›¸ä¼¼å‡½æ•°ååˆ†æ:")
        
        # æŒ‰åŠŸèƒ½åˆ†ç»„
        groups = defaultdict(list)
        for name in self.functions.keys():
            if 'extract' in name:
                groups['extract'].append(name)
            elif 'check' in name or 'validate' in name:
                groups['validation'].append(name)
            elif 'sanitize' in name or 'clean' in name:
                groups['sanitization'].append(name)
            elif 'get_' in name:
                groups['getters'].append(name)
            elif 'process' in name:
                groups['processing'].append(name)
        
        for group_name, functions in groups.items():
            if len(functions) > 1:
                print(f"   {group_name.upper()}ç±»å‡½æ•°: {len(functions)}ä¸ª")
                for func in functions:
                    print(f"      â€¢ {func}")
    
    def _find_duplicate_blocks(self):
        """æŸ¥æ‰¾é‡å¤ä»£ç å—"""
        print(f"\nğŸ”„ ä»£ç å—é‡å¤åˆ†æ:")
        
        # ç®€å•çš„é‡å¤æ¨¡å¼æ£€æµ‹
        patterns = {
            'try-except-logger': 0,
            'if-not-available': 0,
            'response-status-check': 0,
            'temp-file-creation': 0,
            'ai-response-validation': 0
        }
        
        content_lower = self.content.lower()
        
        patterns['try-except-logger'] = content_lower.count('try:') + content_lower.count('except') + content_lower.count('logger.')
        patterns['temp-file-creation'] = content_lower.count('tempfile') + content_lower.count('tmp_file')
        patterns['response-status-check'] = content_lower.count('status_code') + content_lower.count('response.')
        patterns['ai-response-validation'] = content_lower.count('ai_response') + content_lower.count('validate')
        
        print("   å¸¸è§ä»£ç æ¨¡å¼å‡ºç°é¢‘ç‡:")
        for pattern, count in patterns.items():
            if count > 5:  # åªæ˜¾ç¤ºé¢‘ç¹å‡ºç°çš„æ¨¡å¼
                print(f"      {pattern}: {count}æ¬¡")
    
    def _find_duplicate_imports(self):
        """æŸ¥æ‰¾é‡å¤å¯¼å…¥"""
        print(f"\nğŸ“¦ å¯¼å…¥åˆ†æ (å…±{len(self.imports)}ä¸ªå¯¼å…¥):")
        
        # ç»Ÿè®¡å¯¼å…¥ç±»å‹
        import_types = Counter()
        modules = Counter()
        
        for import_type, module, line in self.imports:
            import_types[import_type] += 1
            base_module = module.split('.')[0]
            modules[base_module] += 1
        
        print("   å¯¼å…¥ç±»å‹åˆ†å¸ƒ:")
        for import_type, count in import_types.most_common():
            print(f"      {import_type}: {count}æ¬¡")
        
        print("   ä¸»è¦æ¨¡å—:")
        for module, count in modules.most_common(10):
            print(f"      {module}: {count}æ¬¡")
    
    def suggest_refactoring(self):
        """ç”Ÿæˆé‡æ„å»ºè®®"""
        print(f"\nğŸ’¡ é‡æ„å»ºè®®")
        print("=" * 50)
        
        suggestions = []
        
        # åŸºäºæ–‡ä»¶å¤§å°çš„å»ºè®®
        if len(self.lines) > 3000:
            suggestions.append("ğŸ”¥ æ–‡ä»¶è¿‡å¤§ (>3000è¡Œ)ï¼Œå¼ºçƒˆå»ºè®®æ‹†åˆ†")
        elif len(self.lines) > 1500:
            suggestions.append("âš ï¸ æ–‡ä»¶è¾ƒå¤§ (>1500è¡Œ)ï¼Œå»ºè®®è€ƒè™‘æ‹†åˆ†")
        
        # åŸºäºå‡½æ•°æ•°é‡çš„å»ºè®®
        if len(self.functions) > 50:
            suggestions.append("ğŸ”§ å‡½æ•°è¿‡å¤šï¼Œå»ºè®®æŒ‰åŠŸèƒ½åˆ†ç»„åˆ°ä¸åŒæ¨¡å—")
        
        # åŸºäºå¤§å‡½æ•°çš„å»ºè®®
        large_functions = [name for name, info in self.functions.items() 
                          if isinstance(info.get('lines'), int) and info['lines'] > 100]
        if large_functions:
            suggestions.append(f"ğŸ“ å‘ç°{len(large_functions)}ä¸ªå¤§å‡½æ•° (>100è¡Œ)ï¼Œå»ºè®®æ‹†åˆ†")
        
        # åŸºäºèŒè´£çš„å»ºè®®
        api_funcs = [name for name in self.functions.keys() if 'get_' in name or 'post_' in name]
        if len(api_funcs) > 10:
            suggestions.append("ğŸŒ APIç«¯ç‚¹è¿‡å¤šï¼Œå»ºè®®ä½¿ç”¨è·¯ç”±åˆ†ç¦»")
        
        # ç”Ÿæˆå…·ä½“çš„é‡æ„è®¡åˆ’
        refactor_plan = self._generate_refactor_plan()
        
        print("ğŸ“‹ é‡æ„ä¼˜å…ˆçº§:")
        for i, suggestion in enumerate(suggestions, 1):
            print(f"   {i}. {suggestion}")
        
        if refactor_plan:
            print(f"\nğŸ—ºï¸ å»ºè®®çš„æ¨¡å—æ‹†åˆ†æ–¹æ¡ˆ:")
            for module_name, functions in refactor_plan.items():
                print(f"   ğŸ“¦ {module_name}: {len(functions)}ä¸ªå‡½æ•°")
                for func in functions[:3]:
                    print(f"      â€¢ {func}")
                if len(functions) > 3:
                    print(f"      ... è¿˜æœ‰{len(functions)-3}ä¸ª")
    
    def _generate_refactor_plan(self):
        """ç”Ÿæˆé‡æ„è®¡åˆ’"""
        plan = {
            'api_routes.py': [],
            'data_processors.py': [],
            'security_validators.py': [],
            'multimodal_handlers.py': [],
            'database_operations.py': [],
            'ai_integrations.py': [],
            'utils.py': []
        }
        
        for name, info in self.functions.items():
            if any(keyword in name.lower() for keyword in ['get_', 'post_', 'endpoint']):
                plan['api_routes.py'].append(name)
            elif any(keyword in name.lower() for keyword in ['extract', 'parse', 'process']):
                plan['data_processors.py'].append(name)
            elif any(keyword in name.lower() for keyword in ['check', 'validate', 'sanitize', 'safety']):
                plan['security_validators.py'].append(name)
            elif any(keyword in name.lower() for keyword in ['image', 'multimodal', 'picture']):
                plan['multimodal_handlers.py'].append(name)
            elif any(keyword in name.lower() for keyword in ['search', 'database', 'db_']):
                plan['database_operations.py'].append(name)
            elif any(keyword in name.lower() for keyword in ['llm', 'ai_', 'model']):
                plan['ai_integrations.py'].append(name)
            else:
                plan['utils.py'].append(name)
        
        # ç§»é™¤ç©ºæ¨¡å—
        return {k: v for k, v in plan.items() if v}
    
    def generate_report(self):
        """ç”Ÿæˆåˆ†ææŠ¥å‘Š"""
        report = {
            'file_info': {
                'path': self.file_path,
                'total_lines': len(self.lines),
                'functions_count': len(self.functions),
                'classes_count': len(self.classes),
                'imports_count': len(self.imports)
            },
            'functions': dict(self.functions),
            'classes': dict(self.classes),
            'refactor_suggestions': self._generate_refactor_plan(),
            'analysis_timestamp': '2025-08-19T15:50:00'
        }
        
        # ä¿å­˜æŠ¥å‘Š
        import json
        with open('/opt/tcm-ai/template_files/main_py_analysis_report.json', 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ“„ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜è‡³: /opt/tcm-ai/template_files/main_py_analysis_report.json")
        return report
    
    def run_analysis(self):
        """è¿è¡Œå®Œæ•´åˆ†æ"""
        print("ğŸš€ å¼€å§‹main.pyæ–‡ä»¶ç»“æ„åˆ†æ")
        print("=" * 80)
        
        self.load_file()
        self.analyze_structure() 
        self.analyze_functions()
        self.find_duplicate_code()
        self.suggest_refactoring()
        
        return self.generate_report()

def main():
    analyzer = MainPyAnalyzer('/opt/tcm-ai/api/main.py')
    report = analyzer.run_analysis()
    
    print(f"\nğŸ¯ åˆ†ææ€»ç»“:")
    print(f"   æ–‡ä»¶å¤§å°: {report['file_info']['total_lines']}è¡Œ")
    print(f"   å‡½æ•°æ•°é‡: {report['file_info']['functions_count']}ä¸ª")
    print(f"   å»ºè®®æ‹†åˆ†: {len(report['refactor_suggestions'])}ä¸ªæ¨¡å—")
    print(f"\nâœ… åˆ†æå®Œæˆï¼Œå¯ä»¥å¼€å§‹é‡æ„è§„åˆ’")

if __name__ == "__main__":
    main()