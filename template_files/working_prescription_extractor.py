#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å·¥ä½œç‰ˆæœ¬çš„å¤„æ–¹æå–å™¨
åŸºäºè°ƒè¯•ç»“æœä¼˜åŒ–çš„æ­£åˆ™è¡¨è¾¾å¼
"""

import sys
import re
import json
from docx import Document
from typing import Dict, List, Any
import logging

sys.path.append('/opt/tcm-ai')

logger = logging.getLogger(__name__)

class WorkingPrescriptionExtractor:
    """åŸºäºå®é™…æ ¼å¼çš„å¤„æ–¹æå–å™¨"""
    
    def __init__(self):
        # å¸¸è§ä¸­è¯åï¼ˆåŒ…æ‹¬å¸¦ç©ºæ ¼çš„ç‰ˆæœ¬ï¼‰
        self.common_herbs = {
            'ç”˜è‰', 'ç”Ÿå§œ', 'å¤§æ£', 'éº»é»„', 'æ¡‚æ', 'ç™½èŠ', 'æä»', 'çŸ³è†',
            'é»„èŠ©', 'æŸ´èƒ¡', 'åŠå¤', 'é™ˆçš®', 'èŒ¯è‹“', 'ç™½æœ¯', 'äººå‚', 'å½“å½’',
            'å·èŠ', 'ç†Ÿåœ°', 'ç”Ÿåœ°', 'çŸ¥æ¯', 'è¿ç¿˜', 'é‡‘é“¶èŠ±', 'æ¿è“æ ¹',
            'æ¡”æ¢—', 'è–„è·', 'è†èŠ¥', 'é˜²é£', 'ç¾Œæ´»', 'ç‹¬æ´»', 'è‘›æ ¹', 'å‡éº»',
            'å‰èƒ¡', 'ç´«è‹', 'è—¿é¦™', 'ä½©å…°', 'è‹æœ¯', 'åšæœ´', 'æ³å£³', 'æœ¨é¦™',
            'ç‰›è’¡å­', 'ç«¹å¶', 'è±†è±‰', 'æ²™å‚', 'æµ™è´æ¯', 'éº¦å†¬', 'æ €å­',
            'æ¡‘å¶', 'æ¡‘ç™½çš®', 'è‹è€³å­', 'ç™½å‰', 'è±è”å­', 'å±±è±†æ ¹',
            'å°„å¹²', 'èŠèŠ±', 'è”“è†å­', 'èŒ…æ ¹', 'è‘›æ ¹', 'é»„èŠ©', 'è¿ç¿˜',
            'ä¾§æŸå¶', 'ä¸‰ä¸ƒ', 'ç“œè’Œ', 'ä¸¹çš®', 'è¾›å¤·', 'å…šå‚', 'é»„èŠª'
        }

    def extract_herbs_from_paragraph(self, para_text: str) -> List[Dict[str, str]]:
        """ä»æ®µè½ä¸­æå–è¯ç‰©ä¿¡æ¯"""
        herbs = []
        
        # å…ˆå¤„ç†æ˜æ˜¾çš„å¤„æ–¹æ ¼å¼
        # æ¨¡å¼1: "è† èŠ¥ 6 å…‹" (ç©ºæ ¼åˆ†éš”çš„è¯åå’Œå‰‚é‡)
        pattern1 = r'([\u4e00-\u9fff]\s*[\u4e00-\u9fff](?:\s*[\u4e00-\u9fff])?(?:\s*[\u4e00-\u9fff])?)\s*(\d+(?:\.\d+)?)\s*å…‹'
        matches1 = re.findall(pattern1, para_text)
        
        for herb_name, dose in matches1:
            clean_name = re.sub(r'\s+', '', herb_name)  # å»é™¤ç©ºæ ¼
            if self._is_valid_herb(clean_name):
                herbs.append({
                    'name': clean_name,
                    'dose': dose,
                    'unit': 'å…‹'
                })
        
        # æ¨¡å¼2: "æŸ´èƒ¡6å…‹" (æ— ç©ºæ ¼çš„è¯åå’Œå‰‚é‡)
        pattern2 = r'([\u4e00-\u9fff]{2,4})(\d+(?:\.\d+)?)å…‹'
        matches2 = re.findall(pattern2, para_text)
        
        for herb_name, dose in matches2:
            if self._is_valid_herb(herb_name):
                # é¿å…é‡å¤æ·»åŠ 
                if not any(h['name'] == herb_name for h in herbs):
                    herbs.append({
                        'name': herb_name,
                        'dose': dose,
                        'unit': 'å…‹'
                    })
        
        # æ¨¡å¼3: å¤„ç†ç‰¹æ®Šæ ¼å¼å¦‚ "æ¿ è“ æ ¹ 1 5 å…‹" (å‰‚é‡ä¹Ÿè¢«åˆ†éš”)
        pattern3 = r'([\u4e00-\u9fff](?:\s*[\u4e00-\u9fff]){1,3})\s*(\d+(?:\s+\d+)?)\s*å…‹'
        matches3 = re.findall(pattern3, para_text)
        
        for herb_name, dose in matches3:
            clean_name = re.sub(r'\s+', '', herb_name)
            clean_dose = re.sub(r'\s+', '', dose)  # å»é™¤å‰‚é‡ä¸­çš„ç©ºæ ¼
            if self._is_valid_herb(clean_name):
                # é¿å…é‡å¤æ·»åŠ 
                if not any(h['name'] == clean_name for h in herbs):
                    herbs.append({
                        'name': clean_name,
                        'dose': clean_dose,
                        'unit': 'å…‹'
                    })
        
        return herbs

    def _is_valid_herb(self, herb_name: str) -> bool:
        """éªŒè¯æ˜¯å¦ä¸ºæœ‰æ•ˆè¯å"""
        # åœ¨å¸¸è§ä¸­è¯åˆ—è¡¨ä¸­
        if herb_name in self.common_herbs:
            return True
        
        # é•¿åº¦åˆç†ä¸”ä¸åŒ…å«æ˜æ˜¾çš„éè¯åè¯æ±‡
        if 2 <= len(herb_name) <= 6:
            invalid_words = ['æ‚£è€…', 'åŒ»ç”Ÿ', 'æ²»ç–—', 'æ–¹æ³•', 'æ¯æ—¥', 'æœç”¨', 'å‰‚é‡', 'æ—¶é—´', 'åŠ å‡']
            if not any(word in herb_name for word in invalid_words):
                return True
        
        return False

    def extract_text_from_docx(self, docx_path: str) -> List[str]:
        """æå–æ–‡æ¡£æ–‡æœ¬ï¼Œä¿æŒæ®µè½ç»“æ„"""
        try:
            doc = Document(docx_path)
            paragraphs = []
            
            for para in doc.paragraphs:
                text = para.text.strip()
                if text:
                    paragraphs.append(text)
            
            return paragraphs
        except Exception as e:
            logger.error(f"æå–æ–‡æ¡£å¤±è´¥: {e}")
            return []

    def find_prescription_paragraphs(self, paragraphs: List[str]) -> List[Dict[str, Any]]:
        """æ‰¾åˆ°åŒ…å«å¤„æ–¹çš„æ®µè½"""
        prescription_paragraphs = []
        
        for i, para in enumerate(paragraphs):
            # æå–è¯ç‰©ä¿¡æ¯
            herbs = self.extract_herbs_from_paragraph(para)
            
            # å¦‚æœåŒ…å«3ä¸ªä»¥ä¸Šæœ‰æ•ˆè¯ç‰©ï¼Œè®¤ä¸ºæ˜¯å¤„æ–¹æ®µè½
            if len(herbs) >= 3:
                prescription_paragraphs.append({
                    'paragraph_index': i + 1,
                    'text': para,
                    'herbs': herbs,
                    'herb_count': len(herbs)
                })
        
        return prescription_paragraphs

    def extract_context_info(self, paragraphs: List[str], prescription_para_index: int) -> Dict[str, Any]:
        """æå–å¤„æ–¹å‰åçš„ä¸Šä¸‹æ–‡ä¿¡æ¯"""
        context_info = {
            'syndrome': '',
            'treatment_method': '',
            'formula_name': '',
            'usage': ''
        }
        
        # æœç´¢å‰å5ä¸ªæ®µè½
        start_idx = max(0, prescription_para_index - 5)
        end_idx = min(len(paragraphs), prescription_para_index + 5)
        
        context_text = ' '.join(paragraphs[start_idx:end_idx])
        
        # æå–è¯å‹/ç—…ç—‡
        syndrome_patterns = [
            r'(é£å¯’æ„Ÿå†’)', r'(é£çƒ­æ„Ÿå†’)', r'(å¤–æ„Ÿé£å¯’)', r'(å¤–æ„Ÿé£çƒ­)',
            r'(é£å¯’æŸè¡¨)', r'(é£çƒ­çŠ¯è‚º)', r'(ç—°æ¹¿å’³å—½)', r'(é˜´è™šç«æ—º)',
            r'(è‚ºçƒ­å’³å—½)', r'(è„¾è™šæ¹¿ç››)'
        ]
        
        for pattern in syndrome_patterns:
            match = re.search(pattern, context_text)
            if match:
                context_info['syndrome'] = match.group(1)
                break
        
        # æå–æ²»æ³•
        treatment_patterns = [
            r'æ²»æ³•[ï¼š:]([^ã€‚\n]{5,30})',
            r'(ç–é£æ•£å¯’)', r'(è¾›æ¸©è§£è¡¨)', r'(æ¸…çƒ­è§£æ¯’)', r'(è¾›å‡‰è§£è¡¨)',
            r'(å®£è‚ºæ­¢å’³)', r'(åŒ–ç—°æ­¢å’³)', r'(æ¶¦è‚ºæ­¢å’³)'
        ]
        
        for pattern in treatment_patterns:
            match = re.search(pattern, context_text)
            if match:
                context_info['treatment_method'] = match.group(1)
                break
        
        # æå–æ–¹å‰‚å
        formula_match = re.search(r'([\u4e00-\u9fff]{2,8}[æ±¤æ•£ä¸¸è†é¥®æ–¹])', context_text)
        if formula_match:
            context_info['formula_name'] = formula_match.group(1)
        
        # æå–ç”¨æ³•
        usage_patterns = [
            r'(æ°´ç…[åˆ†æœ])', r'(æ¯æ—¥[ä¸€äºŒä¸‰]å‰‚)', r'(åˆ†[äºŒä¸‰]æ¬¡[æ¸©]?æœ)',
            r'(ç…æœ)', r'(æ¸©æœ)'
        ]
        
        for pattern in usage_patterns:
            match = re.search(pattern, context_text)
            if match:
                context_info['usage'] = match.group(1)
                break
        
        return context_info

    def process_document(self, docx_path: str) -> Dict[str, Any]:
        """å¤„ç†æ–‡æ¡£æå–å¤„æ–¹ä¿¡æ¯"""
        result = {
            'success': False,
            'filename': docx_path.split('/')[-1],
            'total_prescriptions': 0,
            'prescriptions': [],
            'error_message': ''
        }
        
        try:
            # æå–æ®µè½
            paragraphs = self.extract_text_from_docx(docx_path)
            if not paragraphs:
                result['error_message'] = "æ— æ³•æå–æ–‡æ¡£å†…å®¹"
                return result
            
            # æ‰¾åˆ°å¤„æ–¹æ®µè½
            prescription_paragraphs = self.find_prescription_paragraphs(paragraphs)
            
            if not prescription_paragraphs:
                result['error_message'] = "æœªæ‰¾åˆ°å¤„æ–¹ä¿¡æ¯"
                return result
            
            # ä¸ºæ¯ä¸ªå¤„æ–¹æ®µè½æå–å®Œæ•´ä¿¡æ¯
            for i, presc_para in enumerate(prescription_paragraphs):
                context_info = self.extract_context_info(paragraphs, presc_para['paragraph_index'])
                
                prescription = {
                    'prescription_id': i + 1,
                    'syndrome': context_info['syndrome'],
                    'treatment_method': context_info['treatment_method'],
                    'formula_name': context_info['formula_name'] or f"å¤„æ–¹{i+1}",
                    'herbs': presc_para['herbs'],
                    'herb_count': presc_para['herb_count'],
                    'usage': context_info['usage'],
                    'source_paragraph': presc_para['paragraph_index'],
                    'source_text': presc_para['text'][:200] + '...' if len(presc_para['text']) > 200 else presc_para['text']
                }
                
                result['prescriptions'].append(prescription)
            
            result['total_prescriptions'] = len(prescription_paragraphs)
            result['success'] = True
            
        except Exception as e:
            result['error_message'] = str(e)
            logger.error(f"å¤„ç†æ–‡æ¡£å¤±è´¥: {e}")
        
        return result

def test_working_extractor():
    """æµ‹è¯•å·¥ä½œç‰ˆæœ¬æå–å™¨"""
    extractor = WorkingPrescriptionExtractor()
    
    test_files = [
        '/opt/tcm-ai/all_tcm_docs/æ„Ÿå†’.docx',
        '/opt/tcm-ai/all_tcm_docs/å’³å—½.docx'
    ]
    
    print("ğŸ”¬ æµ‹è¯•å·¥ä½œç‰ˆæœ¬çš„å¤„æ–¹æå–å™¨")
    print("=" * 60)
    
    all_results = []
    
    for test_file in test_files:
        print(f"\nğŸ“„ å¤„ç†: {test_file.split('/')[-1]}")
        result = extractor.process_document(test_file)
        all_results.append(result)
        
        if result['success']:
            print(f"âœ… æˆåŠŸæå– {result['total_prescriptions']} ä¸ªå¤„æ–¹")
            
            # æ˜¾ç¤ºæ¯ä¸ªå¤„æ–¹çš„è¯¦ç»†ä¿¡æ¯
            for i, prescription in enumerate(result['prescriptions']):
                print(f"\nğŸ“‹ å¤„æ–¹{i+1} (æ¥æºæ®µè½{prescription['source_paragraph']}):")
                print(f"   æ–¹å‰‚åç§°: {prescription['formula_name']}")
                if prescription['syndrome']:
                    print(f"   è¯å‹: {prescription['syndrome']}")
                if prescription['treatment_method']:
                    print(f"   æ²»æ³•: {prescription['treatment_method']}")
                print(f"   è¯ç‰©ç»„æˆ({prescription['herb_count']}å‘³):")
                for herb in prescription['herbs']:
                    print(f"     â€¢ {herb['name']} {herb['dose']}{herb['unit']}")
                if prescription['usage']:
                    print(f"   ç”¨æ³•: {prescription['usage']}")
                print(f"   åŸæ–‡: {prescription['source_text']}")
        else:
            print(f"âŒ å¤±è´¥: {result['error_message']}")
    
    # ä¿å­˜ç»“æœ
    if any(r['success'] for r in all_results):
        with open('/opt/tcm-ai/template_files/working_extraction_results.json', 'w', encoding='utf-8') as f:
            json.dump(all_results, f, ensure_ascii=False, indent=2)
        print(f"\nğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: working_extraction_results.json")
    
    # ç”Ÿæˆæ€»ç»“
    total_prescriptions = sum(r['total_prescriptions'] for r in all_results if r['success'])
    print(f"\nğŸ“Š æ€»ç»“:")
    print(f"   æˆåŠŸå¤„ç†æ–‡æ¡£: {sum(1 for r in all_results if r['success'])}/{len(all_results)}")
    print(f"   æ€»æå–å¤„æ–¹æ•°: {total_prescriptions}")
    
    return all_results

if __name__ == "__main__":
    test_working_extractor()