#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é‡æ„åç³»ç»ŸåŠŸèƒ½æµ‹è¯•
éªŒè¯æ¨¡å—åŒ–é‡æ„æ˜¯å¦æˆåŠŸï¼Œæ‰€æœ‰åŠŸèƒ½æ˜¯å¦æ­£å¸¸
"""

import sys
import os
import asyncio
import json
from datetime import datetime
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, '/opt/tcm-ai')
sys.path.insert(0, '/opt/tcm-ai/api')

def test_module_imports():
    """æµ‹è¯•æ¨¡å—å¯¼å…¥"""
    print("=" * 60)
    print("1. æµ‹è¯•æ¨¡å—å¯¼å…¥")
    print("-" * 40)
    
    try:
        # æµ‹è¯•å·¥å…·æ¨¡å—å¯¼å…¥
        from api.utils.common_utils import (
            safe_execute, generate_conversation_id, 
            create_success_response, create_error_response
        )
        print("âœ“ é€šç”¨å·¥å…·æ¨¡å—å¯¼å…¥æˆåŠŸ")
        
        from api.utils.text_utils import (
            clean_medical_text, has_medical_keywords,
            extract_keywords_from_query, validate_prescription_format
        )
        print("âœ“ æ–‡æœ¬å¤„ç†æ¨¡å—å¯¼å…¥æˆåŠŸ")
        
        # æµ‹è¯•å¤„ç†å™¨æ¨¡å—å¯¼å…¥
        from api.processors.user_history_processor import UserHistoryProcessor
        print("âœ“ ç”¨æˆ·å†å²å¤„ç†å™¨å¯¼å…¥æˆåŠŸ")
        
        from api.processors.image_analysis_processor import ImageAnalysisProcessor
        print("âœ“ å›¾åƒåˆ†æå¤„ç†å™¨å¯¼å…¥æˆåŠŸ")
        
        from api.processors.knowledge_retrieval_processor import KnowledgeRetrievalProcessor
        print("âœ“ çŸ¥è¯†æ£€ç´¢å¤„ç†å™¨å¯¼å…¥æˆåŠŸ")
        
        from api.processors.llm_integration_processor import LLMIntegrationProcessor
        print("âœ“ LLMé›†æˆå¤„ç†å™¨å¯¼å…¥æˆåŠŸ")
        
        from api.processors.medical_safety_processor import MedicalSafetyProcessor
        print("âœ“ åŒ»ç–—å®‰å…¨å¤„ç†å™¨å¯¼å…¥æˆåŠŸ")
        
        from api.processors.chat_endpoint_processor import ChatEndpointProcessor
        print("âœ“ èŠå¤©ç«¯ç‚¹å¤„ç†å™¨å¯¼å…¥æˆåŠŸ")
        
        # æµ‹è¯•æœåŠ¡åŒ…è£…å™¨å¯¼å…¥
        from api.services.llm_service_wrapper import LLMServiceWrapper, MultimodalServiceWrapper
        print("âœ“ æœåŠ¡åŒ…è£…å™¨å¯¼å…¥æˆåŠŸ")
        
        return True, "æ‰€æœ‰æ¨¡å—å¯¼å…¥æˆåŠŸ"
        
    except Exception as e:
        return False, f"æ¨¡å—å¯¼å…¥å¤±è´¥: {e}"

def test_utility_functions():
    """æµ‹è¯•å·¥å…·å‡½æ•°"""
    print("=" * 60)
    print("2. æµ‹è¯•å·¥å…·å‡½æ•°")
    print("-" * 40)
    
    try:
        from api.utils.common_utils import (
            safe_execute, generate_conversation_id,
            get_current_timestamp_iso, clean_text
        )
        from api.utils.text_utils import (
            clean_medical_text, extract_keywords_from_query,
            normalize_prescription_dosage, validate_prescription_format
        )
        
        # æµ‹è¯•IDç”Ÿæˆ
        conv_id = generate_conversation_id()
        assert len(conv_id) > 10, "å¯¹è¯IDç”Ÿæˆå¤±è´¥"
        print(f"âœ“ å¯¹è¯IDç”Ÿæˆ: {conv_id[:8]}...")
        
        # æµ‹è¯•æ—¶é—´æˆ³ç”Ÿæˆ
        timestamp = get_current_timestamp_iso()
        assert datetime.fromisoformat(timestamp.replace('Z', '+00:00')), "æ—¶é—´æˆ³æ ¼å¼é”™è¯¯"
        print(f"âœ“ æ—¶é—´æˆ³ç”Ÿæˆ: {timestamp}")
        
        # æµ‹è¯•æ–‡æœ¬å¤„ç†
        test_text = "æ‚£è€…æœ‰å¤´ç—›ã€å’³å—½ç—‡çŠ¶ï¼Œéœ€è¦ä¸­åŒ»è¯Šç–—"
        cleaned_text = clean_medical_text(test_text)
        assert len(cleaned_text) > 0, "æ–‡æœ¬æ¸…ç†å¤±è´¥"
        print(f"âœ“ æ–‡æœ¬æ¸…ç†: {cleaned_text[:20]}...")
        
        # æµ‹è¯•å…³é”®è¯æå–
        keywords = extract_keywords_from_query(test_text)
        assert len(keywords) > 0, "å…³é”®è¯æå–å¤±è´¥"
        print(f"âœ“ å…³é”®è¯æå–: {keywords}")
        
        # æµ‹è¯•å¤„æ–¹æ ¼å¼éªŒè¯
        test_prescription = """
        å…šå‚ 12g
        ç™½æœ¯ 10g
        èŒ¯è‹“ 12g
        ç”˜è‰ 6g
        """
        valid, message = validate_prescription_format(test_prescription)
        assert valid, f"å¤„æ–¹éªŒè¯å¤±è´¥: {message}"
        print(f"âœ“ å¤„æ–¹æ ¼å¼éªŒè¯: {message}")
        
        # æµ‹è¯•å®‰å…¨æ‰§è¡Œ
        def test_func():
            return "æµ‹è¯•æˆåŠŸ"
        
        result = safe_execute(test_func, default_return="é»˜è®¤å€¼")
        assert result == "æµ‹è¯•æˆåŠŸ", "å®‰å…¨æ‰§è¡Œå‡½æ•°å¤±è´¥"
        print("âœ“ å®‰å…¨æ‰§è¡Œå‡½æ•°æµ‹è¯•é€šè¿‡")
        
        return True, "æ‰€æœ‰å·¥å…·å‡½æ•°æµ‹è¯•é€šè¿‡"
        
    except Exception as e:
        return False, f"å·¥å…·å‡½æ•°æµ‹è¯•å¤±è´¥: {e}"

def test_service_wrappers():
    """æµ‹è¯•æœåŠ¡åŒ…è£…å™¨"""
    print("=" * 60)
    print("3. æµ‹è¯•æœåŠ¡åŒ…è£…å™¨")
    print("-" * 40)
    
    try:
        from api.services.llm_service_wrapper import LLMServiceWrapper, MultimodalServiceWrapper
        
        # æ¨¡æ‹ŸAIé…ç½®
        mock_config = {
            'default_model': 'qwen-max',
            'multimodal_model': 'qwen-vl-max',
            'temperature': 0.7,
            'timeout': 60,
            'multimodal_timeout': 80
        }
        
        # æµ‹è¯•LLMæœåŠ¡åŒ…è£…å™¨
        llm_service = LLMServiceWrapper(mock_config)
        llm_response = llm_service.generate_response("æµ‹è¯•æç¤ºè¯", temperature=0.8)
        
        assert llm_response['success'], "LLMæœåŠ¡è°ƒç”¨å¤±è´¥"
        assert len(llm_response['response']) > 0, "LLMå“åº”ä¸ºç©º"
        print("âœ“ LLMæœåŠ¡åŒ…è£…å™¨æµ‹è¯•é€šè¿‡")
        
        # æµ‹è¯•å¤šæ¨¡æ€æœåŠ¡åŒ…è£…å™¨
        multimodal_service = MultimodalServiceWrapper(mock_config)
        
        # åˆ›å»ºä¸´æ—¶å›¾åƒæ–‡ä»¶è¿›è¡Œæµ‹è¯•
        import tempfile
        with tempfile.NamedTemporaryFile(suffix='.jpg', delete=False) as tmp_file:
            tmp_file.write(b'fake image data')
            temp_path = tmp_file.name
        
        try:
            multimodal_response = multimodal_service.analyze_image(
                temp_path, "åˆ†æè¿™å¼ èˆŒè±¡å›¾ç‰‡"
            )
            
            assert multimodal_response['success'], "å¤šæ¨¡æ€æœåŠ¡è°ƒç”¨å¤±è´¥"
            assert len(multimodal_response['response']) > 0, "å¤šæ¨¡æ€å“åº”ä¸ºç©º"
            print("âœ“ å¤šæ¨¡æ€æœåŠ¡åŒ…è£…å™¨æµ‹è¯•é€šè¿‡")
            
        finally:
            os.unlink(temp_path)
        
        return True, "æœåŠ¡åŒ…è£…å™¨æµ‹è¯•é€šè¿‡"
        
    except Exception as e:
        return False, f"æœåŠ¡åŒ…è£…å™¨æµ‹è¯•å¤±è´¥: {e}"

def test_processors():
    """æµ‹è¯•å¤„ç†å™¨åŠŸèƒ½"""
    print("=" * 60)
    print("4. æµ‹è¯•å¤„ç†å™¨åŠŸèƒ½")
    print("-" * 40)
    
    try:
        # æ¨¡æ‹ŸæœåŠ¡å®¹å™¨
        class MockDBManager:
            def execute_query(self, query, params=None):
                return {'success': True, 'data': []}
        
        class MockConfigManager:
            def get_ai_config(self):
                return {
                    'default_model': 'qwen-max',
                    'temperature': 0.7,
                    'enable_safety_check': True,
                    'enable_response_caching': True
                }
        
        services_container = {
            'db_manager': MockDBManager(),
            'vector_store_service': None,
            'faiss_service': None,
            'multimodal_service': None,
            'llm_service': None,
            'config_manager': MockConfigManager(),
            'cache_service': None
        }
        
        # æµ‹è¯•åŒ»ç–—å®‰å…¨å¤„ç†å™¨
        from api.processors.medical_safety_processor import MedicalSafetyProcessor
        safety_processor = MedicalSafetyProcessor(
            services_container['db_manager'],
            services_container['config_manager']
        )
        
        test_prescription = """
        å…šå‚ 12g
        ç™½æœ¯ 10g
        èŒ¯è‹“ 12g
        ç”˜è‰ 6g
        """
        
        safety_result = safety_processor.perform_comprehensive_safety_check(
            test_prescription, user_profile={}
        )
        
        assert 'overall_risk_level' in safety_result, "å®‰å…¨æ£€æŸ¥ç»“æœæ ¼å¼é”™è¯¯"
        assert safety_result['safety_passed'] is not None, "å®‰å…¨æ£€æŸ¥çŠ¶æ€ç¼ºå¤±"
        print("âœ“ åŒ»ç–—å®‰å…¨å¤„ç†å™¨æµ‹è¯•é€šè¿‡")
        
        # æµ‹è¯•LLMé›†æˆå¤„ç†å™¨ï¼ˆæ¨¡æ‹Ÿï¼‰
        from api.processors.llm_integration_processor import LLMIntegrationProcessor
        from api.services.llm_service_wrapper import LLMServiceWrapper
        
        llm_service = LLMServiceWrapper(services_container['config_manager'].get_ai_config())
        llm_processor = LLMIntegrationProcessor(
            llm_service, 
            services_container['config_manager']
        )
        
        test_context = {
            'user_history': {'recent_history': []},
            'retrieved_knowledge': {'retrieved_items': []},
            'image_analysis': []
        }
        
        llm_result = llm_processor.generate_ai_response(
            "æ‚£è€…å¤´ç—›ï¼Œè¯·åˆ†æ",
            test_context,
            'tcm_diagnosis'
        )
        
        assert llm_result['success'], "LLMé›†æˆå¤„ç†å™¨æµ‹è¯•å¤±è´¥"
        assert len(llm_result['response']) > 0, "LLMå“åº”ä¸ºç©º"
        print("âœ“ LLMé›†æˆå¤„ç†å™¨æµ‹è¯•é€šè¿‡")
        
        return True, "å¤„ç†å™¨åŠŸèƒ½æµ‹è¯•é€šè¿‡"
        
    except Exception as e:
        return False, f"å¤„ç†å™¨åŠŸèƒ½æµ‹è¯•å¤±è´¥: {e}"

def test_chat_endpoint_processor():
    """æµ‹è¯•èŠå¤©ç«¯ç‚¹å¤„ç†å™¨"""
    print("=" * 60)
    print("5. æµ‹è¯•èŠå¤©ç«¯ç‚¹å¤„ç†å™¨")
    print("-" * 40)
    
    try:
        from api.processors.chat_endpoint_processor import ChatEndpointProcessor
        from api.services.llm_service_wrapper import LLMServiceWrapper, MultimodalServiceWrapper
        
        # æ¨¡æ‹Ÿå®Œæ•´çš„æœåŠ¡å®¹å™¨
        class MockDBManager:
            def execute_query(self, query, params=None):
                if 'INSERT INTO conversations' in query:
                    return {'success': True}
                return {'success': True, 'data': []}
        
        class MockConfigManager:
            def get_ai_config(self):
                return {
                    'default_model': 'qwen-max',
                    'multimodal_model': 'qwen-vl-max',
                    'temperature': 0.7,
                    'enable_safety_check': True,
                    'enable_response_caching': False,  # ç®€åŒ–æµ‹è¯•
                    'timeout': 60,
                    'multimodal_timeout': 80
                }
        
        config_manager = MockConfigManager()
        ai_config = config_manager.get_ai_config()
        
        services_container = {
            'db_manager': MockDBManager(),
            'vector_store_service': None,
            'faiss_service': None,
            'multimodal_service': MultimodalServiceWrapper(ai_config),
            'llm_service': LLMServiceWrapper(ai_config),
            'config_manager': config_manager,
            'cache_service': None
        }
        
        # åˆ›å»ºèŠå¤©ç«¯ç‚¹å¤„ç†å™¨
        chat_processor = ChatEndpointProcessor(services_container)
        
        # æµ‹è¯•ç®€å•çš„èŠå¤©è¯·æ±‚
        test_user_input = "æˆ‘æœ‰å¤´ç—›ç—‡çŠ¶ï¼Œè¯·ä¸­åŒ»åˆ†æ"
        test_user_id = "test_user_123"
        
        result = chat_processor.process_chat_request(
            user_input=test_user_input,
            user_id=test_user_id,
            images=None,
            additional_context={'conversation_id': 'test_conv_123'}
        )
        
        assert result['success'], f"èŠå¤©å¤„ç†å¤±è´¥: {result.get('error')}"
        assert 'data' in result, "èŠå¤©ç»“æœç¼ºå°‘æ•°æ®"
        assert 'response' in result['data'], "èŠå¤©ç»“æœç¼ºå°‘å“åº”å†…å®¹"
        assert len(result['data']['response']) > 0, "èŠå¤©å“åº”ä¸ºç©º"
        
        print(f"âœ“ èŠå¤©è¯·æ±‚å¤„ç†æˆåŠŸ")
        print(f"  - å“åº”é•¿åº¦: {len(result['data']['response'])} å­—ç¬¦")
        print(f"  - å¤„ç†æ—¶é—´: {result['data'].get('processing_time', 0):.2f} ç§’")
        print(f"  - å®‰å…¨æ£€æŸ¥: {'é€šè¿‡' if result['data'].get('safety_status', {}).get('safety_passed', True) else 'ä¸é€šè¿‡'}")
        
        return True, "èŠå¤©ç«¯ç‚¹å¤„ç†å™¨æµ‹è¯•é€šè¿‡"
        
    except Exception as e:
        return False, f"èŠå¤©ç«¯ç‚¹å¤„ç†å™¨æµ‹è¯•å¤±è´¥: {e}"

def test_system_integration():
    """æµ‹è¯•ç³»ç»Ÿé›†æˆ"""
    print("=" * 60)
    print("6. æµ‹è¯•ç³»ç»Ÿé›†æˆ")
    print("-" * 40)
    
    try:
        # æ¨¡æ‹Ÿå®Œæ•´çš„APIè°ƒç”¨æµç¨‹ï¼ˆä¸åŒ…æ‹¬FastAPIéƒ¨åˆ†ï¼‰
        print("æµ‹è¯•å®Œæ•´çš„å¤„ç†æµç¨‹...")
        
        # å¯¼å…¥ä¸»è¦ç»„ä»¶
        from api.processors.chat_endpoint_processor import ChatEndpointProcessor
        from api.services.llm_service_wrapper import LLMServiceWrapper, MultimodalServiceWrapper
        from api.utils.common_utils import generate_conversation_id
        
        # åˆ›å»ºæœåŠ¡å®¹å™¨
        class MockServices:
            class DBManager:
                def execute_query(self, query, params=None):
                    if 'SELECT' in query and 'conversations' in query:
                        return {'success': True, 'data': []}
                    elif 'INSERT INTO conversations' in query:
                        return {'success': True}
                    return {'success': True, 'data': []}
            
            class ConfigManager:
                def get_ai_config(self):
                    return {
                        'default_model': 'qwen-max',
                        'multimodal_model': 'qwen-vl-max',
                        'temperature': 0.7,
                        'enable_safety_check': True,
                        'enable_response_caching': False,
                        'timeout': 60,
                        'max_tokens': 2000
                    }
        
        mock_services = MockServices()
        config_manager = mock_services.ConfigManager()
        ai_config = config_manager.get_ai_config()
        
        services_container = {
            'db_manager': mock_services.DBManager(),
            'vector_store_service': None,
            'faiss_service': None,
            'multimodal_service': MultimodalServiceWrapper(ai_config),
            'llm_service': LLMServiceWrapper(ai_config),
            'config_manager': config_manager,
            'cache_service': None
        }
        
        # åˆ›å»ºå¤„ç†å™¨
        chat_processor = ChatEndpointProcessor(services_container)
        
        # æµ‹è¯•å¤šç§åœºæ™¯
        test_scenarios = [
            {
                'name': 'ç—‡çŠ¶å’¨è¯¢',
                'input': 'æˆ‘æœ€è¿‘æ€»æ˜¯å¤´ç—›ï¼Œè¿˜æœ‰ç‚¹å’³å—½ï¼Œè¯·å¸®æˆ‘åˆ†æä¸€ä¸‹',
                'user_id': 'test_user_001'
            },
            {
                'name': 'å¤„æ–¹å’¨è¯¢',
                'input': 'æˆ‘éœ€è¦ä¸€ä¸ªæ²»ç–—å¤±çœ çš„ä¸­è¯å¤„æ–¹',
                'user_id': 'test_user_002'
            },
            {
                'name': 'ç”Ÿæ´»è°ƒç†',
                'input': 'å¦‚ä½•é€šè¿‡é¥®é£Ÿè°ƒç†è„¾èƒƒè™šå¼±ï¼Ÿ',
                'user_id': 'test_user_003'
            }
        ]
        
        successful_tests = 0
        for i, scenario in enumerate(test_scenarios, 1):
            print(f"\næµ‹è¯•åœºæ™¯ {i}: {scenario['name']}")
            
            try:
                result = chat_processor.process_chat_request(
                    user_input=scenario['input'],
                    user_id=scenario['user_id'],
                    images=None,
                    additional_context={
                        'conversation_id': generate_conversation_id(),
                        'selected_doctor': 'zhang_zhongjing'
                    }
                )
                
                if result['success']:
                    print(f"  âœ“ å¤„ç†æˆåŠŸ")
                    print(f"    å“åº”é•¿åº¦: {len(result['data']['response'])} å­—ç¬¦")
                    print(f"    å¤„ç†æ—¶é—´: {result['data'].get('processing_time', 0):.2f} ç§’")
                    successful_tests += 1
                else:
                    print(f"  âœ— å¤„ç†å¤±è´¥: {result.get('error')}")
                    
            except Exception as e:
                print(f"  âœ— å¼‚å¸¸: {e}")
        
        success_rate = successful_tests / len(test_scenarios)
        print(f"\næµ‹è¯•æ±‡æ€»:")
        print(f"  æˆåŠŸåœºæ™¯: {successful_tests}/{len(test_scenarios)}")
        print(f"  æˆåŠŸç‡: {success_rate:.1%}")
        
        if success_rate >= 0.8:
            return True, f"ç³»ç»Ÿé›†æˆæµ‹è¯•é€šè¿‡ (æˆåŠŸç‡: {success_rate:.1%})"
        else:
            return False, f"ç³»ç»Ÿé›†æˆæµ‹è¯•å¤±è´¥ (æˆåŠŸç‡: {success_rate:.1%})"
            
    except Exception as e:
        return False, f"ç³»ç»Ÿé›†æˆæµ‹è¯•å¤±è´¥: {e}"

def generate_test_report(test_results):
    """ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š"""
    print("=" * 60)
    print("æµ‹è¯•æŠ¥å‘Š")
    print("=" * 60)
    
    total_tests = len(test_results)
    passed_tests = sum(1 for result in test_results if result['success'])
    failed_tests = total_tests - passed_tests
    
    print(f"æ€»æµ‹è¯•æ•°: {total_tests}")
    print(f"é€šè¿‡æµ‹è¯•: {passed_tests}")
    print(f"å¤±è´¥æµ‹è¯•: {failed_tests}")
    print(f"é€šè¿‡ç‡: {passed_tests/total_tests:.1%}")
    print()
    
    for i, result in enumerate(test_results, 1):
        status = "âœ“ é€šè¿‡" if result['success'] else "âœ— å¤±è´¥"
        print(f"{i}. {result['name']}: {status}")
        if not result['success']:
            print(f"   é”™è¯¯: {result['message']}")
    
    print("-" * 60)
    
    if passed_tests == total_tests:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼é‡æ„åçš„ç³»ç»ŸåŠŸèƒ½æ­£å¸¸ã€‚")
        return True
    else:
        print(f"âš ï¸  æœ‰ {failed_tests} ä¸ªæµ‹è¯•å¤±è´¥ï¼Œéœ€è¦è¿›ä¸€æ­¥è°ƒè¯•ã€‚")
        return False

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("å¼€å§‹æµ‹è¯•é‡æ„åçš„TCM AIè¯Šæ–­ç³»ç»Ÿ")
    print(f"æµ‹è¯•æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    # å®šä¹‰æµ‹è¯•ç”¨ä¾‹
    test_cases = [
        ("æ¨¡å—å¯¼å…¥æµ‹è¯•", test_module_imports),
        ("å·¥å…·å‡½æ•°æµ‹è¯•", test_utility_functions),
        ("æœåŠ¡åŒ…è£…å™¨æµ‹è¯•", test_service_wrappers),
        ("å¤„ç†å™¨åŠŸèƒ½æµ‹è¯•", test_processors),
        ("èŠå¤©ç«¯ç‚¹å¤„ç†å™¨æµ‹è¯•", test_chat_endpoint_processor),
        ("ç³»ç»Ÿé›†æˆæµ‹è¯•", test_system_integration)
    ]
    
    test_results = []
    
    for test_name, test_func in test_cases:
        print(f"\næ‰§è¡Œæµ‹è¯•: {test_name}")
        try:
            success, message = test_func()
            test_results.append({
                'name': test_name,
                'success': success,
                'message': message
            })
            
            if success:
                print(f"âœ“ {test_name}: {message}")
            else:
                print(f"âœ— {test_name}: {message}")
                
        except Exception as e:
            test_results.append({
                'name': test_name,
                'success': False,
                'message': f"æµ‹è¯•å¼‚å¸¸: {str(e)}"
            })
            print(f"âœ— {test_name}: æµ‹è¯•å¼‚å¸¸: {e}")
    
    # ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š
    print("\n")
    overall_success = generate_test_report(test_results)
    
    # ä¿å­˜æµ‹è¯•ç»“æœåˆ°æ–‡ä»¶
    report_file = '/opt/tcm-ai/template_files/refactoring_test_report.json'
    with open(report_file, 'w', encoding='utf-8') as f:
        json.dump({
            'test_time': datetime.now().isoformat(),
            'overall_success': overall_success,
            'test_results': test_results,
            'summary': {
                'total_tests': len(test_results),
                'passed_tests': sum(1 for r in test_results if r['success']),
                'failed_tests': sum(1 for r in test_results if not r['success']),
                'success_rate': sum(1 for r in test_results if r['success']) / len(test_results)
            }
        }, ensure_ascii=False, indent=2)
    
    print(f"\næµ‹è¯•æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")
    
    return overall_success

if __name__ == "__main__":
    success = main()
    exit(0 if success else 1)